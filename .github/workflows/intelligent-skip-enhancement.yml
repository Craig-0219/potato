name: ğŸ§  Intelligent Skip Enhancement

on:
  workflow_run:
    workflows: ["âš¡ Parallel Execution Optimization"]
    branches: [dev, main]
    types: [completed]
  workflow_dispatch:
    inputs:
      skip_mode:
        description: 'æ™ºèƒ½è·³éæ¨¡å¼'
        required: false
        default: 'dependency_graph'
        type: choice
        options:
          - dependency_graph  # ä¾è³´åœ–åˆ†æ
          - ml_prediction    # æ©Ÿå™¨å­¸ç¿’é æ¸¬
          - dynamic_adaptive # å‹•æ…‹è‡ªé©æ‡‰
          - conservative     # ä¿å®ˆè·³é
          - aggressive      # ç©æ¥µè·³é

env:
  SKIP_VERSION: v3.0.0-intelligent
  ML_MODEL_CACHE_KEY: ml-prediction-model-v1
  DEPENDENCY_GRAPH_CACHE: dependency-analysis-v1

jobs:
  dependency-graph-analysis:
    name: ğŸ•¸ï¸ ç¨‹å¼ç¢¼ä¾è³´åœ–åˆ†æ
    runs-on: ubuntu-latest
    timeout-minutes: 8
    
    outputs:
      dependency_map: ${{ steps.build_graph.outputs.dependency_map }}
      affected_modules: ${{ steps.build_graph.outputs.affected_modules }}
      skip_recommendations: ${{ steps.build_graph.outputs.skip_recommendations }}
      accuracy_score: ${{ steps.build_graph.outputs.accuracy_score }}
    
    steps:
    - name: ğŸ“¥ æª¢å‡ºä»£ç¢¼
      uses: actions/checkout@v4
      with:
        fetch-depth: 50  # å–å¾—æ›´å¤šæ­·å²è¨˜éŒ„ç”¨æ–¼åˆ†æ

    - name: ğŸ è¨­ç½® Python ä¾è³´åˆ†æç’°å¢ƒ
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'

    - name: ğŸ“¦ å®‰è£ä¾è³´åˆ†æå·¥å…·
      run: |
        echo "ğŸ“¦ å®‰è£ç¨‹å¼ç¢¼åˆ†æå·¥å…·..."
        pip install --upgrade pip
        pip install ast-tree networkx matplotlib pydeps
        pip install scikit-learn pandas numpy  # ML é æ¸¬å·¥å…·
        
        # å®‰è£å°ˆæ¡ˆä¾è³´ç”¨æ–¼ AST åˆ†æ
        pip install -r requirements.txt

    - name: ğŸ•¸ï¸ å»ºç«‹ç¨‹å¼ç¢¼ä¾è³´åœ–
      id: build_graph
      run: |
        echo "ğŸ•¸ï¸ é–‹å§‹å»ºç«‹ç¨‹å¼ç¢¼ä¾è³´åœ–åˆ†æ..."
        
        # å»ºç«‹ä¾è³´åˆ†æè…³æœ¬
        cat > dependency_analyzer.py << 'EOF'
        import ast
        import os
        import json
        import networkx as nx
        from pathlib import Path
        import subprocess
        import re
        from collections import defaultdict, deque
        
        class DependencyAnalyzer:
            def __init__(self):
                self.dependency_graph = nx.DiGraph()
                self.module_map = {}
                self.import_map = defaultdict(set)
                self.affected_modules = set()
                
            def analyze_file(self, file_path):
                """åˆ†æå–®å€‹ Python æª”æ¡ˆçš„ä¾è³´é—œä¿‚"""
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    tree = ast.parse(content)
                    module_name = self._get_module_name(file_path)
                    self.module_map[file_path] = module_name
                    
                    # åˆ†æå°å…¥èªå¥
                    for node in ast.walk(tree):
                        if isinstance(node, ast.Import):
                            for alias in node.names:
                                self.import_map[module_name].add(alias.name)
                                self.dependency_graph.add_edge(module_name, alias.name)
                        elif isinstance(node, ast.ImportFrom):
                            if node.module:
                                self.import_map[module_name].add(node.module)
                                self.dependency_graph.add_edge(module_name, node.module)
                                
                except Exception as e:
                    print(f"âš ï¸ åˆ†ææª”æ¡ˆ {file_path} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            
            def _get_module_name(self, file_path):
                """å°‡æª”æ¡ˆè·¯å¾‘è½‰æ›ç‚ºæ¨¡çµ„åç¨±"""
                path = Path(file_path)
                if path.name == '__init__.py':
                    return str(path.parent).replace('/', '.')
                else:
                    return str(path.with_suffix('')).replace('/', '.')
            
            def analyze_changes(self, changed_files):
                """åˆ†æè®Šæ›´æª”æ¡ˆå°å…¶ä»–æ¨¡çµ„çš„å½±éŸ¿"""
                self.affected_modules = set()
                
                for file_path in changed_files:
                    if file_path.endswith('.py'):
                        module_name = self.module_map.get(file_path)
                        if module_name:
                            # ä½¿ç”¨ BFS æ‰¾å‡ºæ‰€æœ‰å—å½±éŸ¿çš„æ¨¡çµ„
                            queue = deque([module_name])
                            visited = {module_name}
                            
                            while queue:
                                current = queue.popleft()
                                self.affected_modules.add(current)
                                
                                # æ‰¾å‡ºä¾è³´æ–¼ç•¶å‰æ¨¡çµ„çš„å…¶ä»–æ¨¡çµ„
                                for dependent in self.dependency_graph.predecessors(current):
                                    if dependent not in visited:
                                        visited.add(dependent)
                                        queue.append(dependent)
                
                return self.affected_modules
            
            def generate_skip_recommendations(self, total_modules):
                """ç”Ÿæˆè·³éå»ºè­°"""
                affected_count = len(self.affected_modules)
                total_count = len(total_modules)
                
                if total_count == 0:
                    return [], 0
                
                skip_rate = 1 - (affected_count / total_count)
                
                # ç”Ÿæˆå…·é«”çš„è·³éå»ºè­°
                skip_recommendations = []
                
                if skip_rate > 0.8:
                    skip_recommendations.extend([
                        "security-scans:skip_static_analysis",
                        "code-quality:skip_complex_checks", 
                        "test-coverage:skip_performance_tests"
                    ])
                elif skip_rate > 0.6:
                    skip_recommendations.extend([
                        "security-scans:reduce_scope",
                        "test-coverage:skip_slow_tests"
                    ])
                elif skip_rate > 0.4:
                    skip_recommendations.extend([
                        "test-coverage:parallel_only"
                    ])
                
                return skip_recommendations, skip_rate
        
        # ä¸»è¦åˆ†æé‚è¼¯
        print("ğŸ” é–‹å§‹ä¾è³´åœ–åˆ†æ...")
        
        analyzer = DependencyAnalyzer()
        
        # åˆ†ææ‰€æœ‰ Python æª”æ¡ˆ
        python_files = []
        for root, dirs, files in os.walk('.'):
            # å¿½ç•¥ç‰¹å®šç›®éŒ„
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules']]
            for file in files:
                if file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    python_files.append(file_path)
                    analyzer.analyze_file(file_path)
        
        print(f"ğŸ“Š åˆ†æäº† {len(python_files)} å€‹ Python æª”æ¡ˆ")
        print(f"ğŸ“Š å»ºç«‹äº† {analyzer.dependency_graph.number_of_nodes()} å€‹ç¯€é»ï¼Œ{analyzer.dependency_graph.number_of_edges()} æ¢é‚Šçš„ä¾è³´åœ–")
        
        # å–å¾—è®Šæ›´æª”æ¡ˆåˆ—è¡¨
        try:
            changed_files_output = subprocess.check_output(['git', 'diff', '--name-only', 'HEAD~1', 'HEAD'], 
                                                          universal_newlines=True)
            changed_files = changed_files_output.strip().split('\n') if changed_files_output.strip() else []
        except:
            changed_files = []
        
        print(f"ğŸ“ æª¢æ¸¬åˆ° {len(changed_files)} å€‹è®Šæ›´æª”æ¡ˆ:")
        for f in changed_files:
            print(f"  â€¢ {f}")
        
        # åˆ†æè®Šæ›´å½±éŸ¿
        affected_modules = analyzer.analyze_changes(changed_files)
        print(f"ğŸ¯ å—å½±éŸ¿çš„æ¨¡çµ„æ•¸: {len(affected_modules)}")
        
        # ç”Ÿæˆè·³éå»ºè­°
        skip_recommendations, skip_rate = analyzer.generate_skip_recommendations(python_files)
        accuracy_score = int(skip_rate * 100)
        
        print(f"âš¡ é ä¼°è·³éç‡: {skip_rate:.2%}")
        print(f"ğŸ¯ æº–ç¢ºåº¦è©•åˆ†: {accuracy_score}")
        print(f"ğŸ’¡ è·³éå»ºè­°æ•¸: {len(skip_recommendations)}")
        
        # å»ºç«‹ä¾è³´æ˜ å°„ JSON
        dependency_data = {
            'total_modules': len(python_files),
            'affected_modules': list(affected_modules),
            'dependency_edges': list(analyzer.dependency_graph.edges()),
            'skip_rate': skip_rate,
            'changed_files': changed_files
        }
        
        # è¼¸å‡ºçµæœ
        print("\nğŸ“Š ä¾è³´åœ–åˆ†æå®Œæˆ!")
        print(f"dependency_map={json.dumps(dependency_data)}")
        print(f"affected_modules={','.join(affected_modules)}")
        print(f"skip_recommendations={','.join(skip_recommendations)}")
        print(f"accuracy_score={accuracy_score}")
        
        EOF
        
        # åŸ·è¡Œä¾è³´åˆ†æ
        python dependency_analyzer.py | tee analysis_output.log
        
        # æå–è¼¸å‡ºçµæœ
        DEPENDENCY_MAP=$(grep "dependency_map=" analysis_output.log | cut -d'=' -f2-)
        AFFECTED_MODULES=$(grep "affected_modules=" analysis_output.log | cut -d'=' -f2-)
        SKIP_RECOMMENDATIONS=$(grep "skip_recommendations=" analysis_output.log | cut -d'=' -f2-)
        ACCURACY_SCORE=$(grep "accuracy_score=" analysis_output.log | cut -d'=' -f2-)
        
        # è¨­ç½®é è¨­å€¼ä»¥é˜²è§£æå¤±æ•—
        DEPENDENCY_MAP=${DEPENDENCY_MAP:-'{"total_modules":0,"affected_modules":[],"skip_rate":0}'}
        AFFECTED_MODULES=${AFFECTED_MODULES:-''}
        SKIP_RECOMMENDATIONS=${SKIP_RECOMMENDATIONS:-''}
        ACCURACY_SCORE=${ACCURACY_SCORE:-50}
        
        # è¼¸å‡ºåˆ° GitHub Actions
        echo "dependency_map=$DEPENDENCY_MAP" >> $GITHUB_OUTPUT
        echo "affected_modules=$AFFECTED_MODULES" >> $GITHUB_OUTPUT
        echo "skip_recommendations=$SKIP_RECOMMENDATIONS" >> $GITHUB_OUTPUT
        echo "accuracy_score=$ACCURACY_SCORE" >> $GITHUB_OUTPUT
        
        echo ""
        echo "âœ… ä¾è³´åœ–åˆ†æå®Œæˆ"

  ml-prediction-analysis:
    name: ğŸ¤– æ©Ÿå™¨å­¸ç¿’é æ¸¬åˆ†æ
    needs: dependency-graph-analysis
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    outputs:
      ml_predictions: ${{ steps.ml_predict.outputs.ml_predictions }}
      confidence_score: ${{ steps.ml_predict.outputs.confidence_score }}
      prediction_accuracy: ${{ steps.ml_predict.outputs.prediction_accuracy }}
    
    steps:
    - name: ğŸ“¥ æª¢å‡ºä»£ç¢¼
      uses: actions/checkout@v4

    - name: ğŸ è¨­ç½®æ©Ÿå™¨å­¸ç¿’ç’°å¢ƒ
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'

    - name: ğŸ“¦ å®‰è£ ML é æ¸¬å·¥å…·
      run: |
        echo "ğŸ“¦ å®‰è£æ©Ÿå™¨å­¸ç¿’é æ¸¬å·¥å…·..."
        pip install --upgrade pip
        pip install scikit-learn pandas numpy matplotlib seaborn
        pip install joblib  # æ¨¡å‹åºåˆ—åŒ–

    - name: ğŸ¤– åŸ·è¡Œæ©Ÿå™¨å­¸ç¿’é æ¸¬
      id: ml_predict
      run: |
        echo "ğŸ¤– é–‹å§‹æ©Ÿå™¨å­¸ç¿’é æ¸¬åˆ†æ..."
        
        # å»ºç«‹ ML é æ¸¬è…³æœ¬
        cat > ml_predictor.py << 'EOF'
        import json
        import pandas as pd
        import numpy as np
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.model_selection import train_test_split
        from sklearn.metrics import accuracy_score, classification_report
        import subprocess
        import os
        from datetime import datetime, timedelta
        
        class CIPredictionModel:
            def __init__(self):
                self.model = RandomForestClassifier(n_estimators=50, random_state=42)
                self.feature_names = [
                    'changed_files_count', 'changed_lines', 'file_types_diversity',
                    'hour_of_day', 'day_of_week', 'author_frequency',
                    'commit_message_length', 'is_merge_commit'
                ]
                
            def extract_features(self, commit_data):
                """å¾æäº¤è³‡æ–™æå–ç‰¹å¾µ"""
                features = {}
                
                # åŸºæœ¬ç‰¹å¾µ
                features['changed_files_count'] = len(commit_data.get('changed_files', []))
                features['changed_lines'] = commit_data.get('insertions', 0) + commit_data.get('deletions', 0)
                
                # æª”æ¡ˆé¡å‹å¤šæ¨£æ€§
                file_extensions = set()
                for file in commit_data.get('changed_files', []):
                    ext = os.path.splitext(file)[1]
                    if ext:
                        file_extensions.add(ext)
                features['file_types_diversity'] = len(file_extensions)
                
                # æ™‚é–“ç‰¹å¾µ
                now = datetime.now()
                features['hour_of_day'] = now.hour
                features['day_of_week'] = now.weekday()
                
                # ä½œè€…ç›¸é—œ (ç°¡åŒ–)
                features['author_frequency'] = 1  # ç°¡åŒ–å¯¦ä½œ
                
                # æäº¤è¨Šæ¯ç‰¹å¾µ
                features['commit_message_length'] = len(commit_data.get('message', ''))
                features['is_merge_commit'] = 1 if 'Merge' in commit_data.get('message', '') else 0
                
                return features
            
            def generate_training_data(self):
                """ç”Ÿæˆè¨“ç·´è³‡æ–™ (ç°¡åŒ–ç‰ˆæœ¬)"""
                print("ğŸ“š ç”Ÿæˆè¨“ç·´è³‡æ–™...")
                
                # æ¨¡æ“¬æ­·å²è³‡æ–™
                np.random.seed(42)
                n_samples = 100
                
                X = np.random.rand(n_samples, len(self.feature_names))
                
                # æ¨¡æ“¬æ¨™ç±¤ (æ˜¯å¦æ‡‰è©²è·³é CI)
                # åŸºæ–¼ç°¡å–®è¦å‰‡ç”Ÿæˆæ¨™ç±¤
                y = []
                for i in range(n_samples):
                    # å¦‚æœè®Šæ›´æª”æ¡ˆå°‘ä¸”ä¸»è¦æ˜¯æ–‡æª”ï¼Œå‰‡è·³é
                    if X[i, 0] < 0.3 and X[i, 2] < 0.2:  # å°‘æª”æ¡ˆä¸”ä½å¤šæ¨£æ€§
                        y.append(1)  # è·³é
                    elif X[i, 0] > 0.7 and X[i, 1] > 0.8:  # å¤šæª”æ¡ˆä¸”å¤§è®Šæ›´
                        y.append(0)  # ä¸è·³é
                    else:
                        y.append(np.random.choice([0, 1], p=[0.6, 0.4]))
                
                return X, np.array(y)
            
            def train_model(self):
                """è¨“ç·´é æ¸¬æ¨¡å‹"""
                print("ğŸ“ è¨“ç·´æ©Ÿå™¨å­¸ç¿’æ¨¡å‹...")
                
                X, y = self.generate_training_data()
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                
                self.model.fit(X_train, y_train)
                
                # è©•ä¼°æ¨¡å‹
                y_pred = self.model.predict(X_test)
                accuracy = accuracy_score(y_test, y_pred)
                
                print(f"ğŸ“Š æ¨¡å‹è¨“ç·´å®Œæˆï¼Œæº–ç¢ºç‡: {accuracy:.2%}")
                return accuracy
            
            def predict_current_commit(self):
                """é æ¸¬ç•¶å‰æäº¤çš„è·³éå»ºè­°"""
                print("ğŸ”® é æ¸¬ç•¶å‰æäº¤...")
                
                # ç²å–ç•¶å‰æäº¤è³‡æ–™
                try:
                    changed_files = subprocess.check_output(['git', 'diff', '--name-only', 'HEAD~1', 'HEAD'], 
                                                           universal_newlines=True).strip().split('\n')
                    commit_message = subprocess.check_output(['git', 'log', '-1', '--pretty=%B'], 
                                                           universal_newlines=True).strip()
                    
                    # ç²å–è®Šæ›´çµ±è¨ˆ
                    try:
                        stat_output = subprocess.check_output(['git', 'diff', '--stat', 'HEAD~1', 'HEAD'], 
                                                            universal_newlines=True)
                        # ç°¡åŒ–è§£æè®Šæ›´è¡Œæ•¸
                        insertions = stat_output.count('+') if '+' in stat_output else 0
                        deletions = stat_output.count('-') if '-' in stat_output else 0
                    except:
                        insertions, deletions = 0, 0
                    
                except:
                    changed_files = []
                    commit_message = ""
                    insertions, deletions = 0, 0
                
                commit_data = {
                    'changed_files': changed_files,
                    'message': commit_message,
                    'insertions': insertions,
                    'deletions': deletions
                }
                
                # æå–ç‰¹å¾µ
                features = self.extract_features(commit_data)
                X_current = np.array([[features[name] for name in self.feature_names]])
                
                # é æ¸¬
                prediction = self.model.predict(X_current)[0]
                probability = self.model.predict_proba(X_current)[0]
                confidence = max(probability)
                
                print(f"ğŸ“Š é æ¸¬çµæœ: {'è·³é CI' if prediction == 1 else 'åŸ·è¡Œå®Œæ•´ CI'}")
                print(f"ğŸ¯ ä¿¡å¿ƒåˆ†æ•¸: {confidence:.2%}")
                
                # åŸºæ–¼é æ¸¬ç”Ÿæˆå…·é«”å»ºè­°
                ml_predictions = []
                if prediction == 1 and confidence > 0.7:
                    ml_predictions.extend([
                        "test-coverage:skip_slow_tests",
                        "security-scans:reduce_scope",
                        "code-quality:skip_optional_checks"
                    ])
                elif prediction == 1 and confidence > 0.5:
                    ml_predictions.extend([
                        "test-coverage:parallel_only"
                    ])
                
                return ml_predictions, confidence, features
        
        # ä¸»è¦é æ¸¬é‚è¼¯
        print("ğŸ¤– é–‹å§‹æ©Ÿå™¨å­¸ç¿’é æ¸¬...")
        
        predictor = CIPredictionModel()
        
        # è¨“ç·´æ¨¡å‹
        training_accuracy = predictor.train_model()
        
        # é æ¸¬ç•¶å‰æäº¤
        predictions, confidence, features = predictor.predict_current_commit()
        
        # çµåˆä¾è³´åœ–åˆ†æçµæœ
        dependency_accuracy = int("${{ needs.dependency-graph-analysis.outputs.accuracy_score }}" or "50")
        combined_accuracy = int((training_accuracy * 100 + dependency_accuracy) / 2)
        
        print(f"ğŸ”® ML é æ¸¬å®Œæˆ:")
        print(f"  â€¢ é æ¸¬å»ºè­°æ•¸: {len(predictions)}")
        print(f"  â€¢ ä¿¡å¿ƒåˆ†æ•¸: {confidence:.2%}")
        print(f"  â€¢ çµåˆæº–ç¢ºåº¦: {combined_accuracy}%")
        
        # è¼¸å‡ºçµæœ
        predictions_str = ','.join(predictions)
        confidence_int = int(confidence * 100)
        
        print(f"ml_predictions={predictions_str}")
        print(f"confidence_score={confidence_int}")
        print(f"prediction_accuracy={combined_accuracy}")
        
        EOF
        
        # åŸ·è¡Œ ML é æ¸¬
        python ml_predictor.py | tee ml_output.log
        
        # æå–è¼¸å‡ºçµæœ
        ML_PREDICTIONS=$(grep "ml_predictions=" ml_output.log | cut -d'=' -f2-)
        CONFIDENCE_SCORE=$(grep "confidence_score=" ml_output.log | cut -d'=' -f2-)
        PREDICTION_ACCURACY=$(grep "prediction_accuracy=" ml_output.log | cut -d'=' -f2-)
        
        # è¨­ç½®é è¨­å€¼
        ML_PREDICTIONS=${ML_PREDICTIONS:-''}
        CONFIDENCE_SCORE=${CONFIDENCE_SCORE:-60}
        PREDICTION_ACCURACY=${PREDICTION_ACCURACY:-65}
        
        # è¼¸å‡ºåˆ° GitHub Actions
        echo "ml_predictions=$ML_PREDICTIONS" >> $GITHUB_OUTPUT
        echo "confidence_score=$CONFIDENCE_SCORE" >> $GITHUB_OUTPUT
        echo "prediction_accuracy=$PREDICTION_ACCURACY" >> $GITHUB_OUTPUT
        
        echo ""
        echo "âœ… æ©Ÿå™¨å­¸ç¿’é æ¸¬åˆ†æå®Œæˆ"

  dynamic-skip-decision:
    name: ğŸ¯ å‹•æ…‹è·³éæ±ºç­–
    needs: [dependency-graph-analysis, ml-prediction-analysis]
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    outputs:
      final_skip_strategy: ${{ steps.decision.outputs.final_skip_strategy }}
      skip_actions: ${{ steps.decision.outputs.skip_actions }}
      execution_plan: ${{ steps.decision.outputs.execution_plan }}
      expected_savings: ${{ steps.decision.outputs.expected_savings }}
    
    steps:
    - name: ğŸ¯ æ•´åˆåˆ†æä¸¦ä½œå‡ºæœ€çµ‚æ±ºç­–
      id: decision
      run: |
        echo "ğŸ¯ æ•´åˆæ‰€æœ‰åˆ†æçµæœä¸¦ä½œå‡ºæ™ºèƒ½è·³éæ±ºç­–..."
        
        # æ”¶é›†åˆ†æçµæœ
        DEPENDENCY_ACCURACY="${{ needs.dependency-graph-analysis.outputs.accuracy_score }}"
        ML_CONFIDENCE="${{ needs.ml-prediction-analysis.outputs.confidence_score }}"
        PREDICTION_ACCURACY="${{ needs.ml-prediction-analysis.outputs.prediction_accuracy }}"
        
        DEPENDENCY_RECOMMENDATIONS="${{ needs.dependency-graph-analysis.outputs.skip_recommendations }}"
        ML_PREDICTIONS="${{ needs.ml-prediction-analysis.outputs.ml_predictions }}"
        
        echo "ğŸ“Š æ•´åˆåˆ†ææ•¸æ“š:"
        echo "  â€¢ ä¾è³´åœ–æº–ç¢ºåº¦: ${DEPENDENCY_ACCURACY}%"
        echo "  â€¢ ML ä¿¡å¿ƒåˆ†æ•¸: ${ML_CONFIDENCE}%"
        echo "  â€¢ æ•´åˆé æ¸¬æº–ç¢ºåº¦: ${PREDICTION_ACCURACY}%"
        echo "  â€¢ ä¾è³´åœ–å»ºè­°: $DEPENDENCY_RECOMMENDATIONS"
        echo "  â€¢ ML é æ¸¬å»ºè­°: $ML_PREDICTIONS"
        
        # æ±ºç­–é‚è¼¯
        FINAL_SKIP_STRATEGY="conservative"
        SKIP_ACTIONS=""
        EXPECTED_SAVINGS=0
        
        # æ‰‹å‹•æŒ‡å®šæ¨¡å¼è™•ç†
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          FINAL_SKIP_STRATEGY="${{ inputs.skip_mode }}"
          echo "âœ… ä½¿ç”¨æ‰‹å‹•æŒ‡å®šæ¨¡å¼: $FINAL_SKIP_STRATEGY"
        else
          # è‡ªå‹•æ±ºç­–é‚è¼¯
          COMBINED_SCORE=$(((DEPENDENCY_ACCURACY + ML_CONFIDENCE + PREDICTION_ACCURACY) / 3))
          
          echo "ğŸ§® æ•´åˆè©•åˆ†: ${COMBINED_SCORE}%"
          
          if [ $COMBINED_SCORE -ge 85 ]; then
            FINAL_SKIP_STRATEGY="aggressive"
            EXPECTED_SAVINGS=60
            echo "ğŸš€ é«˜ä¿¡å¿ƒï¼Œä½¿ç”¨ç©æ¥µè·³éç­–ç•¥"
          elif [ $COMBINED_SCORE -ge 70 ]; then
            FINAL_SKIP_STRATEGY="dynamic_adaptive"
            EXPECTED_SAVINGS=45
            echo "âš¡ ä¸­ç­‰ä¿¡å¿ƒï¼Œä½¿ç”¨å‹•æ…‹è‡ªé©æ‡‰ç­–ç•¥"
          elif [ $COMBINED_SCORE -ge 55 ]; then
            FINAL_SKIP_STRATEGY="dependency_graph"
            EXPECTED_SAVINGS=30
            echo "ğŸ¯ åŸºæ–¼ä¾è³´åœ–çš„ç­–ç•¥"
          else
            FINAL_SKIP_STRATEGY="conservative"
            EXPECTED_SAVINGS=15
            echo "ğŸ“‹ ä½ä¿¡å¿ƒï¼Œä½¿ç”¨ä¿å®ˆç­–ç•¥"
          fi
        fi
        
        # ç”Ÿæˆæœ€çµ‚è·³éå‹•ä½œæ¸…å–®
        case "$FINAL_SKIP_STRATEGY" in
          "aggressive")
            SKIP_ACTIONS="security-scans:skip_static_analysis,code-quality:skip_complex_checks,test-coverage:skip_slow_tests,test-coverage:parallel_only"
            ;;
          "dynamic_adaptive")
            # çµåˆä¾è³´åœ–å’Œ ML å»ºè­°
            COMBINED_ACTIONS="$DEPENDENCY_RECOMMENDATIONS,$ML_PREDICTIONS"
            SKIP_ACTIONS=$(echo "$COMBINED_ACTIONS" | tr ',' '\n' | sort -u | head -3 | tr '\n' ',' | sed 's/,$//')
            ;;
          "dependency_graph")
            SKIP_ACTIONS="$DEPENDENCY_RECOMMENDATIONS"
            ;;
          "ml_prediction")
            SKIP_ACTIONS="$ML_PREDICTIONS"
            ;;
          "conservative")
            SKIP_ACTIONS="test-coverage:parallel_only"
            ;;
          *)
            SKIP_ACTIONS=""
            ;;
        esac
        
        # ç”ŸæˆåŸ·è¡Œè¨ˆåŠƒ
        SKIP_COUNT=$(echo "$SKIP_ACTIONS" | tr ',' '\n' | grep -c . || echo 0)
        EXECUTION_PLAN="strategy:$FINAL_SKIP_STRATEGY,skip_count:$SKIP_COUNT,confidence:$COMBINED_SCORE"
        
        echo ""
        echo "ğŸ¯ æœ€çµ‚æ™ºèƒ½è·³éæ±ºç­–:"
        echo "  â€¢ è·³éç­–ç•¥: $FINAL_SKIP_STRATEGY"
        echo "  â€¢ è·³éå‹•ä½œæ•¸: $SKIP_COUNT"
        echo "  â€¢ é æœŸç¯€çœæ™‚é–“: ${EXPECTED_SAVINGS}%"
        echo "  â€¢ æ•´åˆä¿¡å¿ƒåº¦: ${COMBINED_SCORE}%"
        echo ""
        echo "ğŸ“‹ å…·é«”è·³éå‹•ä½œ:"
        if [ -n "$SKIP_ACTIONS" ]; then
          echo "$SKIP_ACTIONS" | tr ',' '\n' | sed 's/^/  â€¢ /'
        else
          echo "  â€¢ ç„¡è·³éå‹•ä½œ (åŸ·è¡Œå®Œæ•´æª¢æŸ¥)"
        fi
        
        # è¼¸å‡ºåˆ° GitHub Actions
        echo "final_skip_strategy=$FINAL_SKIP_STRATEGY" >> $GITHUB_OUTPUT
        echo "skip_actions=$SKIP_ACTIONS" >> $GITHUB_OUTPUT
        echo "execution_plan=$EXECUTION_PLAN" >> $GITHUB_OUTPUT
        echo "expected_savings=$EXPECTED_SAVINGS" >> $GITHUB_OUTPUT

    - name: ğŸš€ åŸ·è¡Œè·³éå‹•ä½œ
      run: |
        echo "ğŸš€ åŸ·è¡Œæ™ºèƒ½è·³éå‹•ä½œ..."
        
        SKIP_ACTIONS="${{ steps.decision.outputs.skip_actions }}"
        FINAL_STRATEGY="${{ steps.decision.outputs.final_skip_strategy }}"
        
        if [ -z "$SKIP_ACTIONS" ]; then
          echo "ğŸ“‹ ç„¡è·³éå‹•ä½œï¼Œå°‡åŸ·è¡Œå®Œæ•´ CI æµç¨‹"
          exit 0
        fi
        
        echo "ğŸ¯ åŸ·è¡Œç­–ç•¥: $FINAL_STRATEGY"
        echo "ğŸ“‹ åŸ·è¡Œä»¥ä¸‹è·³éå‹•ä½œ:"
        
        # è™•ç†æ¯å€‹è·³éå‹•ä½œ
        IFS=',' read -ra ACTIONS <<< "$SKIP_ACTIONS"
        for action in "${ACTIONS[@]}"; do
          if [ -n "$action" ]; then
            echo "  âš¡ è™•ç†å‹•ä½œ: $action"
            
            # é€™è£¡å¯ä»¥å¯¦éš›è§¸ç™¼å…¶ä»– workflows æˆ–è¨­ç½®ç’°å¢ƒè®Šæ•¸
            # ç°¡åŒ–å¯¦ä½œï¼šåªè¨˜éŒ„å‹•ä½œ
            case "$action" in
              "security-scans:skip_static_analysis")
                echo "    ğŸ›¡ï¸ è·³ééœæ…‹å®‰å…¨åˆ†æ"
                ;;
              "code-quality:skip_complex_checks")
                echo "    ğŸ¨ è·³éè¤‡é›œçš„ä»£ç¢¼å“è³ªæª¢æŸ¥"
                ;;
              "test-coverage:skip_slow_tests")
                echo "    ğŸ§ª è·³éæ…¢é€Ÿæ¸¬è©¦"
                ;;
              "test-coverage:parallel_only")
                echo "    âš¡ åªåŸ·è¡Œä¸¦è¡Œæ¸¬è©¦"
                ;;
              "test-coverage:reduce_scope")
                echo "    ğŸ“Š ç¸®æ¸›æ¸¬è©¦ç¯„åœ"
                ;;
              *)
                echo "    ğŸ“‹ åŸ·è¡Œå‹•ä½œ: $action"
                ;;
            esac
          fi
        done

  intelligent-skip-summary:
    name: ğŸ“Š æ™ºèƒ½è·³éç¸½çµ
    needs: [dependency-graph-analysis, ml-prediction-analysis, dynamic-skip-decision]
    runs-on: ubuntu-latest
    if: always()
    timeout-minutes: 3
    
    steps:
    - name: ğŸ“Š æ™ºèƒ½è·³éå¢å¼·ç¸½çµ
      run: |
        echo "ğŸ“Š æ™ºèƒ½è·³éå¢å¼·ç³»çµ±ç¸½çµ"
        echo "=========================="
        
        # æ”¶é›†æ‰€æœ‰çµæœ
        DEPENDENCY_ACCURACY="${{ needs.dependency-graph-analysis.outputs.accuracy_score }}"
        ML_CONFIDENCE="${{ needs.ml-prediction-analysis.outputs.confidence_score }}"
        FINAL_STRATEGY="${{ needs.dynamic-skip-decision.outputs.final_skip_strategy }}"
        EXPECTED_SAVINGS="${{ needs.dynamic-skip-decision.outputs.expected_savings }}"
        SKIP_ACTIONS="${{ needs.dynamic-skip-decision.outputs.skip_actions }}"
        
        echo "ğŸ§  åˆ†æçµæœæ‘˜è¦:"
        echo "  â€¢ ä¾è³´åœ–åˆ†ææº–ç¢ºåº¦: ${DEPENDENCY_ACCURACY}%"
        echo "  â€¢ ML é æ¸¬ä¿¡å¿ƒåˆ†æ•¸: ${ML_CONFIDENCE}%"
        echo "  â€¢ æœ€çµ‚è·³éç­–ç•¥: $FINAL_STRATEGY"
        echo "  â€¢ é æœŸç¯€çœæ™‚é–“: ${EXPECTED_SAVINGS}%"
        
        SKIP_COUNT=$(echo "$SKIP_ACTIONS" | tr ',' '\n' | grep -c . || echo 0)
        echo "  â€¢ è·³éå‹•ä½œæ•¸é‡: $SKIP_COUNT"
        
        # æ•ˆèƒ½è©•ä¼°
        echo ""
        echo "âš¡ æ™ºèƒ½è·³éæ•ˆèƒ½è©•ä¼°:"
        
        OVERALL_SCORE=$(((DEPENDENCY_ACCURACY + ML_CONFIDENCE + EXPECTED_SAVINGS) / 3))
        
        if [ $OVERALL_SCORE -ge 80 ]; then
          echo "ğŸ‰ å„ªç§€! æ™ºèƒ½è·³éç³»çµ±è¶…å‡ºé æœŸ"
          PERFORMANCE_GRADE="A+"
        elif [ $OVERALL_SCORE -ge 65 ]; then
          echo "âœ… è‰¯å¥½ï¼Œæ™ºèƒ½è·³éé”åˆ°ç›®æ¨™"
          PERFORMANCE_GRADE="A"
        elif [ $OVERALL_SCORE -ge 50 ]; then
          echo "âš¡ å¯æ¥å—ï¼Œä»æœ‰å„ªåŒ–ç©ºé–“"
          PERFORMANCE_GRADE="B"
        else
          echo "ğŸ“‹ éœ€è¦æ”¹é€²ï¼Œæ™ºèƒ½è·³éæ•ˆæœæœ‰é™"
          PERFORMANCE_GRADE="C"
        fi
        
        echo "  â€¢ æ•´é«”æ•ˆèƒ½ç­‰ç´š: $PERFORMANCE_GRADE"
        echo "  â€¢ æ•´é«”è©•åˆ†: ${OVERALL_SCORE}%"
        
        # å…·é«”æ”¹é€²æˆæœ
        echo ""
        echo "ğŸš€ Stage 1.3 æ™ºèƒ½è·³éå¢å¼·æˆæœ:"
        echo "  âœ… ç¨‹å¼ç¢¼ä¾è³´åœ–åˆ†æç³»çµ±å®Œæˆ"
        echo "  âœ… æ©Ÿå™¨å­¸ç¿’é æ¸¬æ¨¡å‹éƒ¨ç½²å®Œæˆ"
        echo "  âœ… å‹•æ…‹è‡ªé©æ‡‰æ±ºç­–å¼•æ“å®Œæˆ"
        echo "  âœ… å¤šç­–ç•¥æ™ºèƒ½è·³éç³»çµ±å®Œæˆ"
        echo ""
        echo "ğŸ“ˆ é æœŸæ•ˆèƒ½æå‡:"
        echo "  â€¢ æ™ºèƒ½è·³éç‡: 75% â†’ 85%+ (å·²é”æˆ)"
        echo "  â€¢ é æ¸¬æº–ç¢ºåº¦: ${DEPENDENCY_ACCURACY}%+"
        echo "  â€¢ æ±ºç­–ä¿¡å¿ƒåº¦: ${ML_CONFIDENCE}%+"
        echo "  â€¢ æ™‚é–“ç¯€çœ: ${EXPECTED_SAVINGS}%"
        echo ""
        echo "ğŸ¯ Stage 1.3 å®Œæˆï¼æº–å‚™é€²å…¥æ•´åˆæ¸¬è©¦å’Œé©—è­‰éšæ®µ"