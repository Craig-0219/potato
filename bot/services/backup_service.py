# bot/services/backup_service.py - v1.0.0
# ğŸ“¦ è‡ªå‹•å‚™ä»½æœå‹™
# Automated Backup Service

import asyncio
import gzip
import json
import logging
import os
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional

from bot.db.pool import db_pool
from bot.services.data_management_service import data_management_service
from bot.utils.multi_tenant_security import secure_query_builder

logger = logging.getLogger(__name__)


class BackupService:
    """è‡ªå‹•å‚™ä»½æœå‹™"""

    def __init__(self):
        self.db = db_pool
        self.query_builder = secure_query_builder
        self.data_service = data_management_service
        self.backup_path = Path("backups")
        self.backup_path.mkdir(exist_ok=True)

        # å‚™ä»½è¨­å®š
        self.backup_config = {
            "daily_backups_retain": 7,  # ä¿ç•™ 7 å¤©çš„æ¯æ—¥å‚™ä»½
            "weekly_backups_retain": 4,  # ä¿ç•™ 4 é€±çš„é€±å‚™ä»½
            "monthly_backups_retain": 12,  # ä¿ç•™ 12 å€‹æœˆçš„æœˆå‚™ä»½
            "compression_enabled": True,
            "include_logs": False,  # é è¨­ä¸åŒ…å«æ—¥èªŒä»¥ç¯€çœç©ºé–“
        }

    async def start_backup_scheduler(self):
        """å•Ÿå‹•å‚™ä»½æ’ç¨‹å™¨"""
        logger.info("ğŸ“¦ å•Ÿå‹•è‡ªå‹•å‚™ä»½æœå‹™")

        async def backup_scheduler():
            while True:
                try:
                    now = datetime.now(timezone.utc)

                    # æ¯æ—¥å‚™ä»½ (æ¯å¤©å‡Œæ™¨ 2:00 UTC)
                    if now.hour == 2 and now.minute < 5:
                        await self.perform_daily_backup()

                        # é€±æ—¥åŸ·è¡Œé€±å‚™ä»½
                        if now.weekday() == 6:  # 0=é€±ä¸€, 6=é€±æ—¥
                            await self.perform_weekly_backup()

                        # æ¯æœˆ1æ—¥åŸ·è¡Œæœˆå‚™ä»½
                        if now.day == 1:
                            await self.perform_monthly_backup()

                    # æ¸…ç†éæœŸå‚™ä»½ (æ¯å¤©åŸ·è¡Œ)
                    if now.hour == 3 and now.minute < 5:
                        await self.cleanup_old_backups()

                    # æ¯5åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
                    await asyncio.sleep(300)

                except Exception as e:
                    logger.error(f"âŒ å‚™ä»½æ’ç¨‹å™¨éŒ¯èª¤: {e}")
                    await asyncio.sleep(60)  # éŒ¯èª¤æ™‚ç­‰å¾…1åˆ†é˜

        # åœ¨èƒŒæ™¯åŸ·è¡Œ
        asyncio.create_task(backup_scheduler())

    async def perform_daily_backup(self):
        """åŸ·è¡Œæ¯æ—¥å‚™ä»½"""
        try:
            logger.info("ğŸ—“ï¸ é–‹å§‹æ¯æ—¥å‚™ä»½")

            backup_time = datetime.now(timezone.utc)
            backup_name = f"daily_backup_{backup_time.strftime('%Y%m%d_%H%M%S')}"

            # ç²å–æ‰€æœ‰æ´»èºä¼ºæœå™¨
            guild_ids = await self._get_active_guilds()

            # åŸ·è¡Œå‚™ä»½
            backup_result = await self._backup_guild_data(guild_ids, backup_name, "daily")

            # è¨˜éŒ„å‚™ä»½çµæœ
            await self._log_backup_event(backup_name, "daily", backup_result)

            logger.info(f"âœ… æ¯æ—¥å‚™ä»½å®Œæˆ: {backup_name}")

        except Exception as e:
            logger.error(f"âŒ æ¯æ—¥å‚™ä»½å¤±æ•—: {e}")

    async def perform_weekly_backup(self):
        """åŸ·è¡Œé€±å‚™ä»½"""
        try:
            logger.info("ğŸ“… é–‹å§‹é€±å‚™ä»½")

            backup_time = datetime.now(timezone.utc)
            backup_name = f"weekly_backup_{backup_time.strftime('%Y_W%U')}"

            guild_ids = await self._get_active_guilds()
            backup_result = await self._backup_guild_data(guild_ids, backup_name, "weekly")

            await self._log_backup_event(backup_name, "weekly", backup_result)

            logger.info(f"âœ… é€±å‚™ä»½å®Œæˆ: {backup_name}")

        except Exception as e:
            logger.error(f"âŒ é€±å‚™ä»½å¤±æ•—: {e}")

    async def perform_monthly_backup(self):
        """åŸ·è¡Œæœˆå‚™ä»½"""
        try:
            logger.info("ğŸ“† é–‹å§‹æœˆå‚™ä»½")

            backup_time = datetime.now(timezone.utc)
            backup_name = f"monthly_backup_{backup_time.strftime('%Y_%m')}"

            guild_ids = await self._get_active_guilds()
            backup_result = await self._backup_guild_data(guild_ids, backup_name, "monthly")

            await self._log_backup_event(backup_name, "monthly", backup_result)

            logger.info(f"âœ… æœˆå‚™ä»½å®Œæˆ: {backup_name}")

        except Exception as e:
            logger.error(f"âŒ æœˆå‚™ä»½å¤±æ•—: {e}")

    async def _get_active_guilds(self) -> List[int]:
        """ç²å–æ´»èºä¼ºæœå™¨åˆ—è¡¨"""
        try:
            async with self.db.connection() as conn:
                async with conn.cursor() as cursor:
                    await cursor.execute(
                        """
                        SELECT guild_id FROM guild_info
                        WHERE status = 'active'
                    """
                    )
                    results = await cursor.fetchall()
                    return [row[0] for row in results]

        except Exception as e:
            logger.error(f"âŒ ç²å–æ´»èºä¼ºæœå™¨å¤±æ•—: {e}")
            return []

    async def _backup_guild_data(
        self, guild_ids: List[int], backup_name: str, backup_type: str
    ) -> Dict[str, Any]:
        """å‚™ä»½ä¼ºæœå™¨æ•¸æ“š"""
        try:
            backup_data = {
                "backup_info": {
                    "name": backup_name,
                    "type": backup_type,
                    "created_at": datetime.now(timezone.utc).isoformat(),
                    "guild_count": len(guild_ids),
                    "version": "3.0.1",
                },
                "guilds": {},
            }

            total_records = 0
            successful_guilds = 0

            # å‚™ä»½æ¯å€‹ä¼ºæœå™¨çš„æ•¸æ“š
            for guild_id in guild_ids:
                try:
                    guild_backup = await self._backup_single_guild(guild_id)
                    if guild_backup:
                        backup_data["guilds"][str(guild_id)] = guild_backup
                        total_records += guild_backup.get("record_count", 0)
                        successful_guilds += 1

                except Exception as e:
                    logger.error(f"âŒ å‚™ä»½ä¼ºæœå™¨ {guild_id} å¤±æ•—: {e}")
                    continue

            # å„²å­˜å‚™ä»½æª”æ¡ˆ
            backup_file = self.backup_path / f"{backup_name}.json"

            if self.backup_config["compression_enabled"]:
                backup_file = backup_file.with_suffix(".json.gz")
                with gzip.open(backup_file, "wt", encoding="utf-8") as f:
                    json.dump(backup_data, f, indent=2, ensure_ascii=False, default=str)
            else:
                with open(backup_file, "w", encoding="utf-8") as f:
                    json.dump(backup_data, f, indent=2, ensure_ascii=False, default=str)

            # è¨ˆç®—æª”æ¡ˆå¤§å°
            file_size_mb = backup_file.stat().st_size / 1024 / 1024

            backup_result = {
                "backup_name": backup_name,
                "backup_type": backup_type,
                "file_path": str(backup_file),
                "file_size_mb": round(file_size_mb, 2),
                "total_guilds": len(guild_ids),
                "successful_guilds": successful_guilds,
                "total_records": total_records,
                "compressed": self.backup_config["compression_enabled"],
            }

            logger.info(f"ğŸ“¦ å‚™ä»½æª”æ¡ˆå·²å»ºç«‹: {backup_file} ({file_size_mb:.1f}MB)")
            return backup_result

        except Exception as e:
            logger.error(f"âŒ å‚™ä»½ä¼ºæœå™¨æ•¸æ“šå¤±æ•—: {e}")
            return {}

    async def _backup_single_guild(self, guild_id: int) -> Optional[Dict[str, Any]]:
        """å‚™ä»½å–®ä¸€ä¼ºæœå™¨æ•¸æ“š"""
        try:
            guild_data = {
                "guild_id": guild_id,
                "backup_time": datetime.now(timezone.utc).isoformat(),
                "tables": {},
                "record_count": 0,
            }

            # è¦å‚™ä»½çš„è¡¨æ ¼åˆ—è¡¨ (ä¸åŒ…å«æ•æ„Ÿæ•¸æ“š)
            backup_tables = [
                "guild_info",
                "guild_settings",
                "guild_quotas",
                "guild_statistics",
                "tickets",
                "ticket_settings",
                "votes",
                "vote_settings",
                "workflows",
                "welcome_settings",
            ]

            async with self.db.connection() as conn:
                async with conn.cursor() as cursor:
                    for table in backup_tables:
                        try:
                            # æª¢æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
                            await cursor.execute(f"SHOW TABLES LIKE '{table}'")
                            if not await cursor.fetchone():
                                continue

                            # æª¢æŸ¥æ˜¯å¦æœ‰ guild_id æ¬„ä½
                            await cursor.execute(f"SHOW COLUMNS FROM {table} LIKE 'guild_id'")
                            has_guild_id = await cursor.fetchone() is not None

                            if has_guild_id:
                                # æœ‰ guild_id çš„è¡¨æ ¼ï¼Œä½¿ç”¨å®‰å…¨æŸ¥è©¢
                                query, params = self.query_builder.build_select(
                                    table=table, guild_id=guild_id
                                )
                                await cursor.execute(query, params)
                            else:
                                # æ²’æœ‰ guild_id çš„è¡¨æ ¼ï¼Œè·³éæˆ–ä½¿ç”¨å…¶ä»–æ¢ä»¶
                                continue

                            results = await cursor.fetchall()
                            if results:
                                # è½‰æ›ç‚ºå­—å…¸æ ¼å¼
                                columns = [desc[0] for desc in cursor.description]
                                table_data = [dict(zip(columns, row)) for row in results]

                                guild_data["tables"][table] = table_data
                                guild_data["record_count"] += len(table_data)

                        except Exception as e:
                            logger.warning(f"âš ï¸ å‚™ä»½è¡¨æ ¼ {table} è·³é: {e}")
                            continue

            return guild_data if guild_data["record_count"] > 0 else None

        except Exception as e:
            logger.error(f"âŒ å‚™ä»½ä¼ºæœå™¨ {guild_id} å¤±æ•—: {e}")
            return None

    async def cleanup_old_backups(self):
        """æ¸…ç†éæœŸå‚™ä»½"""
        try:
            logger.info("ğŸ§¹ é–‹å§‹æ¸…ç†éæœŸå‚™ä»½")

            current_time = datetime.now(timezone.utc)
            cleaned_files = 0

            for backup_file in self.backup_path.glob("*.json*"):
                try:
                    # è§£ææª”æ¡ˆåç¨±ç¢ºå®šå‚™ä»½é¡å‹å’Œæ™‚é–“
                    file_age = current_time - datetime.fromtimestamp(
                        backup_file.stat().st_mtime, tz=timezone.utc
                    )

                    should_delete = False

                    if "daily_backup" in backup_file.name:
                        if file_age.days > self.backup_config["daily_backups_retain"]:
                            should_delete = True
                    elif "weekly_backup" in backup_file.name:
                        if file_age.days > (self.backup_config["weekly_backups_retain"] * 7):
                            should_delete = True
                    elif "monthly_backup" in backup_file.name:
                        if file_age.days > (self.backup_config["monthly_backups_retain"] * 30):
                            should_delete = True

                    if should_delete:
                        backup_file.unlink()
                        cleaned_files += 1
                        logger.info(f"ğŸ—‘ï¸ å·²åˆªé™¤éæœŸå‚™ä»½: {backup_file.name}")

                except Exception as e:
                    logger.warning(f"âš ï¸ æ¸…ç†å‚™ä»½æª”æ¡ˆ {backup_file.name} å¤±æ•—: {e}")
                    continue

            if cleaned_files > 0:
                logger.info(f"âœ… æ¸…ç†å®Œæˆï¼Œå…±åˆªé™¤ {cleaned_files} å€‹éæœŸå‚™ä»½æª”æ¡ˆ")
            else:
                logger.info("âœ… æ²’æœ‰éœ€è¦æ¸…ç†çš„éæœŸå‚™ä»½")

        except Exception as e:
            logger.error(f"âŒ æ¸…ç†éæœŸå‚™ä»½å¤±æ•—: {e}")

    async def _log_backup_event(
        self, backup_name: str, backup_type: str, backup_result: Dict[str, Any]
    ):
        """è¨˜éŒ„å‚™ä»½äº‹ä»¶"""
        try:
            event_data = {
                "guild_id": None,  # ç³»çµ±äº‹ä»¶
                "user_id": None,
                "event_type": "backup_completed",
                "event_category": "system",
                "event_name": f"{backup_type.title()} Backup",
                "description": f"è‡ªå‹•å‚™ä»½å®Œæˆ: {backup_name}",
                "metadata": json.dumps(backup_result),
                "source": "backup_service",
                "status": "success" if backup_result else "failed",
            }

            columns = ", ".join(event_data.keys())
            placeholders = ", ".join(["%s"] * len(event_data))

            async with self.db.connection() as conn:
                async with conn.cursor() as cursor:
                    await cursor.execute(
                        f"""
                        INSERT INTO guild_event_logs ({columns})
                        VALUES ({placeholders})
                    """,
                        list(event_data.values()),
                    )
                    await conn.commit()

        except Exception as e:
            logger.warning(f"âš ï¸ è¨˜éŒ„å‚™ä»½äº‹ä»¶å¤±æ•—: {e}")

    async def restore_from_backup(
        self, backup_file_path: str, guild_id: Optional[int] = None
    ) -> bool:
        """å¾å‚™ä»½é‚„åŸæ•¸æ“š (æ‰‹å‹•æ“ä½œç”¨)"""
        try:
            logger.info(f"ğŸ“‚ é–‹å§‹å¾å‚™ä»½é‚„åŸ: {backup_file_path}")

            # è®€å–å‚™ä»½æª”æ¡ˆ
            backup_path = Path(backup_file_path)
            if not backup_path.exists():
                logger.error(f"âŒ å‚™ä»½æª”æ¡ˆä¸å­˜åœ¨: {backup_file_path}")
                return False

            # æ ¹æ“šå‰¯æª”åæ±ºå®šå¦‚ä½•è®€å–
            if backup_path.suffix == ".gz":
                with gzip.open(backup_path, "rt", encoding="utf-8") as f:
                    backup_data = json.load(f)
            else:
                with open(backup_path, "r", encoding="utf-8") as f:
                    backup_data = json.load(f)

            # é‚„åŸæŒ‡å®šä¼ºæœå™¨æˆ–æ‰€æœ‰ä¼ºæœå™¨
            guilds_to_restore = [str(guild_id)] if guild_id else backup_data["guilds"].keys()

            for guild_id_str in guilds_to_restore:
                if guild_id_str in backup_data["guilds"]:
                    await self._restore_single_guild(
                        int(guild_id_str), backup_data["guilds"][guild_id_str]
                    )

            logger.info("âœ… å‚™ä»½é‚„åŸå®Œæˆ")
            return True

        except Exception as e:
            logger.error(f"âŒ å‚™ä»½é‚„åŸå¤±æ•—: {e}")
            return False

    async def _restore_single_guild(self, guild_id: int, guild_data: Dict[str, Any]):
        """é‚„åŸå–®ä¸€ä¼ºæœå™¨æ•¸æ“š (è¬¹æ…ä½¿ç”¨)"""
        try:
            logger.info(f"ğŸ“‹ é‚„åŸä¼ºæœå™¨ {guild_id} çš„æ•¸æ“š")

            async with self.db.connection() as conn:
                async with conn.cursor() as cursor:
                    for table_name, records in guild_data["tables"].items():
                        if not records:
                            continue

                        try:
                            # æ¸…ç©ºç¾æœ‰æ•¸æ“š (å±éšªæ“ä½œï¼)
                            await cursor.execute(
                                f"""
                                DELETE FROM {table_name} WHERE guild_id = %s
                            """,
                                (guild_id,),
                            )

                            # æ’å…¥å‚™ä»½æ•¸æ“š
                            for record in records:
                                columns = ", ".join(record.keys())
                                placeholders = ", ".join(["%s"] * len(record))

                                await cursor.execute(
                                    f"""
                                    INSERT INTO {table_name} ({columns})
                                    VALUES ({placeholders})
                                """,
                                    list(record.values()),
                                )

                            logger.info(f"âœ… é‚„åŸè¡¨æ ¼ {table_name}: {len(records)} ç­†è¨˜éŒ„")

                        except Exception as e:
                            logger.error(f"âŒ é‚„åŸè¡¨æ ¼ {table_name} å¤±æ•—: {e}")
                            continue

                    await conn.commit()

            logger.info(f"âœ… ä¼ºæœå™¨ {guild_id} æ•¸æ“šé‚„åŸå®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ é‚„åŸä¼ºæœå™¨ {guild_id} å¤±æ•—: {e}")


# å…¨åŸŸå¯¦ä¾‹
backup_service = BackupService()
