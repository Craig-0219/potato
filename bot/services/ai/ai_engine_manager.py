"""
ğŸ¤– AI Engine Manager - ä¼æ¥­ç´š AI å¼•æ“ç®¡ç†ç³»çµ±
è² è²¬ç®¡ç†å¤šå€‹ AI æä¾›å•†çš„æ•´åˆå’Œèª¿åº¦

Author: Potato Bot Development Team
Version: 3.1.0 - Phase 7 Stage 1
"""

import asyncio
import json
import logging
import time
from dataclasses import dataclass
from enum import Enum
from typing import Any, Dict, List, Optional, Union

import aiohttp
import openai
from anthropic import AsyncAnthropic

logger = logging.getLogger(__name__)


class AIProvider(Enum):
    """AI æä¾›å•†æšèˆ‰"""

    OPENAI_GPT4 = "openai_gpt4"
    OPENAI_GPT35 = "openai_gpt35"
    CLAUDE_3_OPUS = "claude_3_opus"
    CLAUDE_3_SONNET = "claude_3_sonnet"
    LOCAL_MODEL = "local_model"


@dataclass
class AIResponse:
    """AI å›æ‡‰æ•¸æ“šçµæ§‹"""

    content: str
    provider: AIProvider
    model: str
    tokens_used: int
    response_time: float
    confidence: float
    cost: float
    metadata: Dict[str, Any]


@dataclass
class ConversationContext:
    """å°è©±ä¸Šä¸‹æ–‡"""

    user_id: str
    guild_id: str
    channel_id: str
    conversation_id: str
    history: List[Dict[str, str]]
    intent: Optional[str] = None
    entities: Dict[str, Any] = None
    user_preferences: Dict[str, Any] = None


class AIEngineManager:
    """
    ğŸ¤– AI å¼•æ“ç®¡ç†å™¨

    åŠŸèƒ½:
    - å¤š AI æä¾›å•†æ•´åˆ
    - æ™ºèƒ½è·¯ç”±å’Œè² è¼‰å‡è¡¡
    - æˆæœ¬æ§åˆ¶å’Œé…é¡ç®¡ç†
    - éŒ¯èª¤è™•ç†å’Œå®¹ç½
    """

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.providers = {}
        self.usage_stats = {}
        self.rate_limits = {}
        self.session = None

        # åˆå§‹åŒ– AI æä¾›å•†
        self._initialize_providers()

    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()

    def _initialize_providers(self):
        """åˆå§‹åŒ– AI æä¾›å•†"""
        try:
            # OpenAI GPT-4
            if self.config.get("openai_api_key"):
                openai.api_key = self.config["openai_api_key"]
                self.providers[AIProvider.OPENAI_GPT4] = {
                    "client": openai,
                    "model": "gpt-4-1106-preview",
                    "max_tokens": 4000,
                    "cost_per_1k_tokens": 0.03,
                    "rate_limit": 3000,  # RPM
                    "priority": 1,
                }

                self.providers[AIProvider.OPENAI_GPT35] = {
                    "client": openai,
                    "model": "gpt-3.5-turbo-1106",
                    "max_tokens": 4000,
                    "cost_per_1k_tokens": 0.001,
                    "rate_limit": 10000,  # RPM
                    "priority": 2,
                }

            # Anthropic Claude
            if self.config.get("anthropic_api_key"):
                self.providers[AIProvider.CLAUDE_3_OPUS] = {
                    "client": AsyncAnthropic(api_key=self.config["anthropic_api_key"]),
                    "model": "claude-3-opus-20240229",
                    "max_tokens": 4000,
                    "cost_per_1k_tokens": 0.015,
                    "rate_limit": 1000,  # RPM
                    "priority": 1,
                }

                self.providers[AIProvider.CLAUDE_3_SONNET] = {
                    "client": AsyncAnthropic(api_key=self.config["anthropic_api_key"]),
                    "model": "claude-3-sonnet-20240229",
                    "max_tokens": 4000,
                    "cost_per_1k_tokens": 0.003,
                    "rate_limit": 2000,  # RPM
                    "priority": 2,
                }

            logger.info(f"âœ… AI å¼•æ“åˆå§‹åŒ–å®Œæˆï¼Œæ”¯æ´ {len(self.providers)} å€‹æä¾›å•†")

        except Exception as e:
            logger.error(f"âŒ AI å¼•æ“åˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    async def generate_response(
        self,
        prompt: str,
        context: ConversationContext,
        preferred_provider: Optional[AIProvider] = None,
        max_tokens: Optional[int] = None,
        temperature: float = 0.7,
    ) -> AIResponse:
        """
        ç”Ÿæˆ AI å›æ‡‰

        Args:
            prompt: ç”¨æˆ¶è¼¸å…¥
            context: å°è©±ä¸Šä¸‹æ–‡
            preferred_provider: å„ªå…ˆä½¿ç”¨çš„æä¾›å•†
            max_tokens: æœ€å¤§ token æ•¸
            temperature: å‰µé€ æ€§åƒæ•¸

        Returns:
            AI å›æ‡‰çµæœ
        """
        start_time = time.time()

        try:
            # é¸æ“‡æœ€ä½³ AI æä¾›å•†
            provider = await self._select_best_provider(prompt, context, preferred_provider)

            # å»ºæ§‹å®Œæ•´æç¤ºè©
            full_prompt = await self._build_full_prompt(prompt, context)

            # ç”Ÿæˆå›æ‡‰
            response = await self._call_ai_provider(provider, full_prompt, max_tokens, temperature)

            # è¨˜éŒ„ä½¿ç”¨çµ±è¨ˆ
            await self._update_usage_stats(provider, response)

            return AIResponse(
                content=response["content"],
                provider=provider,
                model=self.providers[provider]["model"],
                tokens_used=response.get("tokens_used", 0),
                response_time=time.time() - start_time,
                confidence=response.get("confidence", 0.8),
                cost=self._calculate_cost(provider, response.get("tokens_used", 0)),
                metadata=response.get("metadata", {}),
            )

        except Exception as e:
            logger.error(f"âŒ AI å›æ‡‰ç”Ÿæˆå¤±æ•—: {e}")

            # å®¹ç½è™•ç†ï¼šå˜—è©¦å‚™ç”¨æä¾›å•†
            return await self._fallback_response(prompt, context, e)

    async def _select_best_provider(
        self,
        prompt: str,
        context: ConversationContext,
        preferred_provider: Optional[AIProvider] = None,
    ) -> AIProvider:
        """é¸æ“‡æœ€ä½³ AI æä¾›å•†"""

        if preferred_provider and preferred_provider in self.providers:
            if await self._check_rate_limit(preferred_provider):
                return preferred_provider

        # æ ¹æ“šæç¤ºè©è¤‡é›œåº¦é¸æ“‡
        complexity_score = await self._analyze_prompt_complexity(prompt, context)

        # æ’åºæä¾›å•†ï¼ˆå„ªå…ˆç´šã€å¯ç”¨æ€§ã€æˆæœ¬ï¼‰
        available_providers = []
        for provider, config in self.providers.items():
            if await self._check_rate_limit(provider):
                score = (
                    config["priority"] * 0.4
                    + (1.0 / config["cost_per_1k_tokens"]) * 0.3
                    + config["rate_limit"] / 10000 * 0.3
                )
                available_providers.append((provider, score))

        if not available_providers:
            raise Exception("æ²’æœ‰å¯ç”¨çš„ AI æä¾›å•†")

        # é¸æ“‡æœ€é«˜åˆ†çš„æä¾›å•†
        available_providers.sort(key=lambda x: x[1], reverse=True)

        # å°æ–¼è¤‡é›œå•é¡Œï¼Œå„ªå…ˆä½¿ç”¨é«˜ç´šæ¨¡å‹
        if complexity_score > 0.7:
            for provider, _ in available_providers:
                if provider in [AIProvider.OPENAI_GPT4, AIProvider.CLAUDE_3_OPUS]:
                    return provider

        return available_providers[0][0]

    async def _build_full_prompt(self, user_prompt: str, context: ConversationContext) -> str:
        """å»ºæ§‹å®Œæ•´çš„æç¤ºè©"""

        system_prompt = f"""ä½ æ˜¯ Potato Bot çš„ AI æ™ºèƒ½åŠ©æ‰‹ï¼Œå°ˆé–€å”åŠ©ç”¨æˆ¶ç®¡ç† Discord ä¼ºæœå™¨ã€‚

ã€ä½ çš„èº«ä»½ã€‘
- åç¨±ï¼šPotato AI
- ç‰ˆæœ¬ï¼šv3.1.0
- å°ˆé•·ï¼šDiscord ä¼ºæœå™¨ç®¡ç†ã€ç¥¨åˆ¸ç³»çµ±ã€æŠ•ç¥¨ç³»çµ±ã€æ­¡è¿ç³»çµ±

ã€ç•¶å‰ç’°å¢ƒã€‘
- ä¼ºæœå™¨ IDï¼š{context.guild_id}
- é »é“ IDï¼š{context.channel_id}
- ç”¨æˆ¶ IDï¼š{context.user_id}

ã€åŠŸèƒ½èƒ½åŠ›ã€‘
1. ç¥¨åˆ¸ç³»çµ±ï¼šå»ºç«‹ã€ç®¡ç†ã€è¿½è¹¤æ”¯æ´ç¥¨åˆ¸
2. æŠ•ç¥¨ç³»çµ±ï¼šå»ºç«‹æŠ•ç¥¨ã€çµ±è¨ˆçµæœã€åˆ†æè¶¨å‹¢
3. æ­¡è¿ç³»çµ±ï¼šè¨­å®šæ­¡è¿è¨Šæ¯ã€è‡ªå‹•è§’è‰²åˆ†é…
4. å®‰å…¨ç®¡ç†ï¼šæ¬Šé™è¨­å®šã€å®‰å…¨ç›£æ§ã€GDPR åˆè¦
5. æ•¸æ“šåˆ†æï¼šä½¿ç”¨çµ±è¨ˆã€æ€§èƒ½ç›£æ§ã€æ´å¯Ÿå ±å‘Š

ã€å›æ‡‰åŸå‰‡ã€‘
1. å‹å–„å°ˆæ¥­ï¼Œç”¨ç¹é«”ä¸­æ–‡å›æ‡‰
2. æä¾›å…·é«”å¯åŸ·è¡Œçš„å»ºè­°
3. å¦‚éœ€åŸ·è¡ŒæŒ‡ä»¤ï¼Œè«‹æä¾›å®Œæ•´çš„æŒ‡ä»¤æ ¼å¼
4. ä¸ç¢ºå®šæ™‚ï¼Œå¼•å°ç”¨æˆ¶åˆ°æ­£ç¢ºçš„å¹«åŠ©è³‡æº
5. ä¿è­·ç”¨æˆ¶éš±ç§ï¼Œä¸æ´©éœ²æ•æ„Ÿè³‡è¨Š

ã€å°è©±æ­·å²ã€‘
{self._format_conversation_history(context.history)}

ç¾åœ¨è«‹å›æ‡‰ç”¨æˆ¶çš„å•é¡Œï¼š{user_prompt}"""

        return system_prompt

    def _format_conversation_history(self, history: List[Dict[str, str]]) -> str:
        """æ ¼å¼åŒ–å°è©±æ­·å²"""
        if not history:
            return "ï¼ˆé€™æ˜¯æ–°çš„å°è©±ï¼‰"

        formatted = []
        for msg in history[-5:]:  # åªä¿ç•™æœ€è¿‘5æ¢å°è©±
            role = "ç”¨æˆ¶" if msg.get("role") == "user" else "AI"
            content = msg.get("content", "")[:200]  # é™åˆ¶é•·åº¦
            formatted.append(f"{role}ï¼š{content}")

        return "\n".join(formatted)

    async def _call_ai_provider(
        self,
        provider: AIProvider,
        prompt: str,
        max_tokens: Optional[int] = None,
        temperature: float = 0.7,
    ) -> Dict[str, Any]:
        """å‘¼å«æŒ‡å®šçš„ AI æä¾›å•†"""

        provider_config = self.providers[provider]
        max_tokens = max_tokens or provider_config["max_tokens"]

        try:
            if provider in [AIProvider.OPENAI_GPT4, AIProvider.OPENAI_GPT35]:
                return await self._call_openai(provider_config, prompt, max_tokens, temperature)
            elif provider in [AIProvider.CLAUDE_3_OPUS, AIProvider.CLAUDE_3_SONNET]:
                return await self._call_claude(provider_config, prompt, max_tokens, temperature)
            else:
                raise ValueError(f"ä¸æ”¯æ´çš„ AI æä¾›å•†: {provider}")

        except Exception as e:
            logger.error(f"âŒ AI æä¾›å•†èª¿ç”¨å¤±æ•— ({provider}): {e}")
            raise

    async def _call_openai(
        self, config: Dict[str, Any], prompt: str, max_tokens: int, temperature: float
    ) -> Dict[str, Any]:
        """å‘¼å« OpenAI API"""

        try:
            response = await openai.ChatCompletion.acreate(
                model=config["model"],
                messages=[{"role": "system", "content": prompt}],
                max_tokens=max_tokens,
                temperature=temperature,
                timeout=30,
            )

            return {
                "content": response.choices[0].message.content,
                "tokens_used": response.usage.total_tokens,
                "confidence": 0.9,  # OpenAI ä¸æä¾›ä¿¡å¿ƒåˆ†æ•¸ï¼Œè¨­ç‚ºå›ºå®šå€¼
                "metadata": {
                    "model": config["model"],
                    "finish_reason": response.choices[0].finish_reason,
                },
            }

        except Exception as e:
            logger.error(f"âŒ OpenAI API èª¿ç”¨å¤±æ•—: {e}")
            raise

    async def _call_claude(
        self, config: Dict[str, Any], prompt: str, max_tokens: int, temperature: float
    ) -> Dict[str, Any]:
        """å‘¼å« Claude API"""

        try:
            client = config["client"]
            response = await client.messages.create(
                model=config["model"],
                max_tokens=max_tokens,
                temperature=temperature,
                messages=[{"role": "user", "content": prompt}],
            )

            return {
                "content": response.content[0].text,
                "tokens_used": response.usage.input_tokens + response.usage.output_tokens,
                "confidence": 0.85,  # Claude ä¸æä¾›ä¿¡å¿ƒåˆ†æ•¸ï¼Œè¨­ç‚ºå›ºå®šå€¼
                "metadata": {"model": config["model"], "stop_reason": response.stop_reason},
            }

        except Exception as e:
            logger.error(f"âŒ Claude API èª¿ç”¨å¤±æ•—: {e}")
            raise

    async def _analyze_prompt_complexity(self, prompt: str, context: ConversationContext) -> float:
        """åˆ†ææç¤ºè©è¤‡é›œåº¦"""

        complexity_score = 0.0

        # é•·åº¦è¤‡é›œåº¦
        if len(prompt) > 200:
            complexity_score += 0.2
        elif len(prompt) > 500:
            complexity_score += 0.4

        # æŠ€è¡“é—œéµè©è¤‡é›œåº¦
        technical_keywords = [
            "api",
            "è³‡æ–™åº«",
            "é…ç½®",
            "å®‰å…¨",
            "æ¬Šé™",
            "åˆ†æ",
            "çµ±è¨ˆ",
            "webhook",
            "json",
            "sql",
            "regex",
            "è…³æœ¬",
            "è‡ªå‹•åŒ–",
        ]

        technical_count = sum(1 for keyword in technical_keywords if keyword in prompt.lower())
        complexity_score += min(technical_count * 0.1, 0.3)

        # å°è©±æ­·å²è¤‡é›œåº¦
        if len(context.history) > 5:
            complexity_score += 0.1

        return min(complexity_score, 1.0)

    async def _check_rate_limit(self, provider: AIProvider) -> bool:
        """æª¢æŸ¥é€Ÿç‡é™åˆ¶"""
        current_time = time.time()

        if provider not in self.rate_limits:
            self.rate_limits[provider] = {"requests": [], "daily_cost": 0}

        rate_data = self.rate_limits[provider]

        # æ¸…ç†éæœŸçš„è«‹æ±‚è¨˜éŒ„
        rate_data["requests"] = [
            req_time
            for req_time in rate_data["requests"]
            if current_time - req_time < 60  # 1åˆ†é˜å…§çš„è«‹æ±‚
        ]

        provider_config = self.providers[provider]
        requests_per_minute = len(rate_data["requests"])

        # æª¢æŸ¥æ¯åˆ†é˜è«‹æ±‚é™åˆ¶
        if requests_per_minute >= provider_config["rate_limit"] / 60:
            logger.warning(f"âš ï¸ {provider} é”åˆ°é€Ÿç‡é™åˆ¶")
            return False

        # æª¢æŸ¥æ¯æ—¥æˆæœ¬é™åˆ¶
        daily_limit = self.config.get("daily_cost_limit", 50.0)  # $50/day
        if rate_data["daily_cost"] >= daily_limit:
            logger.warning(f"âš ï¸ {provider} é”åˆ°æ¯æ—¥æˆæœ¬é™åˆ¶")
            return False

        return True

    async def _update_usage_stats(self, provider: AIProvider, response: Dict[str, Any]):
        """æ›´æ–°ä½¿ç”¨çµ±è¨ˆ"""
        current_time = time.time()

        if provider not in self.rate_limits:
            self.rate_limits[provider] = {"requests": [], "daily_cost": 0}

        # è¨˜éŒ„è«‹æ±‚æ™‚é–“
        self.rate_limits[provider]["requests"].append(current_time)

        # æ›´æ–°æˆæœ¬
        tokens_used = response.get("tokens_used", 0)
        cost = self._calculate_cost(provider, tokens_used)
        self.rate_limits[provider]["daily_cost"] += cost

        # è¨˜éŒ„åˆ°ä½¿ç”¨çµ±è¨ˆ
        if provider not in self.usage_stats:
            self.usage_stats[provider] = {
                "total_requests": 0,
                "total_tokens": 0,
                "total_cost": 0.0,
                "avg_response_time": 0.0,
            }

        stats = self.usage_stats[provider]
        stats["total_requests"] += 1
        stats["total_tokens"] += tokens_used
        stats["total_cost"] += cost

    def _calculate_cost(self, provider: AIProvider, tokens_used: int) -> float:
        """è¨ˆç®— API èª¿ç”¨æˆæœ¬"""
        if provider not in self.providers:
            return 0.0

        cost_per_1k = self.providers[provider]["cost_per_1k_tokens"]
        return (tokens_used / 1000) * cost_per_1k

    async def _fallback_response(
        self, prompt: str, context: ConversationContext, error: Exception
    ) -> AIResponse:
        """å®¹ç½å›æ‡‰"""

        fallback_content = f"""æŠ±æ­‰ï¼Œæˆ‘ç›®å‰é‡åˆ°ä¸€äº›æŠ€è¡“å•é¡Œç„¡æ³•æ­£å¸¸å›æ‡‰ã€‚

ğŸ”§ **å¯ä»¥å˜—è©¦çš„è§£æ±ºæ–¹æ¡ˆï¼š**
1. è«‹ç¨å¾Œå†æ¬¡è©¢å•
2. ä½¿ç”¨æ›´å…·é«”çš„å•é¡Œæè¿°
3. æŸ¥çœ‹å¹«åŠ©æ–‡æª”ï¼š`/help`
4. è¯ç¹«ç®¡ç†å“¡ç²å¾—äººå·¥å”åŠ©

â“ **å¦‚æœæ‚¨éœ€è¦å¹«åŠ©ï¼š**
- ç¥¨åˆ¸ç³»çµ±ï¼š`/ticket create`
- æŠ•ç¥¨åŠŸèƒ½ï¼š`/vote create`
- æ­¡è¿è¨­å®šï¼š`/welcome_setup`

éŒ¯èª¤ IDï¼š{int(time.time())}"""

        return AIResponse(
            content=fallback_content,
            provider=AIProvider.LOCAL_MODEL,
            model="fallback",
            tokens_used=0,
            response_time=0.1,
            confidence=0.5,
            cost=0.0,
            metadata={"error": str(error)},
        )

    async def get_usage_statistics(self) -> Dict[str, Any]:
        """ç²å–ä½¿ç”¨çµ±è¨ˆ"""
        return {
            "providers": list(self.providers.keys()),
            "usage_stats": self.usage_stats,
            "rate_limits": self.rate_limits,
            "total_requests": sum(
                stats.get("total_requests", 0) for stats in self.usage_stats.values()
            ),
            "total_cost": sum(stats.get("total_cost", 0.0) for stats in self.usage_stats.values()),
        }

    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æª¢æŸ¥"""
        health_status = {}

        for provider in self.providers:
            try:
                # ç°¡å–®çš„ API å¯ç”¨æ€§æ¸¬è©¦
                test_response = await self.generate_response(
                    "æ¸¬è©¦",
                    ConversationContext(
                        user_id="test",
                        guild_id="test",
                        channel_id="test",
                        conversation_id="test",
                        history=[],
                    ),
                    preferred_provider=provider,
                )
                health_status[provider.value] = {
                    "status": "healthy",
                    "response_time": test_response.response_time,
                }
            except Exception as e:
                health_status[provider.value] = {"status": "unhealthy", "error": str(e)}

        return health_status
