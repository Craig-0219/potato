# bot/services/security_audit_manager.py - ä¼æ¥­ç´šå®‰å…¨å¯©è¨ˆç®¡ç†å™¨ v1.7.0
"""
ä¼æ¥­ç´šå®‰å…¨å¯©è¨ˆç®¡ç†å™¨
æä¾›å…¨é¢çš„å®‰å…¨ç›£æ§ã€å¯©è¨ˆæ—¥èªŒã€æ¬Šé™ç®¡ç†å’Œåˆè¦å ±å‘ŠåŠŸèƒ½
"""

import asyncio
import json
import hashlib
import uuid
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Any, Set, Tuple
from enum import Enum
from dataclasses import dataclass, asdict
import ipaddress
from cryptography.fernet import Fernet
import re

from shared.logger import logger

class SecurityEventType(Enum):
    """å®‰å…¨äº‹ä»¶é¡å‹"""
    LOGIN_SUCCESS = "login_success"
    LOGIN_FAILURE = "login_failure" 
    PERMISSION_DENIED = "permission_denied"
    DATA_ACCESS = "data_access"
    DATA_MODIFICATION = "data_modification"
    SYSTEM_CONFIGURATION = "system_configuration"
    USER_MANAGEMENT = "user_management"
    ROLE_ASSIGNMENT = "role_assignment"
    SUSPICIOUS_ACTIVITY = "suspicious_activity"
    SECURITY_VIOLATION = "security_violation"
    COMMAND_EXECUTION = "command_execution"
    FILE_ACCESS = "file_access"
    DATABASE_QUERY = "database_query"
    API_CALL = "api_call"

class RiskLevel(Enum):
    """é¢¨éšªç­‰ç´š"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class AuditAction(Enum):
    """å¯©è¨ˆå‹•ä½œé¡å‹"""
    CREATE = "create"
    READ = "read"
    UPDATE = "update"
    DELETE = "delete"
    EXECUTE = "execute"
    ACCESS = "access"
    EXPORT = "export"
    IMPORT = "import"

class ComplianceStandard(Enum):
    """åˆè¦æ¨™æº–"""
    GDPR = "gdpr"
    HIPAA = "hipaa"
    SOX = "sox"
    ISO27001 = "iso27001"
    PCI_DSS = "pci_dss"

@dataclass
class SecurityEvent:
    """å®‰å…¨äº‹ä»¶æ•¸æ“šé¡"""
    id: str
    event_type: SecurityEventType
    timestamp: datetime
    user_id: int
    guild_id: Optional[int]
    risk_level: RiskLevel
    action: AuditAction
    resource: str
    details: Dict[str, Any]
    ip_address: Optional[str] = None
    user_agent: Optional[str] = None
    session_id: Optional[str] = None
    correlation_id: Optional[str] = None

@dataclass
class SecurityRule:
    """å®‰å…¨è¦å‰‡æ•¸æ“šé¡"""
    id: str
    name: str
    description: str
    rule_type: str
    conditions: Dict[str, Any]
    actions: List[Dict[str, Any]]
    enabled: bool
    severity: RiskLevel
    created_at: datetime
    created_by: int

@dataclass
class ComplianceReport:
    """åˆè¦å ±å‘Šæ•¸æ“šé¡"""
    id: str
    standard: ComplianceStandard
    period_start: datetime
    period_end: datetime
    guild_id: int
    generated_by: int
    generated_at: datetime
    summary: Dict[str, Any]
    violations: List[Dict[str, Any]]
    recommendations: List[str]

class SecurityAuditManager:
    """ä¼æ¥­ç´šå®‰å…¨å¯©è¨ˆç®¡ç†å™¨"""
    
    def __init__(self):
        self.active_sessions: Dict[str, Dict[str, Any]] = {}
        self.security_rules: Dict[str, SecurityRule] = {}
        self.event_buffer: List[SecurityEvent] = []
        self.encryption_key = self._generate_encryption_key()
        self.cipher_suite = Fernet(self.encryption_key)
        self.suspicious_activity_cache: Dict[str, List[datetime]] = {}
        self.rate_limits: Dict[str, Dict[str, datetime]] = {}
        
        # é è¨­å®‰å…¨è¦å‰‡
        self._initialize_default_rules()
        logger.info("âœ… ä¼æ¥­ç´šå®‰å…¨å¯©è¨ˆç®¡ç†å™¨å·²åˆå§‹åŒ–")
    
    def _generate_encryption_key(self) -> bytes:
        """ç”ŸæˆåŠ å¯†å¯†é‘°"""
        # åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ï¼Œé€™æ‡‰è©²å¾å®‰å…¨çš„å¯†é‘°ç®¡ç†æœå‹™ç²å–
        return Fernet.generate_key()
    
    def _initialize_default_rules(self):
        """åˆå§‹åŒ–é è¨­å®‰å…¨è¦å‰‡"""
        default_rules = [
            {
                'id': 'failed_login_detection',
                'name': 'ç™»å…¥å¤±æ•—æª¢æ¸¬',
                'description': 'æª¢æ¸¬é€£çºŒç™»å…¥å¤±æ•—å˜—è©¦',
                'rule_type': 'threshold',
                'conditions': {
                    'event_type': 'login_failure',
                    'threshold': 5,
                    'time_window': 300,  # 5åˆ†é˜
                },
                'actions': [
                    {'type': 'alert', 'severity': 'high'},
                    {'type': 'temporary_ban', 'duration': 1800}  # 30åˆ†é˜
                ],
                'severity': RiskLevel.HIGH
            },
            {
                'id': 'privilege_escalation_detection',
                'name': 'æ¬Šé™æå‡æª¢æ¸¬',
                'description': 'æª¢æ¸¬ç•°å¸¸æ¬Šé™è®Šæ›´',
                'rule_type': 'anomaly',
                'conditions': {
                    'event_type': 'role_assignment',
                    'check_elevation': True
                },
                'actions': [
                    {'type': 'alert', 'severity': 'critical'},
                    {'type': 'require_approval'}
                ],
                'severity': RiskLevel.CRITICAL
            },
            {
                'id': 'data_export_monitoring',
                'name': 'è³‡æ–™åŒ¯å‡ºç›£æ§',
                'description': 'ç›£æ§å¤§é‡è³‡æ–™åŒ¯å‡ºæ´»å‹•',
                'rule_type': 'volume',
                'conditions': {
                    'action': 'export',
                    'volume_threshold': 1000,
                    'time_window': 3600
                },
                'actions': [
                    {'type': 'alert', 'severity': 'medium'},
                    {'type': 'log_detail'}
                ],
                'severity': RiskLevel.MEDIUM
            }
        ]
        
        for rule_data in default_rules:
            rule = SecurityRule(
                id=rule_data['id'],
                name=rule_data['name'],
                description=rule_data['description'],
                rule_type=rule_data['rule_type'],
                conditions=rule_data['conditions'],
                actions=rule_data['actions'],
                enabled=True,
                severity=rule_data['severity'],
                created_at=datetime.now(timezone.utc),
                created_by=0
            )
            self.security_rules[rule.id] = rule
    
    # ========== æ ¸å¿ƒå®‰å…¨äº‹ä»¶è¨˜éŒ„ ==========
    
    async def log_security_event(
        self,
        event_type: SecurityEventType,
        user_id: int,
        action: AuditAction,
        resource: str,
        details: Dict[str, Any],
        guild_id: Optional[int] = None,
        risk_level: RiskLevel = RiskLevel.LOW,
        ip_address: Optional[str] = None,
        user_agent: Optional[str] = None,
        correlation_id: Optional[str] = None
    ) -> str:
        """è¨˜éŒ„å®‰å…¨äº‹ä»¶"""
        try:
            event_id = str(uuid.uuid4())
            
            # å‰µå»ºå®‰å…¨äº‹ä»¶
            event = SecurityEvent(
                id=event_id,
                event_type=event_type,
                timestamp=datetime.now(timezone.utc),
                user_id=user_id,
                guild_id=guild_id,
                risk_level=risk_level,
                action=action,
                resource=resource,
                details=self._sanitize_sensitive_data(details),
                ip_address=ip_address,
                user_agent=user_agent,
                session_id=self._get_session_id(user_id),
                correlation_id=correlation_id
            )
            
            # åŠ å¯†æ•æ„Ÿæ•¸æ“š
            if self._contains_sensitive_data(details):
                event.details = self._encrypt_data(event.details)
            
            # æ·»åŠ åˆ°äº‹ä»¶ç·©è¡å€
            self.event_buffer.append(event)
            
            # æª¢æŸ¥å®‰å…¨è¦å‰‡
            await self._evaluate_security_rules(event)
            
            # æª¢æ¸¬å¯ç–‘æ´»å‹•
            await self._detect_suspicious_activity(event)
            
            # å®šæœŸæŒä¹…åŒ–åˆ°è³‡æ–™åº«
            if len(self.event_buffer) >= 100:
                await self._flush_event_buffer()
            
            logger.info(f"âœ… å®‰å…¨äº‹ä»¶å·²è¨˜éŒ„: {event_type.value} by {user_id}")
            return event_id
            
        except Exception as e:
            logger.error(f"è¨˜éŒ„å®‰å…¨äº‹ä»¶å¤±æ•—: {e}")
            return ""
    
    async def log_command_execution(
        self,
        user_id: int,
        guild_id: int,
        command_name: str,
        parameters: Dict[str, Any],
        success: bool,
        execution_time: float,
        ip_address: Optional[str] = None
    ):
        """è¨˜éŒ„æŒ‡ä»¤åŸ·è¡Œ"""
        risk_level = RiskLevel.LOW
        event_type = SecurityEventType.COMMAND_EXECUTION
        
        # è©•ä¼°æŒ‡ä»¤é¢¨éšªç­‰ç´š
        if command_name in ['ban', 'kick', 'mute', 'delete_channel']:
            risk_level = RiskLevel.HIGH
        elif command_name in ['role_assign', 'permission_change']:
            risk_level = RiskLevel.CRITICAL
        
        details = {
            'command': command_name,
            'parameters': parameters,
            'success': success,
            'execution_time': execution_time,
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
        
        await self.log_security_event(
            event_type=event_type,
            user_id=user_id,
            guild_id=guild_id,
            action=AuditAction.EXECUTE,
            resource=f"command:{command_name}",
            details=details,
            risk_level=risk_level,
            ip_address=ip_address
        )
    
    async def log_data_access(
        self,
        user_id: int,
        guild_id: int,
        table_name: str,
        operation: str,
        record_count: int,
        filters: Dict[str, Any] = None
    ):
        """è¨˜éŒ„è³‡æ–™å­˜å–"""
        risk_level = RiskLevel.LOW
        if record_count > 1000:
            risk_level = RiskLevel.MEDIUM
        elif operation in ['DELETE', 'UPDATE'] and record_count > 100:
            risk_level = RiskLevel.HIGH
        
        details = {
            'table': table_name,
            'operation': operation,
            'record_count': record_count,
            'filters': filters or {},
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
        
        await self.log_security_event(
            event_type=SecurityEventType.DATA_ACCESS,
            user_id=user_id,
            guild_id=guild_id,
            action=AuditAction(operation.lower()) if operation.lower() in [a.value for a in AuditAction] else AuditAction.ACCESS,
            resource=f"database:{table_name}",
            details=details,
            risk_level=risk_level
        )
    
    # ========== å¯ç–‘æ´»å‹•æª¢æ¸¬ ==========
    
    async def _detect_suspicious_activity(self, event: SecurityEvent):
        """æª¢æ¸¬å¯ç–‘æ´»å‹•"""
        user_key = f"{event.user_id}_{event.guild_id or 0}"
        
        # åˆå§‹åŒ–ç”¨æˆ¶æ´»å‹•è¨˜éŒ„
        if user_key not in self.suspicious_activity_cache:
            self.suspicious_activity_cache[user_key] = []
        
        # æ·»åŠ ç•¶å‰äº‹ä»¶æ™‚é–“
        self.suspicious_activity_cache[user_key].append(event.timestamp)
        
        # ä¿æŒæœ€è¿‘1å°æ™‚çš„è¨˜éŒ„
        cutoff_time = event.timestamp - timedelta(hours=1)
        self.suspicious_activity_cache[user_key] = [
            t for t in self.suspicious_activity_cache[user_key] 
            if t > cutoff_time
        ]
        
        # æª¢æ¸¬ç•°å¸¸é »ç‡
        recent_events = len(self.suspicious_activity_cache[user_key])
        
        if recent_events > 50:  # 1å°æ™‚å…§è¶…é50å€‹äº‹ä»¶
            await self._handle_suspicious_activity(
                event.user_id,
                event.guild_id,
                "ç•°å¸¸é«˜é »æ“ä½œ",
                {"events_per_hour": recent_events}
            )
        
        # æª¢æ¸¬ç•°å¸¸æ™‚é–“æ¨¡å¼
        if self._is_unusual_time(event.timestamp):
            await self._handle_suspicious_activity(
                event.user_id,
                event.guild_id,
                "ç•°å¸¸æ™‚é–“æ“ä½œ",
                {"timestamp": event.timestamp.isoformat()}
            )
        
        # æª¢æ¸¬IPåœ°å€ç•°å¸¸
        if event.ip_address and await self._is_suspicious_ip(event.ip_address):
            await self._handle_suspicious_activity(
                event.user_id,
                event.guild_id,
                "å¯ç–‘IPåœ°å€",
                {"ip_address": event.ip_address}
            )
    
    def _is_unusual_time(self, timestamp: datetime) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºç•°å¸¸æ™‚é–“ï¼ˆä¾‹å¦‚æ·±å¤œï¼‰"""
        hour = timestamp.hour
        return hour < 6 or hour > 23  # å‡Œæ™¨6é»å‰æˆ–æ™šä¸Š11é»å¾Œ
    
    async def _is_suspicious_ip(self, ip_address: str) -> bool:
        """æª¢æŸ¥IPåœ°å€æ˜¯å¦å¯ç–‘"""
        try:
            ip = ipaddress.ip_address(ip_address)
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºå·²çŸ¥çš„æƒ¡æ„IPç¯„åœ
            # é€™è£¡å¯ä»¥æ•´åˆç¬¬ä¸‰æ–¹å¨è„…æƒ…å ±æœå‹™
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºTorå‡ºå£ç¯€é»æˆ–VPN
            suspicious_ranges = [
                ipaddress.ip_network('10.0.0.0/8'),      # ç§æœ‰ç¶²è·¯
                ipaddress.ip_network('172.16.0.0/12'),   # ç§æœ‰ç¶²è·¯
                ipaddress.ip_network('192.168.0.0/16'),  # ç§æœ‰ç¶²è·¯
            ]
            
            # å¦‚æœæ˜¯ç§æœ‰IPä½†ä¾†è‡ªå¤–éƒ¨ï¼Œå¯èƒ½æ˜¯å½é€ çš„
            for network in suspicious_ranges:
                if ip in network:
                    return True
            
            return False
            
        except ValueError:
            return True  # ç„¡æ•ˆIPåœ°å€æœ¬èº«å°±å¯ç–‘
    
    async def _handle_suspicious_activity(
        self,
        user_id: int,
        guild_id: Optional[int],
        activity_type: str,
        details: Dict[str, Any]
    ):
        """è™•ç†å¯ç–‘æ´»å‹•"""
        await self.log_security_event(
            event_type=SecurityEventType.SUSPICIOUS_ACTIVITY,
            user_id=user_id,
            guild_id=guild_id,
            action=AuditAction.ACCESS,
            resource="system",
            details={
                "activity_type": activity_type,
                "details": details,
                "detected_at": datetime.now(timezone.utc).isoformat()
            },
            risk_level=RiskLevel.HIGH
        )
        
        # å¯ä»¥åœ¨é€™è£¡æ·»åŠ è‡ªå‹•éŸ¿æ‡‰æªæ–½
        logger.warning(f"ğŸš¨ æª¢æ¸¬åˆ°å¯ç–‘æ´»å‹•: {activity_type} by user {user_id}")
    
    # ========== å®‰å…¨è¦å‰‡è©•ä¼° ==========
    
    async def _evaluate_security_rules(self, event: SecurityEvent):
        """è©•ä¼°å®‰å…¨è¦å‰‡"""
        for rule_id, rule in self.security_rules.items():
            if not rule.enabled:
                continue
            
            try:
                if await self._rule_matches_event(rule, event):
                    await self._execute_rule_actions(rule, event)
            except Exception as e:
                logger.error(f"è©•ä¼°å®‰å…¨è¦å‰‡å¤±æ•— {rule_id}: {e}")
    
    async def _rule_matches_event(self, rule: SecurityRule, event: SecurityEvent) -> bool:
        """æª¢æŸ¥è¦å‰‡æ˜¯å¦åŒ¹é…äº‹ä»¶"""
        conditions = rule.conditions
        
        # æª¢æŸ¥äº‹ä»¶é¡å‹
        if 'event_type' in conditions:
            if event.event_type.value != conditions['event_type']:
                return False
        
        # æª¢æŸ¥å‹•ä½œé¡å‹
        if 'action' in conditions:
            if event.action.value != conditions['action']:
                return False
        
        # æª¢æŸ¥é–¾å€¼è¦å‰‡
        if rule.rule_type == 'threshold':
            return await self._evaluate_threshold_rule(conditions, event)
        
        # æª¢æŸ¥ç•°å¸¸è¦å‰‡
        elif rule.rule_type == 'anomaly':
            return await self._evaluate_anomaly_rule(conditions, event)
        
        # æª¢æŸ¥æ•¸é‡è¦å‰‡
        elif rule.rule_type == 'volume':
            return await self._evaluate_volume_rule(conditions, event)
        
        return True
    
    async def _evaluate_threshold_rule(self, conditions: Dict[str, Any], event: SecurityEvent) -> bool:
        """è©•ä¼°é–¾å€¼è¦å‰‡"""
        threshold = conditions.get('threshold', 5)
        time_window = conditions.get('time_window', 300)  # ç§’
        
        # è¨ˆç®—åœ¨æ™‚é–“çª—å£å…§çš„ç›¸åŒäº‹ä»¶æ•¸é‡
        cutoff_time = event.timestamp - timedelta(seconds=time_window)
        
        matching_events = [
            e for e in self.event_buffer
            if (e.event_type == event.event_type and
                e.user_id == event.user_id and
                e.timestamp > cutoff_time)
        ]
        
        return len(matching_events) >= threshold
    
    async def _evaluate_anomaly_rule(self, conditions: Dict[str, Any], event: SecurityEvent) -> bool:
        """è©•ä¼°ç•°å¸¸è¦å‰‡"""
        if conditions.get('check_elevation') and event.event_type == SecurityEventType.ROLE_ASSIGNMENT:
            # æª¢æŸ¥æ˜¯å¦ç‚ºæ¬Šé™æå‡
            details = event.details
            old_roles = details.get('old_roles', [])
            new_roles = details.get('new_roles', [])
            
            # ç°¡å–®æª¢æŸ¥ï¼šå¦‚æœæ–°è§’è‰²æ•¸é‡å¤§æ–¼èˆŠè§’è‰²ï¼Œå¯èƒ½æ˜¯æå‡
            return len(new_roles) > len(old_roles)
        
        return False
    
    async def _evaluate_volume_rule(self, conditions: Dict[str, Any], event: SecurityEvent) -> bool:
        """è©•ä¼°æ•¸é‡è¦å‰‡"""
        volume_threshold = conditions.get('volume_threshold', 1000)
        time_window = conditions.get('time_window', 3600)
        
        if event.action.value != conditions.get('action'):
            return False
        
        # è¨ˆç®—æ™‚é–“çª—å£å…§çš„æ“ä½œç¸½é‡
        cutoff_time = event.timestamp - timedelta(seconds=time_window)
        
        total_volume = sum(
            e.details.get('record_count', 1) for e in self.event_buffer
            if (e.action == event.action and
                e.user_id == event.user_id and
                e.timestamp > cutoff_time)
        )
        
        return total_volume >= volume_threshold
    
    async def _execute_rule_actions(self, rule: SecurityRule, event: SecurityEvent):
        """åŸ·è¡Œè¦å‰‡å‹•ä½œ"""
        for action in rule.actions:
            action_type = action.get('type')
            
            try:
                if action_type == 'alert':
                    await self._send_security_alert(rule, event, action)
                elif action_type == 'temporary_ban':
                    await self._apply_temporary_restriction(event.user_id, action)
                elif action_type == 'require_approval':
                    await self._require_approval(event, action)
                elif action_type == 'log_detail':
                    await self._log_detailed_information(event, action)
                
            except Exception as e:
                logger.error(f"åŸ·è¡Œå®‰å…¨è¦å‰‡å‹•ä½œå¤±æ•— {action_type}: {e}")
    
    async def _send_security_alert(self, rule: SecurityRule, event: SecurityEvent, action: Dict[str, Any]):
        """ç™¼é€å®‰å…¨è­¦å ±"""
        severity = action.get('severity', 'medium')
        
        alert_details = {
            'rule_name': rule.name,
            'rule_id': rule.id,
            'event_id': event.id,
            'severity': severity,
            'user_id': event.user_id,
            'event_type': event.event_type.value,
            'timestamp': event.timestamp.isoformat(),
            'resource': event.resource
        }
        
        logger.warning(f"ğŸš¨ å®‰å…¨è­¦å ±: {rule.name} - {severity.upper()}")
        # é€™è£¡å¯ä»¥æ•´åˆå¤–éƒ¨è­¦å ±ç³»çµ±
    
    async def _apply_temporary_restriction(self, user_id: int, action: Dict[str, Any]):
        """æ‡‰ç”¨è‡¨æ™‚é™åˆ¶"""
        duration = action.get('duration', 1800)  # é è¨­30åˆ†é˜
        restriction_end = datetime.now(timezone.utc) + timedelta(seconds=duration)
        
        # è¨˜éŒ„é™åˆ¶
        logger.info(f"âš ï¸ å°ç”¨æˆ¶ {user_id} æ‡‰ç”¨è‡¨æ™‚é™åˆ¶ï¼ŒæŒçºŒ {duration} ç§’")
        # å¯¦éš›é™åˆ¶é‚è¼¯éœ€è¦èˆ‡Botçš„æ¬Šé™ç³»çµ±æ•´åˆ
    
    async def _require_approval(self, event: SecurityEvent, action: Dict[str, Any]):
        """è¦æ±‚å¯©æ‰¹"""
        # å°‡äº‹ä»¶æ¨™è¨˜ç‚ºéœ€è¦å¯©æ‰¹
        logger.info(f"ğŸ“‹ äº‹ä»¶ {event.id} éœ€è¦ç®¡ç†å“¡å¯©æ‰¹")
        # å¯ä»¥ç™¼é€é€šçŸ¥çµ¦ç®¡ç†å“¡
    
    async def _log_detailed_information(self, event: SecurityEvent, action: Dict[str, Any]):
        """è¨˜éŒ„è©³ç´°è³‡è¨Š"""
        detailed_info = {
            'event_id': event.id,
            'detailed_context': {
                'session_id': event.session_id,
                'correlation_id': event.correlation_id,
                'user_agent': event.user_agent,
                'ip_address': event.ip_address
            }
        }
        
        logger.info(f"ğŸ“ è©³ç´°è¨˜éŒ„äº‹ä»¶ {event.id}")
    
    # ========== æ•¸æ“šè™•ç†å’ŒåŠ å¯† ==========
    
    def _sanitize_sensitive_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æ¸…ç†æ•æ„Ÿæ•¸æ“š"""
        sensitive_patterns = [
            r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b',  # ä¿¡ç”¨å¡è™Ÿ
            r'\b\d{3}-\d{2}-\d{4}\b',                        # SSN
            r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',  # Email (éƒ¨åˆ†)
        ]
        
        sanitized_data = {}
        for key, value in data.items():
            if isinstance(value, str):
                sanitized_value = value
                for pattern in sensitive_patterns:
                    sanitized_value = re.sub(pattern, '[REDACTED]', sanitized_value)
                sanitized_data[key] = sanitized_value
            else:
                sanitized_data[key] = value
        
        return sanitized_data
    
    def _contains_sensitive_data(self, data: Dict[str, Any]) -> bool:
        """æª¢æŸ¥æ˜¯å¦åŒ…å«æ•æ„Ÿæ•¸æ“š"""
        sensitive_keys = ['password', 'token', 'key', 'secret', 'private', 'credential']
        
        for key in data.keys():
            if any(sensitive_key in key.lower() for sensitive_key in sensitive_keys):
                return True
        
        return False
    
    def _encrypt_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """åŠ å¯†æ•æ„Ÿæ•¸æ“š"""
        try:
            json_data = json.dumps(data)
            encrypted_data = self.cipher_suite.encrypt(json_data.encode())
            return {'encrypted': True, 'data': encrypted_data.hex()}
        except Exception as e:
            logger.error(f"åŠ å¯†æ•¸æ“šå¤±æ•—: {e}")
            return data
    
    def _decrypt_data(self, encrypted_data: Dict[str, Any]) -> Dict[str, Any]:
        """è§£å¯†æ•¸æ“š"""
        try:
            if not encrypted_data.get('encrypted'):
                return encrypted_data
            
            hex_data = encrypted_data['data']
            encrypted_bytes = bytes.fromhex(hex_data)
            decrypted_bytes = self.cipher_suite.decrypt(encrypted_bytes)
            return json.loads(decrypted_bytes.decode())
        except Exception as e:
            logger.error(f"è§£å¯†æ•¸æ“šå¤±æ•—: {e}")
            return {}
    
    # ========== æœƒè©±ç®¡ç† ==========
    
    def _get_session_id(self, user_id: int) -> Optional[str]:
        """ç²å–ç”¨æˆ¶æœƒè©±ID"""
        # ç°¡åŒ–çš„æœƒè©±ç®¡ç†
        session_key = f"user_{user_id}"
        if session_key not in self.active_sessions:
            session_id = str(uuid.uuid4())
            self.active_sessions[session_key] = {
                'session_id': session_id,
                'created_at': datetime.now(timezone.utc),
                'last_activity': datetime.now(timezone.utc)
            }
            return session_id
        else:
            self.active_sessions[session_key]['last_activity'] = datetime.now(timezone.utc)
            return self.active_sessions[session_key]['session_id']
    
    async def cleanup_expired_sessions(self):
        """æ¸…ç†éæœŸæœƒè©±"""
        cutoff_time = datetime.now(timezone.utc) - timedelta(hours=24)
        expired_sessions = [
            key for key, session in self.active_sessions.items()
            if session['last_activity'] < cutoff_time
        ]
        
        for session_key in expired_sessions:
            del self.active_sessions[session_key]
        
        logger.info(f"æ¸…ç†äº† {len(expired_sessions)} å€‹éæœŸæœƒè©±")
    
    # ========== åˆè¦å ±å‘Š ==========
    
    async def generate_compliance_report(
        self,
        guild_id: int,
        standard: ComplianceStandard,
        start_date: datetime,
        end_date: datetime,
        generated_by: int
    ) -> ComplianceReport:
        """ç”Ÿæˆåˆè¦å ±å‘Š"""
        try:
            report_id = str(uuid.uuid4())
            
            # æ ¹æ“šåˆè¦æ¨™æº–ç¯©é¸ç›¸é—œäº‹ä»¶
            relevant_events = [
                event for event in self.event_buffer
                if (event.guild_id == guild_id and
                    start_date <= event.timestamp <= end_date)
            ]
            
            # åˆ†æé•è¦æƒ…æ³
            violations = await self._analyze_compliance_violations(relevant_events, standard)
            
            # ç”Ÿæˆæ‘˜è¦
            summary = await self._generate_compliance_summary(relevant_events, standard)
            
            # æä¾›å»ºè­°
            recommendations = await self._generate_compliance_recommendations(violations, standard)
            
            report = ComplianceReport(
                id=report_id,
                standard=standard,
                period_start=start_date,
                period_end=end_date,
                guild_id=guild_id,
                generated_by=generated_by,
                generated_at=datetime.now(timezone.utc),
                summary=summary,
                violations=violations,
                recommendations=recommendations
            )
            
            logger.info(f"âœ… åˆè¦å ±å‘Šå·²ç”Ÿæˆ: {standard.value} for guild {guild_id}")
            return report
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆåˆè¦å ±å‘Šå¤±æ•—: {e}")
            raise
    
    async def _analyze_compliance_violations(
        self,
        events: List[SecurityEvent],
        standard: ComplianceStandard
    ) -> List[Dict[str, Any]]:
        """åˆ†æåˆè¦é•è¦"""
        violations = []
        
        if standard == ComplianceStandard.GDPR:
            # GDPRç›¸é—œæª¢æŸ¥
            data_access_events = [e for e in events if e.event_type == SecurityEventType.DATA_ACCESS]
            
            for event in data_access_events:
                if event.risk_level == RiskLevel.HIGH and 'personal_data' in str(event.details):
                    violations.append({
                        'type': 'unauthorized_personal_data_access',
                        'event_id': event.id,
                        'timestamp': event.timestamp.isoformat(),
                        'description': 'å¯èƒ½çš„æœªæˆæ¬Šå€‹äººæ•¸æ“šå­˜å–',
                        'severity': 'high'
                    })
        
        elif standard == ComplianceStandard.SOX:
            # SOXç›¸é—œæª¢æŸ¥
            financial_events = [
                e for e in events 
                if 'financial' in str(e.resource) or 'audit' in str(e.resource)
            ]
            
            for event in financial_events:
                if event.action == AuditAction.DELETE:
                    violations.append({
                        'type': 'financial_record_deletion',
                        'event_id': event.id,
                        'timestamp': event.timestamp.isoformat(),
                        'description': 'è²¡å‹™è¨˜éŒ„åˆªé™¤æ“ä½œ',
                        'severity': 'critical'
                    })
        
        return violations
    
    async def _generate_compliance_summary(
        self,
        events: List[SecurityEvent],
        standard: ComplianceStandard
    ) -> Dict[str, Any]:
        """ç”Ÿæˆåˆè¦æ‘˜è¦"""
        return {
            'total_events': len(events),
            'high_risk_events': len([e for e in events if e.risk_level == RiskLevel.HIGH]),
            'critical_events': len([e for e in events if e.risk_level == RiskLevel.CRITICAL]),
            'data_access_events': len([e for e in events if e.event_type == SecurityEventType.DATA_ACCESS]),
            'user_management_events': len([e for e in events if e.event_type == SecurityEventType.USER_MANAGEMENT]),
            'unique_users': len(set(e.user_id for e in events)),
            'compliance_standard': standard.value
        }
    
    async def _generate_compliance_recommendations(
        self,
        violations: List[Dict[str, Any]],
        standard: ComplianceStandard
    ) -> List[str]:
        """ç”Ÿæˆåˆè¦å»ºè­°"""
        recommendations = []
        
        if violations:
            recommendations.append("æª¢æŸ¥ä¸¦ä¿®æ­£æ‰€æœ‰æª¢æ¸¬åˆ°çš„é•è¦è¡Œç‚º")
            recommendations.append("åŠ å¼·ç”¨æˆ¶åŸ¹è¨“å’Œæ„è­˜")
            recommendations.append("å¯¦æ–½æ›´åš´æ ¼çš„å­˜å–æ§åˆ¶")
        
        if standard == ComplianceStandard.GDPR:
            recommendations.extend([
                "å¯¦æ–½æ•¸æ“šä¿è­·å½±éŸ¿è©•ä¼°(DPIA)",
                "ç¢ºä¿æ‰€æœ‰å€‹äººæ•¸æ“šè™•ç†éƒ½æœ‰åˆæ³•åŸºç¤",
                "å»ºç«‹æ•¸æ“šä¸»é«”æ¬Šåˆ©å›æ‡‰ç¨‹åº"
            ])
        
        elif standard == ComplianceStandard.SOX:
            recommendations.extend([
                "å»ºç«‹è²¡å‹™æ•¸æ“šè®Šæ›´çš„é›™é‡èªè­‰",
                "å¯¦æ–½è²¡å‹™ç³»çµ±çš„å®šæœŸç¨½æ ¸",
                "ç¢ºä¿è²¡å‹™è¨˜éŒ„çš„å®Œæ•´æ€§å’Œä¸å¯å¦èªæ€§"
            ])
        
        return recommendations
    
    # ========== äº‹ä»¶ç·©è¡å€ç®¡ç† ==========
    
    async def _flush_event_buffer(self):
        """å°‡äº‹ä»¶ç·©è¡å€åˆ·æ–°åˆ°è³‡æ–™åº«"""
        if not self.event_buffer:
            return
        
        try:
            # é€™è£¡æ‡‰è©²å¯¦ç¾å°‡äº‹ä»¶å¯«å…¥è³‡æ–™åº«çš„é‚è¼¯
            # ç›®å‰å…ˆè¨˜éŒ„æ—¥èªŒ
            logger.info(f"å°‡ {len(self.event_buffer)} å€‹å®‰å…¨äº‹ä»¶å¯«å…¥è³‡æ–™åº«")
            
            # æ¸…ç©ºç·©è¡å€
            self.event_buffer.clear()
            
        except Exception as e:
            logger.error(f"åˆ·æ–°äº‹ä»¶ç·©è¡å€å¤±æ•—: {e}")
    
    # ========== çµ±è¨ˆå’Œå ±å‘Š ==========
    
    async def get_security_statistics(
        self,
        guild_id: int,
        days: int = 30
    ) -> Dict[str, Any]:
        """ç²å–å®‰å…¨çµ±è¨ˆè³‡è¨Š"""
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=days)
        
        relevant_events = [
            event for event in self.event_buffer
            if (event.guild_id == guild_id and event.timestamp > cutoff_date)
        ]
        
        return {
            'total_events': len(relevant_events),
            'events_by_type': self._count_events_by_type(relevant_events),
            'events_by_risk_level': self._count_events_by_risk_level(relevant_events),
            'top_users': self._get_top_users_by_activity(relevant_events),
            'suspicious_activities': len([
                e for e in relevant_events 
                if e.event_type == SecurityEventType.SUSPICIOUS_ACTIVITY
            ]),
            'security_violations': len([
                e for e in relevant_events 
                if e.event_type == SecurityEventType.SECURITY_VIOLATION
            ])
        }
    
    def _count_events_by_type(self, events: List[SecurityEvent]) -> Dict[str, int]:
        """æŒ‰é¡å‹çµ±è¨ˆäº‹ä»¶"""
        counts = {}
        for event in events:
            event_type = event.event_type.value
            counts[event_type] = counts.get(event_type, 0) + 1
        return counts
    
    def _count_events_by_risk_level(self, events: List[SecurityEvent]) -> Dict[str, int]:
        """æŒ‰é¢¨éšªç­‰ç´šçµ±è¨ˆäº‹ä»¶"""
        counts = {}
        for event in events:
            risk_level = event.risk_level.value
            counts[risk_level] = counts.get(risk_level, 0) + 1
        return counts
    
    def _get_top_users_by_activity(self, events: List[SecurityEvent], limit: int = 10) -> List[Dict[str, Any]]:
        """ç²å–æ´»å‹•æœ€å¤šçš„ç”¨æˆ¶"""
        user_counts = {}
        for event in events:
            user_id = event.user_id
            if user_id not in user_counts:
                user_counts[user_id] = {'count': 0, 'high_risk_count': 0}
            user_counts[user_id]['count'] += 1
            if event.risk_level in [RiskLevel.HIGH, RiskLevel.CRITICAL]:
                user_counts[user_id]['high_risk_count'] += 1
        
        sorted_users = sorted(
            user_counts.items(),
            key=lambda x: x[1]['count'],
            reverse=True
        )[:limit]
        
        return [
            {'user_id': user_id, **stats}
            for user_id, stats in sorted_users
        ]

# å…¨åŸŸå¯¦ä¾‹
security_audit_manager = SecurityAuditManager()