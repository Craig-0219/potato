# bot/services/ai_assistant.py - AIæ™ºèƒ½åŠ©æ‰‹æœå‹™
"""
AIæ™ºèƒ½åŠ©æ‰‹æœå‹™ v2.2.0
æ•´åˆChatGPTå’Œå…¶ä»–AIæœå‹™ï¼Œæä¾›æ™ºèƒ½å°è©±ã€å‰µæ„å…§å®¹ç”Ÿæˆç­‰åŠŸèƒ½
"""

import asyncio
import aiohttp
import json
import time
import re
from typing import Dict, List, Optional, Any, Union
from datetime import datetime, timezone, timedelta
from dataclasses import dataclass, asdict
from enum import Enum

from shared.cache_manager import cache_manager, cached
from shared.logger import logger

class AIProvider(Enum):
    """AIæœå‹™æä¾›å•†"""
    OPENAI = "openai"
    CLAUDE = "claude"
    GEMINI = "gemini"
    LOCAL = "local"

class AITaskType(Enum):
    """AIä»»å‹™é¡å‹"""
    CHAT = "chat"                    # èŠå¤©å°è©±
    CODE_HELP = "code_help"          # ä»£ç¢¼åŠ©æ‰‹
    TRANSLATE = "translate"          # ç¿»è­¯
    CREATIVE_WRITING = "creative"    # å‰µæ„å¯«ä½œ
    SUMMARY = "summary"              # å…§å®¹æ‘˜è¦
    EXPLANATION = "explanation"      # è§£é‡‹èªªæ˜
    STORY_GENERATION = "story"       # æ•…äº‹ç”Ÿæˆ
    POEM_GENERATION = "poem"         # è©©æ­Œç”Ÿæˆ
    AD_COPY = "ad_copy"             # å»£å‘Šæ–‡æ¡ˆ

@dataclass
class AIRequest:
    """AIè«‹æ±‚"""
    user_id: int
    guild_id: int
    task_type: AITaskType
    prompt: str
    context: Dict[str, Any]
    provider: AIProvider = AIProvider.OPENAI
    max_tokens: int = 1000
    temperature: float = 0.7
    
@dataclass
class AIResponse:
    """AIå›æ‡‰"""
    request_id: str
    content: str
    tokens_used: int
    response_time: float
    provider: AIProvider
    success: bool
    error_message: Optional[str] = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

class AIAssistantManager:
    """AIåŠ©æ‰‹ç®¡ç†å™¨"""
    
    def __init__(self):
        self.api_keys = {}
        self.rate_limits = {
            AIProvider.OPENAI: {"rpm": 60, "tpm": 50000},  # æ¯åˆ†é˜è«‹æ±‚æ•¸å’Œtokenæ•¸
            AIProvider.CLAUDE: {"rpm": 30, "tpm": 30000},
            AIProvider.GEMINI: {"rpm": 100, "tpm": 100000}
        }
        
        # AIæ¨¡å‹é…ç½®
        self.models = {
            AIProvider.OPENAI: {
                "chat": "gpt-3.5-turbo",
                "creative": "gpt-4",
                "code": "gpt-3.5-turbo"
            }
        }
        
        # é è¨­æç¤ºè©æ¨¡æ¿
        self.prompt_templates = {
            AITaskType.CHAT: {
                "system": "ä½ æ˜¯ä¸€å€‹å‹å–„ã€æœ‰å¹«åŠ©çš„Discordæ©Ÿå™¨äººåŠ©æ‰‹ã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ç”¨æˆ¶å•é¡Œï¼Œä¿æŒå›ç­”ç°¡æ½”è€Œæœ‰ç”¨ã€‚",
                "user": "{prompt}"
            },
            AITaskType.CODE_HELP: {
                "system": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç¨‹å¼è¨­è¨ˆåŠ©æ‰‹ã€‚è«‹å¹«åŠ©ç”¨æˆ¶è§£æ±ºç¨‹å¼è¨­è¨ˆå•é¡Œï¼Œæä¾›æ¸…æ™°çš„è§£é‡‹å’Œå¯åŸ·è¡Œçš„ä»£ç¢¼ç¯„ä¾‹ã€‚",
                "user": "è«‹å¹«æˆ‘è§£æ±ºé€™å€‹ç¨‹å¼è¨­è¨ˆå•é¡Œï¼š{prompt}"
            },
            AITaskType.TRANSLATE: {
                "system": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç¿»è­¯åŠ©æ‰‹ã€‚è«‹æä¾›æº–ç¢ºã€è‡ªç„¶çš„ç¿»è­¯ã€‚",
                "user": "è«‹å°‡ä»¥ä¸‹å…§å®¹ç¿»è­¯ç‚º{target_language}ï¼š{prompt}"
            },
            AITaskType.CREATIVE_WRITING: {
                "system": "ä½ æ˜¯ä¸€å€‹å‰µæ„å¯«ä½œåŠ©æ‰‹ã€‚è«‹æ ¹æ“šç”¨æˆ¶çš„è¦æ±‚å‰µä½œæœ‰è¶£ã€å¼•äººå…¥å‹çš„å…§å®¹ã€‚",
                "user": "è«‹æ ¹æ“šä»¥ä¸‹è¦æ±‚é€²è¡Œå‰µæ„å¯«ä½œï¼š{prompt}"
            },
            AITaskType.STORY_GENERATION: {
                "system": "ä½ æ˜¯ä¸€å€‹æ•…äº‹å‰µä½œå¤§å¸«ã€‚è«‹å‰µä½œå¼•äººå…¥å‹ã€æƒ…ç¯€è±å¯Œçš„æ•…äº‹ã€‚",
                "user": "è«‹æ ¹æ“šä»¥ä¸‹è¨­å®šå‰µä½œä¸€å€‹æ•…äº‹ï¼š{prompt}"
            },
            AITaskType.POEM_GENERATION: {
                "system": "ä½ æ˜¯ä¸€å€‹è©©æ­Œå‰µä½œå°ˆå®¶ã€‚è«‹å‰µä½œå„ªç¾ã€æœ‰éŸ»å¾‹çš„è©©æ­Œã€‚",
                "user": "è«‹æ ¹æ“šä»¥ä¸‹ä¸»é¡Œå‰µä½œè©©æ­Œï¼š{prompt}"
            },
            AITaskType.AD_COPY: {
                "system": "ä½ æ˜¯ä¸€å€‹å»£å‘Šæ–‡æ¡ˆå°ˆå®¶ã€‚è«‹å‰µä½œå¸å¼•äººã€æœ‰èªªæœåŠ›çš„å»£å‘Šæ–‡æ¡ˆã€‚",
                "user": "è«‹ç‚ºä»¥ä¸‹ç”¢å“/æœå‹™å‰µä½œå»£å‘Šæ–‡æ¡ˆï¼š{prompt}"
            }
        }
        
        # å…§å®¹éæ¿¾è¦å‰‡
        self.content_filters = [
            r"(æš´åŠ›|è¡€è…¥|æ®ºå®³)",
            r"(è‰²æƒ…|æ€§[è¡Œç‚ºæš—ç¤º]|è£¸é«”)",
            r"(æ¯’å“|å¸æ¯’|è²©æ¯’)",
            r"(è‡ªæ®º|è‡ªæ®˜|æ­»äº¡å¨è„…)",
            r"(ææ€–ä¸»ç¾©|æ¥µç«¯æ€æƒ³)",
            r"(ç¨®æ—æ­§è¦–|ä»‡æ¨è¨€è«–)"
        ]
        
        logger.info("ğŸ¤– AIåŠ©æ‰‹ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def configure_api_key(self, provider: AIProvider, api_key: str):
        """é…ç½®APIå¯†é‘°"""
        self.api_keys[provider] = api_key
        logger.info(f"ğŸ”‘ {provider.value} APIå¯†é‘°å·²é…ç½®")

    # ========== æ ¸å¿ƒAIè«‹æ±‚è™•ç† ==========

    async def process_request(self, ai_request: AIRequest) -> AIResponse:
        """è™•ç†AIè«‹æ±‚"""
        start_time = time.time()
        request_id = f"{ai_request.user_id}_{int(start_time)}"
        
        try:
            # æª¢æŸ¥é€Ÿç‡é™åˆ¶
            if not await self._check_rate_limit(ai_request.user_id, ai_request.provider):
                return AIResponse(
                    request_id=request_id,
                    content="",
                    tokens_used=0,
                    response_time=0,
                    provider=ai_request.provider,
                    success=False,
                    error_message="è¶…éé€Ÿç‡é™åˆ¶ï¼Œè«‹ç¨å¾Œå†è©¦"
                )
            
            # å…§å®¹éæ¿¾
            if not await self._filter_content(ai_request.prompt):
                return AIResponse(
                    request_id=request_id,
                    content="",
                    tokens_used=0,
                    response_time=0,
                    provider=ai_request.provider,
                    success=False,
                    error_message="è«‹æ±‚å…§å®¹ä¸é©ç•¶ï¼Œå·²è¢«éæ¿¾"
                )
            
            # æ§‹å»ºæç¤ºè©
            formatted_prompt = await self._build_prompt(ai_request)
            
            # ç™¼é€åˆ°AIæœå‹™
            response_content, tokens_used = await self._call_ai_service(
                ai_request.provider, formatted_prompt, ai_request
            )
            
            response_time = time.time() - start_time
            
            # è¨˜éŒ„ä½¿ç”¨é‡
            await self._record_usage(ai_request.user_id, tokens_used, ai_request.provider)
            
            return AIResponse(
                request_id=request_id,
                content=response_content,
                tokens_used=tokens_used,
                response_time=response_time,
                provider=ai_request.provider,
                success=True,
                metadata={
                    "task_type": ai_request.task_type.value,
                    "model_used": self.models.get(ai_request.provider, {}).get("chat", "unknown")
                }
            )
            
        except Exception as e:
            logger.error(f"âŒ AIè«‹æ±‚è™•ç†å¤±æ•—: {e}")
            return AIResponse(
                request_id=request_id,
                content="",
                tokens_used=0,
                response_time=time.time() - start_time,
                provider=ai_request.provider,
                success=False,
                error_message=str(e)
            )

    async def _build_prompt(self, ai_request: AIRequest) -> List[Dict[str, str]]:
        """æ§‹å»ºæ ¼å¼åŒ–çš„æç¤ºè©"""
        try:
            template = self.prompt_templates.get(ai_request.task_type)
            if not template:
                template = self.prompt_templates[AITaskType.CHAT]
            
            # æ›¿æ›æ¨¡æ¿è®Šé‡
            context = ai_request.context or {}
            user_prompt = template["user"].format(
                prompt=ai_request.prompt,
                **context
            )
            
            messages = [
                {"role": "system", "content": template["system"]},
                {"role": "user", "content": user_prompt}
            ]
            
            return messages
            
        except Exception as e:
            logger.error(f"âŒ æ§‹å»ºæç¤ºè©å¤±æ•—: {e}")
            raise

    async def _call_ai_service(self, provider: AIProvider, messages: List[Dict[str, str]], 
                             ai_request: AIRequest) -> tuple[str, int]:
        """èª¿ç”¨AIæœå‹™"""
        if provider == AIProvider.OPENAI:
            return await self._call_openai(messages, ai_request)
        elif provider == AIProvider.CLAUDE:
            return await self._call_claude(messages, ai_request)
        elif provider == AIProvider.GEMINI:
            return await self._call_gemini(messages, ai_request)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {provider}")

    async def _call_openai(self, messages: List[Dict[str, str]], 
                          ai_request: AIRequest) -> tuple[str, int]:
        """èª¿ç”¨OpenAI API"""
        try:
            api_key = self.api_keys.get(AIProvider.OPENAI)
            if not api_key:
                raise ValueError("OpenAI APIå¯†é‘°æœªé…ç½®")
            
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            # é¸æ“‡æ¨¡å‹
            model = self.models[AIProvider.OPENAI].get(
                ai_request.task_type.value.split('_')[0], 
                self.models[AIProvider.OPENAI]["chat"]
            )
            
            payload = {
                "model": model,
                "messages": messages,
                "max_tokens": ai_request.max_tokens,
                "temperature": ai_request.temperature,
                "stream": False
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=30
                ) as response:
                    
                    if response.status != 200:
                        error_text = await response.text()
                        raise Exception(f"OpenAI APIéŒ¯èª¤ {response.status}: {error_text}")
                    
                    result = await response.json()
                    
                    content = result["choices"][0]["message"]["content"]
                    tokens_used = result["usage"]["total_tokens"]
                    
                    return content, tokens_used
                    
        except Exception as e:
            logger.error(f"âŒ OpenAI APIèª¿ç”¨å¤±æ•—: {e}")
            raise

    async def _call_claude(self, messages: List[Dict[str, str]], 
                          ai_request: AIRequest) -> tuple[str, int]:
        """èª¿ç”¨Claude API (é ç•™æ¥å£)"""
        # é ç•™çµ¦æœªä¾†Claude APIæ•´åˆ
        raise NotImplementedError("Claude APIæ•´åˆé–‹ç™¼ä¸­")

    async def _call_gemini(self, messages: List[Dict[str, str]], 
                          ai_request: AIRequest) -> tuple[str, int]:
        """èª¿ç”¨Gemini API (é ç•™æ¥å£)"""
        # é ç•™çµ¦æœªä¾†Gemini APIæ•´åˆ
        raise NotImplementedError("Gemini APIæ•´åˆé–‹ç™¼ä¸­")

    # ========== å…§å®¹éæ¿¾å’Œå®‰å…¨ ==========

    async def _filter_content(self, content: str) -> bool:
        """å…§å®¹éæ¿¾"""
        try:
            content_lower = content.lower()
            
            for filter_pattern in self.content_filters:
                if re.search(filter_pattern, content_lower):
                    logger.warning(f"âš ï¸ å…§å®¹è¢«éæ¿¾: {filter_pattern}")
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å…§å®¹éæ¿¾å¤±æ•—: {e}")
            return True  # éæ¿¾å¤±æ•—æ™‚å…è¨±é€šé

    # ========== é€Ÿç‡é™åˆ¶å’Œä½¿ç”¨çµ±è¨ˆ ==========

    async def _check_rate_limit(self, user_id: int, provider: AIProvider) -> bool:
        """æª¢æŸ¥é€Ÿç‡é™åˆ¶"""
        try:
            cache_key = f"ai_rate_limit:{provider.value}:{user_id}"
            
            # ç²å–ç•¶å‰è¨ˆæ•¸
            current_count = await cache_manager.get(cache_key)
            if current_count is None:
                current_count = 0
            
            rate_limit = self.rate_limits.get(provider, {"rpm": 10})["rpm"]
            
            if current_count >= rate_limit:
                return False
            
            # å¢åŠ è¨ˆæ•¸
            await cache_manager.set(cache_key, current_count + 1, 60)  # 1åˆ†é˜éæœŸ
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æª¢æŸ¥é€Ÿç‡é™åˆ¶å¤±æ•—: {e}")
            return True  # æª¢æŸ¥å¤±æ•—æ™‚å…è¨±é€šé

    async def _record_usage(self, user_id: int, tokens_used: int, provider: AIProvider):
        """è¨˜éŒ„ä½¿ç”¨é‡"""
        try:
            # è¨˜éŒ„åˆ°ç·©å­˜
            daily_key = f"ai_usage_daily:{provider.value}:{user_id}"
            monthly_key = f"ai_usage_monthly:{provider.value}:{user_id}"
            
            daily_usage = await cache_manager.get(daily_key) or 0
            monthly_usage = await cache_manager.get(monthly_key) or 0
            
            await cache_manager.set(daily_key, daily_usage + tokens_used, 86400)  # 24å°æ™‚
            await cache_manager.set(monthly_key, monthly_usage + tokens_used, 2592000)  # 30å¤©
            
        except Exception as e:
            logger.error(f"âŒ è¨˜éŒ„ä½¿ç”¨é‡å¤±æ•—: {e}")

    async def get_user_usage(self, user_id: int, provider: AIProvider) -> Dict[str, int]:
        """ç²å–ç”¨æˆ¶ä½¿ç”¨é‡çµ±è¨ˆ"""
        try:
            daily_key = f"ai_usage_daily:{provider.value}:{user_id}"
            monthly_key = f"ai_usage_monthly:{provider.value}:{user_id}"
            
            daily_usage = await cache_manager.get(daily_key) or 0
            monthly_usage = await cache_manager.get(monthly_key) or 0
            
            return {
                "daily_tokens": daily_usage,
                "monthly_tokens": monthly_usage,
                "daily_limit": self.rate_limits.get(provider, {"rpm": 10})["rpm"],
                "monthly_limit": self.rate_limits.get(provider, {"tpm": 10000})["tpm"]
            }
            
        except Exception as e:
            logger.error(f"âŒ ç²å–ä½¿ç”¨é‡çµ±è¨ˆå¤±æ•—: {e}")
            return {"daily_tokens": 0, "monthly_tokens": 0}

    # ========== ä¾¿æ·æ–¹æ³• ==========

    async def chat(self, user_id: int, guild_id: int, message: str, 
                  provider: AIProvider = AIProvider.OPENAI) -> AIResponse:
        """ç°¡å–®èŠå¤©"""
        request = AIRequest(
            user_id=user_id,
            guild_id=guild_id,
            task_type=AITaskType.CHAT,
            prompt=message,
            context={},
            provider=provider
        )
        return await self.process_request(request)

    async def help_with_code(self, user_id: int, guild_id: int, code_question: str,
                           language: str = "python") -> AIResponse:
        """ä»£ç¢¼åŠ©æ‰‹"""
        request = AIRequest(
            user_id=user_id,
            guild_id=guild_id,
            task_type=AITaskType.CODE_HELP,
            prompt=code_question,
            context={"language": language},
            provider=AIProvider.OPENAI
        )
        return await self.process_request(request)

    async def translate_text(self, user_id: int, guild_id: int, text: str,
                           target_language: str = "è‹±æ–‡") -> AIResponse:
        """ç¿»è­¯æ–‡æœ¬"""
        request = AIRequest(
            user_id=user_id,
            guild_id=guild_id,
            task_type=AITaskType.TRANSLATE,
            prompt=text,
            context={"target_language": target_language},
            provider=AIProvider.OPENAI
        )
        return await self.process_request(request)

    async def generate_story(self, user_id: int, guild_id: int, theme: str,
                           style: str = "è¼•é¬†å¹½é»˜") -> AIResponse:
        """ç”Ÿæˆæ•…äº‹"""
        request = AIRequest(
            user_id=user_id,
            guild_id=guild_id,
            task_type=AITaskType.STORY_GENERATION,
            prompt=f"ä¸»é¡Œï¼š{theme}ï¼Œé¢¨æ ¼ï¼š{style}",
            context={"style": style},
            provider=AIProvider.OPENAI,
            max_tokens=1500,
            temperature=0.8
        )
        return await self.process_request(request)

    async def generate_poem(self, user_id: int, guild_id: int, theme: str,
                          style: str = "ç¾ä»£è©©") -> AIResponse:
        """ç”Ÿæˆè©©æ­Œ"""
        request = AIRequest(
            user_id=user_id,
            guild_id=guild_id,
            task_type=AITaskType.POEM_GENERATION,
            prompt=f"ä¸»é¡Œï¼š{theme}ï¼Œè©©æ­Œé¡å‹ï¼š{style}",
            context={"style": style},
            provider=AIProvider.OPENAI,
            max_tokens=800,
            temperature=0.9
        )
        return await self.process_request(request)

    async def create_ad_copy(self, user_id: int, guild_id: int, product_info: str,
                           target_audience: str = "ä¸€èˆ¬å¤§çœ¾") -> AIResponse:
        """å‰µå»ºå»£å‘Šæ–‡æ¡ˆ"""
        request = AIRequest(
            user_id=user_id,
            guild_id=guild_id,
            task_type=AITaskType.AD_COPY,
            prompt=f"ç”¢å“ä¿¡æ¯ï¼š{product_info}ï¼Œç›®æ¨™å—çœ¾ï¼š{target_audience}",
            context={"target_audience": target_audience},
            provider=AIProvider.OPENAI,
            max_tokens=500,
            temperature=0.7
        )
        return await self.process_request(request)

# å…¨åŸŸå¯¦ä¾‹
ai_assistant = AIAssistantManager()