# bot/services/ai_assistant.py - AIæ™ºèƒ½åŠ©æ‰‹æœå‹™
"""
AIæ™ºèƒ½åŠ©æ‰‹æœå‹™ v2.2.0
æ•´åˆChatGPTå’Œå…¶ä»–AIæœå‹™ï¼Œæä¾›æ™ºèƒ½å°è©±ã€å‰µæ„å…§å®¹ç”Ÿæˆç­‰åŠŸèƒ½
"""

import re
import time
from dataclasses import dataclass
from enum import Enum
from typing import Any, Dict, List, Optional

import aiohttp

from shared.cache_manager import cache_manager
from shared.config import (
    ANTHROPIC_API_KEY,
    GEMINI_API_KEY,
    OPENAI_API_KEY,
)
from shared.logger import logger

# å¼•å…¥ Phase 7 æ–°çš„ AI æœå‹™
from .ai.ai_engine_manager import AIEngineManager
from .ai.conversation_manager import ConversationFlow, ConversationManager
from .ai.intent_recognition import IntentRecognizer, IntentType


class AIProvider(Enum):
    """AIæœå‹™æä¾›å•†"""

    OPENAI = "openai"
    CLAUDE = "claude"
    GEMINI = "gemini"
    LOCAL = "local"


class AITaskType(Enum):
    """AIä»»å‹™é¡å‹"""

    CHAT = "chat"  # èŠå¤©å°è©±
    CODE_HELP = "code_help"  # ä»£ç¢¼åŠ©æ‰‹
    TRANSLATE = "translate"  # ç¿»è­¯
    CREATIVE_WRITING = "creative"  # å‰µæ„å¯«ä½œ
    SUMMARY = "summary"  # å…§å®¹æ‘˜è¦
    EXPLANATION = "explanation"  # è§£é‡‹èªªæ˜
    STORY_GENERATION = "story"  # æ•…äº‹ç”Ÿæˆ
    POEM_GENERATION = "poem"  # è©©æ­Œç”Ÿæˆ
    AD_COPY = "ad_copy"  # å»£å‘Šæ–‡æ¡ˆ


@dataclass
class AIRequest:
    """AIè«‹æ±‚"""

    user_id: int
    guild_id: int
    task_type: AITaskType
    prompt: str
    context: Dict[str, Any]
    provider: AIProvider = AIProvider.OPENAI
    max_tokens: int = 1000
    temperature: float = 0.7


@dataclass
class AIResponse:
    """AIå›æ‡‰"""

    request_id: str
    content: str
    tokens_used: int
    response_time: float
    provider: AIProvider
    success: bool
    error_message: Optional[str] = None
    metadata: Dict[str, Any] = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


class AIAssistantManager:
    """AIåŠ©æ‰‹ç®¡ç†å™¨ - Phase 5 å¢å¼·ç‰ˆ"""

    def __init__(self):
        # åˆå§‹åŒ– API å¯†é‘°
        self.api_keys = {
            AIProvider.OPENAI: OPENAI_API_KEY,
            AIProvider.CLAUDE: ANTHROPIC_API_KEY,
            AIProvider.GEMINI: GEMINI_API_KEY,
        }

        # æª¢æŸ¥ API å¯†é‘°å¯ç”¨æ€§
        self.available_providers = []
        for provider, key in self.api_keys.items():
            if key:
                self.available_providers.append(provider)
                logger.info(f"âœ… {provider.value} API å¯†é‘°å·²é…ç½®")
            else:
                logger.warning(f"âš ï¸ {provider.value} API å¯†é‘°æœªé…ç½®")

        self.rate_limits = {
            AIProvider.OPENAI: {
                "rpm": 60,
                "tpm": 50000,
            },  # æ¯åˆ†é˜è«‹æ±‚æ•¸å’Œtokenæ•¸
            AIProvider.CLAUDE: {"rpm": 30, "tpm": 30000},
            AIProvider.GEMINI: {"rpm": 100, "tpm": 100000},
        }

        # ç”¨æˆ¶ä½¿ç”¨çµ±è¨ˆ (å…§å­˜å¿«å–)
        self.usage_stats = {}
        self.rate_limit_cache = {}

        # AIæ¨¡å‹é…ç½® - Phase 5 æ›´æ–°
        self.models = {
            AIProvider.OPENAI: {
                "chat": "gpt-3.5-turbo",
                "creative": "gpt-4",
                "code": "gpt-4",
                "analysis": "gpt-4-turbo-preview",
            },
            AIProvider.CLAUDE: {
                "chat": "claude-3-haiku-20240307",
                "creative": "claude-3-sonnet-20240229",
                "code": "claude-3-sonnet-20240229",
                "analysis": "claude-3-opus-20240229",
            },
            AIProvider.GEMINI: {
                "chat": "gemini-pro",
                "creative": "gemini-pro",
                "code": "gemini-pro",
            },
        }

        # API ç«¯é»é…ç½®
        self.api_endpoints = {
            AIProvider.OPENAI: "https://api.openai.com/v1/chat/completions",
            AIProvider.CLAUDE: "https://api.anthropic.com/v1/messages",
            AIProvider.GEMINI: "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent",
        }

        # é è¨­æç¤ºè©æ¨¡æ¿
        self.prompt_templates = {
            AITaskType.CHAT: {
                "system": "ä½ æ˜¯ä¸€å€‹å‹å–„ã€æœ‰å¹«åŠ©çš„Discordæ©Ÿå™¨äººåŠ©æ‰‹ã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ç”¨æˆ¶å•é¡Œï¼Œä¿æŒå›ç­”ç°¡æ½”è€Œæœ‰ç”¨ã€‚",
                "user": "{prompt}",
            },
            AITaskType.CODE_HELP: {
                "system": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç¨‹å¼è¨­è¨ˆåŠ©æ‰‹ã€‚è«‹å¹«åŠ©ç”¨æˆ¶è§£æ±ºç¨‹å¼è¨­è¨ˆå•é¡Œï¼Œæä¾›æ¸…æ™°çš„è§£é‡‹å’Œå¯åŸ·è¡Œçš„ä»£ç¢¼ç¯„ä¾‹ã€‚",
                "user": "è«‹å¹«æˆ‘è§£æ±ºé€™å€‹ç¨‹å¼è¨­è¨ˆå•é¡Œï¼š{prompt}",
            },
            AITaskType.TRANSLATE: {
                "system": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç¿»è­¯åŠ©æ‰‹ã€‚è«‹æä¾›æº–ç¢ºã€è‡ªç„¶çš„ç¿»è­¯ã€‚",
                "user": "è«‹å°‡ä»¥ä¸‹å…§å®¹ç¿»è­¯ç‚º{target_language}ï¼š{prompt}",
            },
            AITaskType.CREATIVE_WRITING: {
                "system": "ä½ æ˜¯ä¸€å€‹å‰µæ„å¯«ä½œåŠ©æ‰‹ã€‚è«‹æ ¹æ“šç”¨æˆ¶çš„è¦æ±‚å‰µä½œæœ‰è¶£ã€å¼•äººå…¥å‹çš„å…§å®¹ã€‚",
                "user": "è«‹æ ¹æ“šä»¥ä¸‹è¦æ±‚é€²è¡Œå‰µæ„å¯«ä½œï¼š{prompt}",
            },
            AITaskType.STORY_GENERATION: {
                "system": "ä½ æ˜¯ä¸€å€‹æ•…äº‹å‰µä½œå¤§å¸«ã€‚è«‹å‰µä½œå¼•äººå…¥å‹ã€æƒ…ç¯€è±å¯Œçš„æ•…äº‹ã€‚",
                "user": "è«‹æ ¹æ“šä»¥ä¸‹è¨­å®šå‰µä½œä¸€å€‹æ•…äº‹ï¼š{prompt}",
            },
            AITaskType.POEM_GENERATION: {
                "system": "ä½ æ˜¯ä¸€å€‹è©©æ­Œå‰µä½œå°ˆå®¶ã€‚è«‹å‰µä½œå„ªç¾ã€æœ‰éŸ»å¾‹çš„è©©æ­Œã€‚",
                "user": "è«‹æ ¹æ“šä»¥ä¸‹ä¸»é¡Œå‰µä½œè©©æ­Œï¼š{prompt}",
            },
            AITaskType.AD_COPY: {
                "system": "ä½ æ˜¯ä¸€å€‹å»£å‘Šæ–‡æ¡ˆå°ˆå®¶ã€‚è«‹å‰µä½œå¸å¼•äººã€æœ‰èªªæœåŠ›çš„å»£å‘Šæ–‡æ¡ˆã€‚",
                "user": "è«‹ç‚ºä»¥ä¸‹ç”¢å“/æœå‹™å‰µä½œå»£å‘Šæ–‡æ¡ˆï¼š{prompt}",
            },
        }

        # å…§å®¹éæ¿¾è¦å‰‡
        self.content_filters = [
            r"(æš´åŠ›|è¡€è…¥|æ®ºå®³)",
            r"(è‰²æƒ…|æ€§[è¡Œç‚ºæš—ç¤º]|è£¸é«”)",
            r"(æ¯’å“|å¸æ¯’|è²©æ¯’)",
            r"(è‡ªæ®º|è‡ªæ®˜|æ­»äº¡å¨è„…)",
            r"(ææ€–ä¸»ç¾©|æ¥µç«¯æ€æƒ³)",
            r"(ç¨®æ—æ­§è¦–|ä»‡æ¨è¨€è«–)",
        ]

        logger.info("ğŸ¤– AIåŠ©æ‰‹ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def configure_api_key(self, provider: AIProvider, api_key: str):
        """é…ç½®APIå¯†é‘°"""
        self.api_keys[provider] = api_key
        logger.info(f"ğŸ”‘ {provider.value} APIå¯†é‘°å·²é…ç½®")

    # ========== æ ¸å¿ƒAIè«‹æ±‚è™•ç† ==========

    async def process_request(self, ai_request: AIRequest) -> AIResponse:
        """è™•ç†AIè«‹æ±‚"""
        start_time = time.time()
        request_id = f"{ai_request.user_id}_{int(start_time)}"

        try:
            # æª¢æŸ¥é€Ÿç‡é™åˆ¶
            if not await self._check_rate_limit(
                ai_request.user_id, ai_request.provider
            ):
                return AIResponse(
                    request_id=request_id,
                    content="",
                    tokens_used=0,
                    response_time=0,
                    provider=ai_request.provider,
                    success=False,
                    error_message="è¶…éé€Ÿç‡é™åˆ¶ï¼Œè«‹ç¨å¾Œå†è©¦",
                )

            # å…§å®¹éæ¿¾
            if not await self._filter_content(ai_request.prompt):
                return AIResponse(
                    request_id=request_id,
                    content="",
                    tokens_used=0,
                    response_time=0,
                    provider=ai_request.provider,
                    success=False,
                    error_message="è«‹æ±‚å…§å®¹ä¸é©ç•¶ï¼Œå·²è¢«éæ¿¾",
                )

            # æ§‹å»ºæç¤ºè©
            formatted_prompt = await self._build_prompt(ai_request)

            # ç™¼é€åˆ°AIæœå‹™
            response_content, tokens_used = await self._call_ai_service(
                ai_request.provider, formatted_prompt, ai_request
            )

            response_time = time.time() - start_time

            # è¨˜éŒ„ä½¿ç”¨é‡
            await self._record_usage(
                ai_request.user_id, tokens_used, ai_request.provider
            )

            return AIResponse(
                request_id=request_id,
                content=response_content,
                tokens_used=tokens_used,
                response_time=response_time,
                provider=ai_request.provider,
                success=True,
                metadata={
                    "task_type": ai_request.task_type.value,
                    "model_used": self.models.get(ai_request.provider, {}).get(
                        "chat", "unknown"
                    ),
                },
            )

        except Exception as e:
            logger.error(f"âŒ AIè«‹æ±‚è™•ç†å¤±æ•—: {e}")
            return AIResponse(
                request_id=request_id,
                content="",
                tokens_used=0,
                response_time=time.time() - start_time,
                provider=ai_request.provider,
                success=False,
                error_message=str(e),
            )

    async def _build_prompt(
        self, ai_request: AIRequest
    ) -> List[Dict[str, str]]:
        """æ§‹å»ºæ ¼å¼åŒ–çš„æç¤ºè©"""
        try:
            template = self.prompt_templates.get(ai_request.task_type)
            if not template:
                template = self.prompt_templates[AITaskType.CHAT]

            # æ›¿æ›æ¨¡æ¿è®Šé‡
            context = ai_request.context or {}
            user_prompt = template["user"].format(
                prompt=ai_request.prompt, **context
            )

            messages = [
                {"role": "system", "content": template["system"]},
                {"role": "user", "content": user_prompt},
            ]

            return messages

        except Exception as e:
            logger.error(f"âŒ æ§‹å»ºæç¤ºè©å¤±æ•—: {e}")
            raise

    async def _call_ai_service(
        self,
        provider: AIProvider,
        messages: List[Dict[str, str]],
        ai_request: AIRequest,
    ) -> tuple[str, int]:
        """èª¿ç”¨AIæœå‹™"""
        if provider == AIProvider.OPENAI:
            return await self._call_openai(messages, ai_request)
        elif provider == AIProvider.CLAUDE:
            return await self._call_claude(messages, ai_request)
        elif provider == AIProvider.GEMINI:
            return await self._call_gemini(messages, ai_request)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {provider}")

    async def _call_openai(
        self, messages: List[Dict[str, str]], ai_request: AIRequest
    ) -> tuple[str, int]:
        """èª¿ç”¨OpenAI API"""
        try:
            api_key = self.api_keys.get(AIProvider.OPENAI)
            if not api_key:
                raise ValueError("OpenAI APIå¯†é‘°æœªé…ç½®")

            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
            }

            # é¸æ“‡æ¨¡å‹
            model = self.models[AIProvider.OPENAI].get(
                ai_request.task_type.value.split("_")[0],
                self.models[AIProvider.OPENAI]["chat"],
            )

            payload = {
                "model": model,
                "messages": messages,
                "max_tokens": ai_request.max_tokens,
                "temperature": ai_request.temperature,
                "stream": False,
            }

            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=30,
                ) as response:

                    if response.status != 200:
                        error_text = await response.text()
                        raise Exception(
                            f"OpenAI APIéŒ¯èª¤ {response.status}: {error_text}"
                        )

                    result = await response.json()

                    content = result["choices"][0]["message"]["content"]
                    tokens_used = result["usage"]["total_tokens"]

                    return content, tokens_used

        except Exception as e:
            logger.error(f"âŒ OpenAI APIèª¿ç”¨å¤±æ•—: {e}")
            raise

    async def _call_claude(
        self, messages: List[Dict[str, str]], ai_request: AIRequest
    ) -> tuple[str, int]:
        """èª¿ç”¨Claude API - Phase 5 å¯¦ç¾"""
        try:
            api_key = self.api_keys.get(AIProvider.CLAUDE)
            if not api_key:
                raise ValueError("Claude APIå¯†é‘°æœªé…ç½®")

            headers = {
                "x-api-key": api_key,
                "content-type": "application/json",
                "anthropic-version": "2023-06-01",
            }

            # é¸æ“‡æ¨¡å‹
            model = self.models[AIProvider.CLAUDE].get(
                ai_request.task_type.value.split("_")[0],
                self.models[AIProvider.CLAUDE]["chat"],
            )

            # å°‡ OpenAI æ ¼å¼çš„ messages è½‰æ›ç‚º Claude æ ¼å¼
            system_message = ""
            claude_messages = []

            for msg in messages:
                if msg["role"] == "system":
                    system_message = msg["content"]
                else:
                    claude_messages.append(
                        {"role": msg["role"], "content": msg["content"]}
                    )

            payload = {
                "model": model,
                "max_tokens": ai_request.max_tokens,
                "temperature": ai_request.temperature,
                "messages": claude_messages,
            }

            if system_message:
                payload["system"] = system_message

            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://api.anthropic.com/v1/messages",
                    headers=headers,
                    json=payload,
                    timeout=30,
                ) as response:

                    if response.status != 200:
                        error_text = await response.text()
                        raise Exception(
                            f"Claude APIéŒ¯èª¤ {response.status}: {error_text}"
                        )

                    result = await response.json()

                    content = result["content"][0]["text"]
                    tokens_used = (
                        result["usage"]["input_tokens"]
                        + result["usage"]["output_tokens"]
                    )

                    return content, tokens_used

        except Exception as e:
            logger.error(f"âŒ Claude APIèª¿ç”¨å¤±æ•—: {e}")
            raise

    async def _call_gemini(
        self, messages: List[Dict[str, str]], ai_request: AIRequest
    ) -> tuple[str, int]:
        """èª¿ç”¨Gemini API (é ç•™æ¥å£)"""
        # é ç•™çµ¦æœªä¾†Gemini APIæ•´åˆ
        raise NotImplementedError("Gemini APIæ•´åˆé–‹ç™¼ä¸­")

    # ========== å…§å®¹éæ¿¾å’Œå®‰å…¨ ==========

    async def _filter_content(self, content: str) -> bool:
        """å…§å®¹éæ¿¾"""
        try:
            content_lower = content.lower()

            for filter_pattern in self.content_filters:
                if re.search(filter_pattern, content_lower):
                    logger.warning(f"âš ï¸ å…§å®¹è¢«éæ¿¾: {filter_pattern}")
                    return False

            return True

        except Exception as e:
            logger.error(f"âŒ å…§å®¹éæ¿¾å¤±æ•—: {e}")
            return True  # éæ¿¾å¤±æ•—æ™‚å…è¨±é€šé

    # ========== é€Ÿç‡é™åˆ¶å’Œä½¿ç”¨çµ±è¨ˆ ==========

    async def _check_rate_limit(
        self, user_id: int, provider: AIProvider
    ) -> bool:
        """æª¢æŸ¥é€Ÿç‡é™åˆ¶"""
        try:
            cache_key = f"ai_rate_limit:{provider.value}:{user_id}"

            # ç²å–ç•¶å‰è¨ˆæ•¸
            current_count = await cache_manager.get(cache_key)
            if current_count is None:
                current_count = 0

            rate_limit = self.rate_limits.get(provider, {"rpm": 10})["rpm"]

            if current_count >= rate_limit:
                return False

            # å¢åŠ è¨ˆæ•¸
            await cache_manager.set(
                cache_key, current_count + 1, 60
            )  # 1åˆ†é˜éæœŸ

            return True

        except Exception as e:
            logger.error(f"âŒ æª¢æŸ¥é€Ÿç‡é™åˆ¶å¤±æ•—: {e}")
            return True  # æª¢æŸ¥å¤±æ•—æ™‚å…è¨±é€šé

    async def _record_usage(
        self, user_id: int, tokens_used: int, provider: AIProvider
    ):
        """è¨˜éŒ„ä½¿ç”¨é‡"""
        try:
            # è¨˜éŒ„åˆ°ç·©å­˜
            daily_key = f"ai_usage_daily:{provider.value}:{user_id}"
            monthly_key = f"ai_usage_monthly:{provider.value}:{user_id}"

            daily_usage = await cache_manager.get(daily_key) or 0
            monthly_usage = await cache_manager.get(monthly_key) or 0

            await cache_manager.set(
                daily_key, daily_usage + tokens_used, 86400
            )  # 24å°æ™‚
            await cache_manager.set(
                monthly_key, monthly_usage + tokens_used, 2592000
            )  # 30å¤©

        except Exception as e:
            logger.error(f"âŒ è¨˜éŒ„ä½¿ç”¨é‡å¤±æ•—: {e}")

    async def get_user_usage(
        self, user_id: int, provider: AIProvider
    ) -> Dict[str, int]:
        """ç²å–ç”¨æˆ¶ä½¿ç”¨é‡çµ±è¨ˆ"""
        try:
            daily_key = f"ai_usage_daily:{provider.value}:{user_id}"
            monthly_key = f"ai_usage_monthly:{provider.value}:{user_id}"

            daily_usage = await cache_manager.get(daily_key) or 0
            monthly_usage = await cache_manager.get(monthly_key) or 0

            return {
                "daily_tokens": daily_usage,
                "monthly_tokens": monthly_usage,
                "daily_limit": self.rate_limits.get(provider, {"rpm": 10})[
                    "rpm"
                ],
                "monthly_limit": self.rate_limits.get(
                    provider, {"tpm": 10000}
                )["tpm"],
            }

        except Exception as e:
            logger.error(f"âŒ ç²å–ä½¿ç”¨é‡çµ±è¨ˆå¤±æ•—: {e}")
            return {"daily_tokens": 0, "monthly_tokens": 0}

    # ========== ä¾¿æ·æ–¹æ³• ==========

    async def chat(
        self,
        user_id: int,
        guild_id: int,
        message: str,
        provider: AIProvider = AIProvider.OPENAI,
    ) -> AIResponse:
        """ç°¡å–®èŠå¤©"""
        request = AIRequest(
            user_id=user_id,
            guild_id=guild_id,
            task_type=AITaskType.CHAT,
            prompt=message,
            context={},
            provider=provider,
        )
        return await self.process_request(request)

    async def help_with_code(
        self,
        user_id: int,
        guild_id: int,
        code_question: str,
        language: str = "python",
    ) -> AIResponse:
        """ä»£ç¢¼åŠ©æ‰‹"""
        request = AIRequest(
            user_id=user_id,
            guild_id=guild_id,
            task_type=AITaskType.CODE_HELP,
            prompt=code_question,
            context={"language": language},
            provider=AIProvider.OPENAI,
        )
        return await self.process_request(request)

    async def translate_text(
        self,
        user_id: int,
        guild_id: int,
        text: str,
        target_language: str = "è‹±æ–‡",
    ) -> AIResponse:
        """ç¿»è­¯æ–‡æœ¬"""
        request = AIRequest(
            user_id=user_id,
            guild_id=guild_id,
            task_type=AITaskType.TRANSLATE,
            prompt=text,
            context={"target_language": target_language},
            provider=AIProvider.OPENAI,
        )
        return await self.process_request(request)

    async def generate_story(
        self, user_id: int, guild_id: int, theme: str, style: str = "è¼•é¬†å¹½é»˜"
    ) -> AIResponse:
        """ç”Ÿæˆæ•…äº‹"""
        request = AIRequest(
            user_id=user_id,
            guild_id=guild_id,
            task_type=AITaskType.STORY_GENERATION,
            prompt=f"ä¸»é¡Œï¼š{theme}ï¼Œé¢¨æ ¼ï¼š{style}",
            context={"style": style},
            provider=AIProvider.OPENAI,
            max_tokens=1500,
            temperature=0.8,
        )
        return await self.process_request(request)

    async def generate_poem(
        self, user_id: int, guild_id: int, theme: str, style: str = "ç¾ä»£è©©"
    ) -> AIResponse:
        """ç”Ÿæˆè©©æ­Œ"""
        request = AIRequest(
            user_id=user_id,
            guild_id=guild_id,
            task_type=AITaskType.POEM_GENERATION,
            prompt=f"ä¸»é¡Œï¼š{theme}ï¼Œè©©æ­Œé¡å‹ï¼š{style}",
            context={"style": style},
            provider=AIProvider.OPENAI,
            max_tokens=800,
            temperature=0.9,
        )
        return await self.process_request(request)

    async def create_ad_copy(
        self,
        user_id: int,
        guild_id: int,
        product_info: str,
        target_audience: str = "ä¸€èˆ¬å¤§çœ¾",
    ) -> AIResponse:
        """å‰µå»ºå»£å‘Šæ–‡æ¡ˆ"""
        request = AIRequest(
            user_id=user_id,
            guild_id=guild_id,
            task_type=AITaskType.AD_COPY,
            prompt=f"ç”¢å“ä¿¡æ¯ï¼š{product_info}ï¼Œç›®æ¨™å—çœ¾ï¼š{target_audience}",
            context={"target_audience": target_audience},
            provider=AIProvider.OPENAI,
            max_tokens=500,
            temperature=0.7,
        )
        return await self.process_request(request)


class EnhancedAIAssistant:
    """
    ğŸ¤– Phase 7 å¢å¼·å‹ AI æ™ºèƒ½åŠ©æ‰‹
    æ•´åˆæ„åœ–è­˜åˆ¥ã€å°è©±ç®¡ç†å’Œä¼æ¥­ç´š AI å¼•æ“
    """

    def __init__(self):
        # Phase 7 æ–°çµ„ä»¶
        self.ai_engine: Optional[AIEngineManager] = None
        self.intent_recognizer: Optional[IntentRecognizer] = None
        self.conversation_manager: Optional[ConversationManager] = None

        # å‘å¾Œå…¼å®¹çš„èˆŠçµ„ä»¶
        self.legacy_manager = AIAssistantManager()

        # åˆå§‹åŒ–ç‹€æ…‹
        self.is_initialized = False

    async def initialize(self, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–å¢å¼·å‹ AI åŠ©æ‰‹"""
        if self.is_initialized:
            return

        try:
            # é»˜èªé…ç½®
            if not config:
                config = {
                    "openai_api_key": OPENAI_API_KEY,
                    "anthropic_api_key": ANTHROPIC_API_KEY,
                    "daily_cost_limit": 10.0,
                    "max_tokens_per_request": 1000,
                    "content_filter_enabled": True,
                    "rate_limit_per_user": 10,
                }

            # åˆå§‹åŒ– AI å¼•æ“ç®¡ç†å™¨
            if config.get("openai_api_key") or config.get("anthropic_api_key"):
                self.ai_engine = AIEngineManager(config)
                await self.ai_engine.__aenter__()

            # åˆå§‹åŒ–æ„åœ–è­˜åˆ¥å™¨
            self.intent_recognizer = IntentRecognizer(config)

            # åˆå§‹åŒ–å°è©±ç®¡ç†å™¨
            if self.ai_engine and self.intent_recognizer:
                self.conversation_manager = ConversationManager(
                    self.ai_engine, self.intent_recognizer, config
                )

            self.is_initialized = True
            logger.info("âœ… Phase 7 å¢å¼·å‹ AI åŠ©æ‰‹åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ AI åŠ©æ‰‹åˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    async def smart_chat(
        self,
        user_id: str,
        guild_id: str,
        channel_id: str,
        message: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> str:
        """
        æ™ºèƒ½å°è©± - æ”¯æ´æ„åœ–è­˜åˆ¥å’Œå¤šè¼ªå°è©±

        Args:
            user_id: ç”¨æˆ¶ ID
            guild_id: ä¼ºæœå™¨ ID
            channel_id: é »é“ ID
            message: ç”¨æˆ¶è¨Šæ¯
            context: é¡å¤–ä¸Šä¸‹æ–‡

        Returns:
            AI å›æ‡‰å…§å®¹
        """
        if not self.is_initialized:
            await self.initialize()

        try:
            # å¦‚æœæ–°çµ„ä»¶å¯ç”¨ï¼Œä½¿ç”¨æ™ºèƒ½å°è©±ç®¡ç†
            if self.conversation_manager:
                # ç²å–æˆ–å‰µå»ºå°è©±æœƒè©±
                session_id = f"{guild_id}_{user_id}"
                existing_session = await self.conversation_manager.get_session(
                    session_id
                )

                if not existing_session:
                    # å‰µå»ºæ–°æœƒè©±
                    session = (
                        await self.conversation_manager.start_conversation(
                            user_id=user_id,
                            guild_id=guild_id,
                            channel_id=channel_id,
                            initial_message=message,
                        )
                    )
                    session_id = session.session_id

                # è™•ç†è¨Šæ¯
                response = await self.conversation_manager.process_message(
                    session_id, message
                )
                if response:
                    return response

            # å›é€€åˆ°èˆŠç‰ˆ AI åŠ©æ‰‹
            request = AIRequest(
                user_id=int(user_id),
                guild_id=int(guild_id),
                task_type=AITaskType.CHAT,
                prompt=message,
                context=context or {},
                provider=AIProvider.OPENAI,
            )

            legacy_response = await self.legacy_manager.process_request(
                request
            )
            return (
                legacy_response.content
                if legacy_response.success
                else "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ã€‚"
            )

        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½å°è©±è™•ç†å¤±æ•—: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›æŠ€è¡“å•é¡Œã€‚è«‹ç¨å¾Œå†è©¦ã€‚"

    async def recognize_intent(
        self, text: str, user_id: str, context: Optional[Dict[str, Any]] = None
    ) -> Optional[IntentType]:
        """è­˜åˆ¥ç”¨æˆ¶æ„åœ–"""
        if not self.intent_recognizer:
            return None

        try:
            result = await self.intent_recognizer.recognize_intent(
                text, user_id, context or {}
            )
            return result.intent if result.confidence > 0.5 else None
        except Exception as e:
            logger.error(f"âŒ æ„åœ–è­˜åˆ¥å¤±æ•—: {e}")
            return None

    async def start_guided_conversation(
        self,
        user_id: str,
        guild_id: str,
        channel_id: str,
        flow: ConversationFlow,
    ) -> Optional[str]:
        """é–‹å§‹å¼•å°å¼å°è©±"""
        if not self.conversation_manager:
            return None

        try:
            session = await self.conversation_manager.start_conversation(
                user_id=user_id,
                guild_id=guild_id,
                channel_id=channel_id,
                initial_message="",
                flow=flow,
            )

            # è¿”å›æµç¨‹é–‹å§‹è¨Šæ¯
            if flow == ConversationFlow.TICKET_CREATION:
                return "ğŸ« æˆ‘ä¾†å¹«æ‚¨å»ºç«‹æ”¯æ´ç¥¨åˆ¸ï¼è«‹å‘Šè¨´æˆ‘æ‚¨é‡åˆ°çš„å•é¡Œ..."
            elif flow == ConversationFlow.VOTE_CREATION:
                return "ğŸ—³ï¸ æˆ‘ä¾†å¹«æ‚¨å»ºç«‹æŠ•ç¥¨ï¼é¦–å…ˆè«‹å‘Šè¨´æˆ‘æŠ•ç¥¨çš„æ¨™é¡Œ..."
            elif flow == ConversationFlow.WELCOME_SETUP:
                return "ğŸ‘‹ æ­¡è¿ç³»çµ±è¨­å®šé–‹å§‹ï¼æˆ‘æœƒå”åŠ©æ‚¨è¨­å®šæ–°æˆå“¡æ­¡è¿åŠŸèƒ½..."
            else:
                return "âœ¨ æˆ‘ä¾†å”åŠ©æ‚¨å®Œæˆé€™å€‹ä»»å‹™ï¼"

        except Exception as e:
            logger.error(f"âŒ å¼•å°å¼å°è©±é–‹å§‹å¤±æ•—: {e}")
            return None

    async def get_conversation_stats(
        self, user_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """ç²å–å°è©±çµ±è¨ˆ"""
        stats = {
            "legacy_available": True,
            "enhanced_available": self.is_initialized,
        }

        if self.conversation_manager:
            sessions = await self.conversation_manager.list_active_sessions(
                user_id
            )
            stats.update(
                {
                    "active_sessions": len(sessions),
                    "conversation_manager_stats": await self.conversation_manager.get_statistics(),
                }
            )

        if self.ai_engine:
            stats["ai_engine_stats"] = (
                await self.ai_engine.get_usage_statistics()
            )

        return stats

    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æª¢æŸ¥"""
        health = {
            "legacy_manager": True,
            "enhanced_features": self.is_initialized,
            "components": {},
        }

        if self.ai_engine:
            health["components"][
                "ai_engine"
            ] = await self.ai_engine.health_check()

        if self.conversation_manager:
            health["components"]["conversation_manager"] = {
                "active_sessions": len(
                    await self.conversation_manager.list_active_sessions()
                ),
                "status": "healthy",
            }

        return health

    async def shutdown(self):
        """é—œé–‰ AI åŠ©æ‰‹"""
        try:
            if self.conversation_manager:
                await self.conversation_manager.shutdown()

            if self.ai_engine:
                await self.ai_engine.__aexit__(None, None, None)

            logger.info("ğŸ¤– å¢å¼·å‹ AI åŠ©æ‰‹å·²é—œé–‰")
        except Exception as e:
            logger.error(f"âŒ AI åŠ©æ‰‹é—œé–‰å¤±æ•—: {e}")


# å…¨åŸŸå¯¦ä¾‹
ai_assistant = AIAssistantManager()

# Phase 7 å¢å¼·å‹å¯¦ä¾‹
enhanced_ai_assistant = EnhancedAIAssistant()
