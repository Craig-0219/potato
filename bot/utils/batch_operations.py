# bot/utils/batch_operations.py - ç¥¨åˆ¸ç³»çµ±æ‰¹æ¬¡æ“ä½œå·¥å…·

import discord
import asyncio
import csv
import json
import io
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass
from enum import Enum

from bot.db.ticket_dao import TicketDAO
from bot.services.ticket_manager import (
    StatisticsService, NotificationService
)
from bot.utils.ticket_constants import (
    TicketConstants, get_priority_emoji, get_status_emoji,
    SUCCESS_MESSAGES, ERROR_MESSAGES
)
from bot.utils.debug import debug_log


class BatchOperationType(Enum):
    """æ‰¹æ¬¡æ“ä½œé¡å‹"""
    CLOSE_INACTIVE = "close_inactive"
    CLOSE_OLD = "close_old"
    ARCHIVE_CLOSED = "archive_closed"
    EXPORT_CSV = "export_csv"
    EXPORT_JSON = "export_json"
    CLEANUP_CACHE = "cleanup_cache"
    UPDATE_STATISTICS = "update_statistics"
    SEND_REMINDERS = "send_reminders"
    BULK_ASSIGN = "bulk_assign"
    BULK_PRIORITY = "bulk_priority"
    BULK_TAG = "bulk_tag"


@dataclass
class BatchOperationResult:
    """æ‰¹æ¬¡æ“ä½œçµæœ"""
    success: bool
    processed_count: int
    error_count: int
    total_count: int
    errors: List[str]
    data: Optional[Any] = None
    execution_time: float = 0.0
    
    @property
    def success_rate(self) -> float:
        """æˆåŠŸç‡"""
        if self.total_count == 0:
            return 100.0
        return (self.processed_count / self.total_count) * 100
    
    def add_error(self, error: str):
        """æ·»åŠ éŒ¯èª¤"""
        self.errors.append(error)
        self.error_count += 1


@dataclass
class BatchOperationConfig:
    """æ‰¹æ¬¡æ“ä½œé…ç½®"""
    operation_type: BatchOperationType
    guild_id: int
    parameters: Dict[str, Any]
    dry_run: bool = False
    batch_size: int = 50
    delay_between_batches: float = 1.0
    max_concurrent: int = 5
    notify_on_completion: bool = True
    log_channel_id: Optional[int] = None


class BatchOperationManager:
    """æ‰¹æ¬¡æ“ä½œç®¡ç†å™¨"""
    
    def __init__(self):
        self.dao = TicketDAO()
        self.statistics_service = StatisticsService()
        self.notification_service = NotificationService()
        
        # æ“ä½œæ˜ å°„
        self.operation_handlers = {
            BatchOperationType.CLOSE_INACTIVE: self._close_inactive_tickets,
            BatchOperationType.CLOSE_OLD: self._close_old_tickets,
            BatchOperationType.ARCHIVE_CLOSED: self._archive_closed_tickets,
            BatchOperationType.EXPORT_CSV: self._export_tickets_csv,
            BatchOperationType.EXPORT_JSON: self._export_tickets_json,
            BatchOperationType.CLEANUP_CACHE: self._cleanup_cache,
            BatchOperationType.UPDATE_STATISTICS: self._update_statistics,
            BatchOperationType.SEND_REMINDERS: self._send_reminders,
            BatchOperationType.BULK_ASSIGN: self._bulk_assign_tickets,
            BatchOperationType.BULK_PRIORITY: self._bulk_update_priority,
            BatchOperationType.BULK_TAG: self._bulk_update_tags
        }
    
    async def execute_operation(self, config: BatchOperationConfig) -> BatchOperationResult:
        """åŸ·è¡Œæ‰¹æ¬¡æ“ä½œ"""
        start_time = datetime.now()
        
        try:
            debug_log(f"[BatchOperation] é–‹å§‹åŸ·è¡Œ {config.operation_type.value} æ“ä½œ")
            
            # é©—è­‰é…ç½®
            validation_result = await self._validate_config(config)
            if not validation_result.success:
                return validation_result
            
            # å–å¾—æ“ä½œè™•ç†å™¨
            handler = self.operation_handlers.get(config.operation_type)
            if not handler:
                return BatchOperationResult(
                    success=False,
                    processed_count=0,
                    error_count=1,
                    total_count=0,
                    errors=[f"ä¸æ”¯æ´çš„æ“ä½œé¡å‹ï¼š{config.operation_type.value}"]
                )
            
            # åŸ·è¡Œæ“ä½œ
            result = await handler(config)
            
            # è¨ˆç®—åŸ·è¡Œæ™‚é–“
            end_time = datetime.now()
            result.execution_time = (end_time - start_time).total_seconds()
            
            # ç™¼é€å®Œæˆé€šçŸ¥
            if config.notify_on_completion and result.success:
                await self._send_completion_notification(config, result)
            
            debug_log(f"[BatchOperation] æ“ä½œå®Œæˆ - è™•ç†: {result.processed_count}, éŒ¯èª¤: {result.error_count}")
            
            return result
            
        except Exception as e:
            debug_log(f"[BatchOperation] åŸ·è¡Œæ“ä½œéŒ¯èª¤ï¼š{e}")
            
            end_time = datetime.now()
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=1,
                total_count=0,
                errors=[f"åŸ·è¡ŒéŒ¯èª¤ï¼š{str(e)}"],
                execution_time=(end_time - start_time).total_seconds()
            )
    
    async def _validate_config(self, config: BatchOperationConfig) -> BatchOperationResult:
        """é©—è­‰é…ç½®"""
        errors = []
        
        # åŸºæœ¬é©—è­‰
        if config.batch_size < 1 or config.batch_size > 1000:
            errors.append("æ‰¹æ¬¡å¤§å°å¿…é ˆåœ¨ 1-1000 ä¹‹é–“")
        
        if config.max_concurrent < 1 or config.max_concurrent > 20:
            errors.append("ä½µç™¼æ•¸å¿…é ˆåœ¨ 1-20 ä¹‹é–“")
        
        # ç‰¹å®šæ“ä½œé©—è­‰
        if config.operation_type in [BatchOperationType.CLOSE_INACTIVE, BatchOperationType.CLOSE_OLD]:
            if 'hours_threshold' not in config.parameters:
                errors.append("ç¼ºå°‘å¿…è¦åƒæ•¸ï¼šhours_threshold")
            elif not isinstance(config.parameters['hours_threshold'], (int, float)):
                errors.append("hours_threshold å¿…é ˆæ˜¯æ•¸å­—")
        
        if config.operation_type in [BatchOperationType.BULK_ASSIGN]:
            if 'staff_id' not in config.parameters:
                errors.append("ç¼ºå°‘å¿…è¦åƒæ•¸ï¼šstaff_id")
        
        if config.operation_type in [BatchOperationType.BULK_PRIORITY]:
            if 'priority' not in config.parameters:
                errors.append("ç¼ºå°‘å¿…è¦åƒæ•¸ï¼špriority")
            elif config.parameters['priority'] not in TicketConstants.PRIORITIES:
                errors.append("ç„¡æ•ˆçš„å„ªå…ˆç´š")
        
        if errors:
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=len(errors),
                total_count=0,
                errors=errors
            )
        
        return BatchOperationResult(
            success=True,
            processed_count=0,
            error_count=0,
            total_count=0,
            errors=[]
        )
    
    # ===== ç¥¨åˆ¸é—œé–‰æ“ä½œ =====
    
    async def _close_inactive_tickets(self, config: BatchOperationConfig) -> BatchOperationResult:
        """é—œé–‰ç„¡æ´»å‹•ç¥¨åˆ¸"""
        try:
            hours_threshold = config.parameters['hours_threshold']
            cutoff_time = datetime.now(timezone.utc) - timedelta(hours=hours_threshold)
            
            # å–å¾—ç„¡æ´»å‹•ç¥¨åˆ¸
            async with self.dao.db_pool.acquire() as conn:
                async with conn.cursor(dictionary=True) as cursor:
                    await cursor.execute(
                        """
                        SELECT ticket_id, channel_id, discord_id, type, priority, created_at, last_activity
                        FROM tickets
                        WHERE guild_id = %s 
                        AND status = 'open'
                        AND last_activity < %s
                        ORDER BY last_activity ASC
                        """,
                        (config.guild_id, cutoff_time)
                    )
                    tickets_to_close = await cursor.fetchall()
            
            if not tickets_to_close:
                return BatchOperationResult(
                    success=True,
                    processed_count=0,
                    error_count=0,
                    total_count=0,
                    errors=[]
                )
            
            result = BatchOperationResult(
                success=True,
                processed_count=0,
                error_count=0,
                total_count=len(tickets_to_close),
                errors=[]
            )
            
            # å¦‚æœæ˜¯æ¼”ç¿’æ¨¡å¼ï¼Œåªè¿”å›çµ±è¨ˆ
            if config.dry_run:
                result.data = {
                    'tickets_to_close': [
                        {
                            'ticket_id': t['ticket_id'],
                            'type': t['type'],
                            'inactive_hours': (datetime.now(timezone.utc) - t['last_activity']).total_seconds() / 3600
                        }
                        for t in tickets_to_close
                    ]
                }
                return result
            
            # æ‰¹æ¬¡è™•ç†
            for i in range(0, len(tickets_to_close), config.batch_size):
                batch = tickets_to_close[i:i + config.batch_size]
                
                # è™•ç†æ‰¹æ¬¡
                batch_tasks = []
                for ticket in batch:
                    task = self._close_single_ticket(
                        ticket, 
                        f"è‡ªå‹•é—œé–‰ï¼šç„¡æ´»å‹•è¶…é {hours_threshold} å°æ™‚"
                    )
                    batch_tasks.append(task)
                
                # ä½µç™¼åŸ·è¡Œ
                batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
                
                # è™•ç†çµæœ
                for j, batch_result in enumerate(batch_results):
                    if isinstance(batch_result, Exception):
                        result.add_error(f"ç¥¨åˆ¸ #{batch[j]['ticket_id']:04d}: {str(batch_result)}")
                    elif batch_result:
                        result.processed_count += 1
                    else:
                        result.add_error(f"ç¥¨åˆ¸ #{batch[j]['ticket_id']:04d}: é—œé–‰å¤±æ•—")
                
                # æ‰¹æ¬¡é–“å»¶é²
                if i + config.batch_size < len(tickets_to_close):
                    await asyncio.sleep(config.delay_between_batches)
            
            return result
            
        except Exception as e:
            debug_log(f"[BatchOperation] é—œé–‰ç„¡æ´»å‹•ç¥¨åˆ¸éŒ¯èª¤ï¼š{e}")
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=1,
                total_count=0,
                errors=[str(e)]
            )
    
    async def _close_old_tickets(self, config: BatchOperationConfig) -> BatchOperationResult:
        """é—œé–‰èˆŠç¥¨åˆ¸"""
        try:
            hours_threshold = config.parameters['hours_threshold']
            cutoff_time = datetime.now(timezone.utc) - timedelta(hours=hours_threshold)
            
            # å–å¾—èˆŠç¥¨åˆ¸
            async with self.dao.db_pool.acquire() as conn:
                async with conn.cursor(dictionary=True) as cursor:
                    await cursor.execute(
                        """
                        SELECT ticket_id, channel_id, discord_id, type, priority, created_at
                        FROM tickets
                        WHERE guild_id = %s 
                        AND status = 'open'
                        AND created_at < %s
                        ORDER BY created_at ASC
                        """,
                        (config.guild_id, cutoff_time)
                    )
                    tickets_to_close = await cursor.fetchall()
            
            result = BatchOperationResult(
                success=True,
                processed_count=0,
                error_count=0,
                total_count=len(tickets_to_close),
                errors=[]
            )
            
            if config.dry_run:
                result.data = {
                    'tickets_to_close': [
                        {
                            'ticket_id': t['ticket_id'],
                            'type': t['type'],
                            'age_hours': (datetime.now(timezone.utc) - t['created_at']).total_seconds() / 3600
                        }
                        for t in tickets_to_close
                    ]
                }
                return result
            
            # æ‰¹æ¬¡é—œé–‰
            for i in range(0, len(tickets_to_close), config.batch_size):
                batch = tickets_to_close[i:i + config.batch_size]
                
                batch_tasks = []
                for ticket in batch:
                    task = self._close_single_ticket(
                        ticket,
                        f"è‡ªå‹•é—œé–‰ï¼šç¥¨åˆ¸è¶…é {hours_threshold} å°æ™‚"
                    )
                    batch_tasks.append(task)
                
                batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
                
                for j, batch_result in enumerate(batch_results):
                    if isinstance(batch_result, Exception):
                        result.add_error(f"ç¥¨åˆ¸ #{batch[j]['ticket_id']:04d}: {str(batch_result)}")
                    elif batch_result:
                        result.processed_count += 1
                    else:
                        result.add_error(f"ç¥¨åˆ¸ #{batch[j]['ticket_id']:04d}: é—œé–‰å¤±æ•—")
                
                if i + config.batch_size < len(tickets_to_close):
                    await asyncio.sleep(config.delay_between_batches)
            
            return result
            
        except Exception as e:
            debug_log(f"[BatchOperation] é—œé–‰èˆŠç¥¨åˆ¸éŒ¯èª¤ï¼š{e}")
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=1,
                total_count=0,
                errors=[str(e)]
            )
    
    async def _close_single_ticket(self, ticket: Dict[str, Any], reason: str) -> bool:
        """é—œé–‰å–®ä¸€ç¥¨åˆ¸"""
        try:
            success = await self.dao.close_ticket(
                ticket['channel_id'],
                'system',
                reason
            )
            
            if success:
                debug_log(f"[BatchOperation] å·²é—œé–‰ç¥¨åˆ¸ #{ticket['ticket_id']:04d}")
            
            return success
            
        except Exception as e:
            debug_log(f"[BatchOperation] é—œé–‰ç¥¨åˆ¸ #{ticket['ticket_id']:04d} éŒ¯èª¤ï¼š{e}")
            return False
    
    # ===== æ­¸æª”æ“ä½œ =====
    
    async def _archive_closed_tickets(self, config: BatchOperationConfig) -> BatchOperationResult:
        """æ­¸æª”å·²é—œé–‰ç¥¨åˆ¸"""
        try:
            days_threshold = config.parameters.get('days_threshold', 30)
            cutoff_time = datetime.now(timezone.utc) - timedelta(days=days_threshold)
            
            # å–å¾—è¦æ­¸æª”çš„ç¥¨åˆ¸
            async with self.dao.db_pool.acquire() as conn:
                async with conn.cursor(dictionary=True) as cursor:
                    await cursor.execute(
                        """
                        SELECT ticket_id, type, closed_at
                        FROM tickets
                        WHERE guild_id = %s 
                        AND status = 'closed'
                        AND closed_at < %s
                        ORDER BY closed_at ASC
                        """,
                        (config.guild_id, cutoff_time)
                    )
                    tickets_to_archive = await cursor.fetchall()
            
            result = BatchOperationResult(
                success=True,
                processed_count=0,
                error_count=0,
                total_count=len(tickets_to_archive),
                errors=[]
            )
            
            if config.dry_run:
                result.data = {
                    'tickets_to_archive': [
                        {
                            'ticket_id': t['ticket_id'],
                            'type': t['type'],
                            'closed_days_ago': (datetime.now(timezone.utc) - t['closed_at']).days
                        }
                        for t in tickets_to_archive
                    ]
                }
                return result
            
            # æ‰¹æ¬¡æ­¸æª”
            for i in range(0, len(tickets_to_archive), config.batch_size):
                batch = tickets_to_archive[i:i + config.batch_size]
                
                # æ›´æ–°ç‹€æ…‹ç‚ºæ­¸æª”
                ticket_ids = [t['ticket_id'] for t in batch]
                
                try:
                    async with self.dao.db_pool.acquire() as conn:
                        async with conn.cursor() as cursor:
                            await cursor.execute(
                                f"UPDATE tickets SET status = 'archived' WHERE ticket_id IN ({','.join(['%s'] * len(ticket_ids))})",
                                ticket_ids
                            )
                            await conn.commit()
                            
                            result.processed_count += cursor.rowcount
                
                except Exception as e:
                    result.add_error(f"æ­¸æª”æ‰¹æ¬¡å¤±æ•—ï¼š{str(e)}")
                
                if i + config.batch_size < len(tickets_to_archive):
                    await asyncio.sleep(config.delay_between_batches)
            
            return result
            
        except Exception as e:
            debug_log(f"[BatchOperation] æ­¸æª”ç¥¨åˆ¸éŒ¯èª¤ï¼š{e}")
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=1,
                total_count=0,
                errors=[str(e)]
            )
    
    # ===== åŒ¯å‡ºæ“ä½œ =====
    
    async def _export_tickets_csv(self, config: BatchOperationConfig) -> BatchOperationResult:
        """åŒ¯å‡ºç¥¨åˆ¸ç‚º CSV"""
        try:
            # å–å¾—åŒ¯å‡ºåƒæ•¸
            status_filter = config.parameters.get('status', 'all')
            start_date = config.parameters.get('start_date')
            end_date = config.parameters.get('end_date')
            
            # å»ºç«‹æŸ¥è©¢æ¢ä»¶
            where_conditions = ["guild_id = %s"]
            params = [config.guild_id]
            
            if status_filter != 'all':
                where_conditions.append("status = %s")
                params.append(status_filter)
            
            if start_date:
                where_conditions.append("created_at >= %s")
                params.append(start_date)
            
            if end_date:
                where_conditions.append("created_at <= %s")
                params.append(end_date)
            
            where_clause = " AND ".join(where_conditions)
            
            # å–å¾—ç¥¨åˆ¸è³‡æ–™
            async with self.dao.db_pool.acquire() as conn:
                async with conn.cursor(dictionary=True) as cursor:
                    await cursor.execute(
                        f"""
                        SELECT 
                            ticket_id, discord_id, username, type, priority, status,
                            created_at, closed_at, closed_by, close_reason,
                            assigned_to, rating, rating_feedback, tags,
                            last_activity
                        FROM tickets
                        WHERE {where_clause}
                        ORDER BY ticket_id DESC
                        """,
                        params
                    )
                    tickets = await cursor.fetchall()
            
            if not tickets:
                return BatchOperationResult(
                    success=True,
                    processed_count=0,
                    error_count=0,
                    total_count=0,
                    errors=["æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„ç¥¨åˆ¸è³‡æ–™"]
                )
            
            # å»ºç«‹ CSV å…§å®¹
            csv_buffer = io.StringIO()
            fieldnames = [
                'ç¥¨åˆ¸ID', 'ç”¨æˆ¶ID', 'ç”¨æˆ¶å', 'é¡å‹', 'å„ªå…ˆç´š', 'ç‹€æ…‹',
                'å»ºç«‹æ™‚é–“', 'é—œé–‰æ™‚é–“', 'é—œé–‰è€…', 'é—œé–‰åŸå› ',
                'æŒ‡æ´¾çµ¦', 'è©•åˆ†', 'è©•åˆ†å›é¥‹', 'æ¨™ç±¤', 'æœ€å¾Œæ´»å‹•'
            ]
            
            writer = csv.DictWriter(csv_buffer, fieldnames=fieldnames)
            writer.writeheader()
            
            for ticket in tickets:
                # è™•ç†æ¨™ç±¤
                tags = ""
                if ticket.get('tags'):
                    try:
                        tag_list = json.loads(ticket['tags']) if isinstance(ticket['tags'], str) else ticket['tags']
                        tags = ', '.join(tag_list) if tag_list else ""
                    except:
                        tags = str(ticket['tags'])
                
                writer.writerow({
                    'ç¥¨åˆ¸ID': f"#{ticket['ticket_id']:04d}",
                    'ç”¨æˆ¶ID': ticket['discord_id'],
                    'ç”¨æˆ¶å': ticket['username'],
                    'é¡å‹': ticket['type'],
                    'å„ªå…ˆç´š': ticket.get('priority', ''),
                    'ç‹€æ…‹': ticket['status'],
                    'å»ºç«‹æ™‚é–“': ticket['created_at'].strftime('%Y-%m-%d %H:%M:%S') if ticket['created_at'] else '',
                    'é—œé–‰æ™‚é–“': ticket['closed_at'].strftime('%Y-%m-%d %H:%M:%S') if ticket.get('closed_at') else '',
                    'é—œé–‰è€…': ticket.get('closed_by', ''),
                    'é—œé–‰åŸå› ': ticket.get('close_reason', ''),
                    'æŒ‡æ´¾çµ¦': ticket.get('assigned_to', ''),
                    'è©•åˆ†': ticket.get('rating', ''),
                    'è©•åˆ†å›é¥‹': ticket.get('rating_feedback', ''),
                    'æ¨™ç±¤': tags,
                    'æœ€å¾Œæ´»å‹•': ticket['last_activity'].strftime('%Y-%m-%d %H:%M:%S') if ticket.get('last_activity') else ''
                })
            
            csv_content = csv_buffer.getvalue()
            csv_buffer.close()
            
            result = BatchOperationResult(
                success=True,
                processed_count=len(tickets),
                error_count=0,
                total_count=len(tickets),
                errors=[],
                data={'csv_content': csv_content, 'filename': f'tickets_{config.guild_id}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'}
            )
            
            return result
            
        except Exception as e:
            debug_log(f"[BatchOperation] åŒ¯å‡º CSV éŒ¯èª¤ï¼š{e}")
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=1,
                total_count=0,
                errors=[str(e)]
            )
    
    async def _export_tickets_json(self, config: BatchOperationConfig) -> BatchOperationResult:
        """åŒ¯å‡ºç¥¨åˆ¸ç‚º JSON"""
        try:
            # å–å¾—ç¥¨åˆ¸è³‡æ–™ï¼ˆä½¿ç”¨èˆ‡ CSV ç›¸åŒçš„é‚è¼¯ï¼‰
            tickets_data = await self.dao.export_tickets_data(
                config.guild_id,
                config.parameters.get('status'),
                config.parameters.get('start_date'),
                config.parameters.get('end_date')
            )
            
            if not tickets_data:
                return BatchOperationResult(
                    success=True,
                    processed_count=0,
                    error_count=0,
                    total_count=0,
                    errors=["æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„ç¥¨åˆ¸è³‡æ–™"]
                )
            
            # è™•ç†è³‡æ–™æ ¼å¼
            processed_data = []
            for ticket in tickets_data:
                # è™•ç†æ—¥æœŸæ™‚é–“æ ¼å¼
                ticket_dict = dict(ticket)
                for key, value in ticket_dict.items():
                    if isinstance(value, datetime):
                        ticket_dict[key] = value.isoformat()
                
                # è™•ç† JSON æ¬„ä½
                if ticket_dict.get('tags') and isinstance(ticket_dict['tags'], str):
                    try:
                        ticket_dict['tags'] = json.loads(ticket_dict['tags'])
                    except:
                        pass
                
                processed_data.append(ticket_dict)
            
            # å»ºç«‹åŒ¯å‡ºè³‡æ–™
            export_data = {
                'export_info': {
                    'guild_id': config.guild_id,
                    'export_time': datetime.now(timezone.utc).isoformat(),
                    'total_tickets': len(processed_data),
                    'filters': config.parameters
                },
                'tickets': processed_data
            }
            
            json_content = json.dumps(export_data, ensure_ascii=False, indent=2)
            
            result = BatchOperationResult(
                success=True,
                processed_count=len(tickets_data),
                error_count=0,
                total_count=len(tickets_data),
                errors=[],
                data={
                    'json_content': json_content,
                    'filename': f'tickets_{config.guild_id}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
                }
            )
            
            return result
            
        except Exception as e:
            debug_log(f"[BatchOperation] åŒ¯å‡º JSON éŒ¯èª¤ï¼š{e}")
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=1,
                total_count=0,
                errors=[str(e)]
            )
    
    # ===== ç³»çµ±ç¶­è­·æ“ä½œ =====
    
    async def _cleanup_cache(self, config: BatchOperationConfig) -> BatchOperationResult:
        """æ¸…ç†å¿«å–"""
        try:
            cleaned_count = 0
            
            # æ¸…ç†çµ±è¨ˆå¿«å–
            async with self.dao.db_pool.acquire() as conn:
                async with conn.cursor() as cursor:
                    await cursor.execute(
                        "DELETE FROM ticket_statistics_cache WHERE expires_at < NOW() OR guild_id = %s",
                        (config.guild_id,)
                    )
                    cleaned_count += cursor.rowcount
                    
                    # æ¸…ç†èˆŠçš„æŸ¥çœ‹è¨˜éŒ„
                    cutoff_date = datetime.now(timezone.utc) - timedelta(days=30)
                    await cursor.execute(
                        "DELETE FROM ticket_views WHERE viewed_at < %s",
                        (cutoff_date,)
                    )
                    cleaned_count += cursor.rowcount
                    
                    # æ¸…ç†è‡ªå‹•å›è¦†æ—¥èªŒ
                    cutoff_date = datetime.now(timezone.utc) - timedelta(days=7)
                    await cursor.execute(
                        "DELETE FROM auto_reply_logs WHERE created_at < %s",
                        (cutoff_date,)
                    )
                    cleaned_count += cursor.rowcount
                    
                    await conn.commit()
            
            return BatchOperationResult(
                success=True,
                processed_count=cleaned_count,
                error_count=0,
                total_count=cleaned_count,
                errors=[]
            )
            
        except Exception as e:
            debug_log(f"[BatchOperation] æ¸…ç†å¿«å–éŒ¯èª¤ï¼š{e}")
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=1,
                total_count=0,
                errors=[str(e)]
            )
    
    async def _update_statistics(self, config: BatchOperationConfig) -> BatchOperationResult:
        """æ›´æ–°çµ±è¨ˆè³‡æ–™"""
        try:
            # é‡æ–°è¨ˆç®—ä¼ºæœå™¨çµ±è¨ˆ
            stats = await self.statistics_service.get_server_statistics(config.guild_id)
            
            # é‡æ–°è¨ˆç®— SLA çµ±è¨ˆ
            sla_stats = await self.dao.get_sla_statistics(config.guild_id)
            
            # é‡æ–°è¨ˆç®—å®¢æœè¡¨ç¾
            staff_stats = await self.statistics_service.get_staff_performance(config.guild_id)
            
            return BatchOperationResult(
                success=True,
                processed_count=1,
                error_count=0,
                total_count=1,
                errors=[],
                data={
                    'server_stats': stats,
                    'sla_stats': sla_stats,
                    'staff_stats': staff_stats
                }
            )
            
        except Exception as e:
            debug_log(f"[BatchOperation] æ›´æ–°çµ±è¨ˆéŒ¯èª¤ï¼š{e}")
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=1,
                total_count=0,
                errors=[str(e)]
            )
    
    # ===== é€šçŸ¥æ“ä½œ =====
    
    async def _send_reminders(self, config: BatchOperationConfig) -> BatchOperationResult:
        """ç™¼é€æé†’é€šçŸ¥"""
        try:
            reminder_type = config.parameters.get('type', 'sla_overdue')
            
            if reminder_type == 'sla_overdue':
                return await self._send_sla_reminders(config)
            elif reminder_type == 'inactive_tickets':
                return await self._send_inactive_reminders(config)
            else:
                return BatchOperationResult(
                    success=False,
                    processed_count=0,
                    error_count=1,
                    total_count=0,
                    errors=[f"ä¸æ”¯æ´çš„æé†’é¡å‹ï¼š{reminder_type}"]
                )
                
        except Exception as e:
            debug_log(f"[BatchOperation] ç™¼é€æé†’éŒ¯èª¤ï¼š{e}")
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=1,
                total_count=0,
                errors=[str(e)]
            )
    
    async def _send_sla_reminders(self, config: BatchOperationConfig) -> BatchOperationResult:
        """ç™¼é€ SLA è¶…æ™‚æé†’"""
        try:
            # å–å¾—è¶…æ™‚ç¥¨åˆ¸
            overdue_tickets = await self.dao.get_overdue_tickets()
            guild_tickets = [t for t in overdue_tickets if t['guild_id'] == config.guild_id]
            
            result = BatchOperationResult(
                success=True,
                processed_count=0,
                error_count=0,
                total_count=len(guild_tickets),
                errors=[]
            )
            
            if not guild_tickets:
                return result
            
            # ç™¼é€æé†’
            for ticket in guild_tickets:
                try:
                    # é€™è£¡éœ€è¦ bot å¯¦ä¾‹ä¾†ç™¼é€è¨Šæ¯ï¼Œå¯¦éš›ä½¿ç”¨æ™‚éœ€è¦å‚³å…¥
                    # æš«æ™‚åªè¨˜éŒ„æ—¥èªŒ
                    debug_log(f"[BatchOperation] éœ€è¦ç™¼é€ SLA æé†’ï¼šç¥¨åˆ¸ #{ticket['ticket_id']:04d}")
                    result.processed_count += 1
                    
                except Exception as e:
                    result.add_error(f"ç¥¨åˆ¸ #{ticket['ticket_id']:04d}: {str(e)}")
            
            return result
            
        except Exception as e:
            debug_log(f"[BatchOperation] ç™¼é€ SLA æé†’éŒ¯èª¤ï¼š{e}")
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=1,
                total_count=0,
                errors=[str(e)]
            )
    
    async def _send_inactive_reminders(self, config: BatchOperationConfig) -> BatchOperationResult:
        """ç™¼é€ç„¡æ´»å‹•æé†’"""
        try:
            hours_threshold = config.parameters.get('hours_threshold', 12)
            cutoff_time = datetime.now(timezone.utc) - timedelta(hours=hours_threshold)
            
            # å–å¾—ç„¡æ´»å‹•ç¥¨åˆ¸
            async with self.dao.db_pool.acquire() as conn:
                async with conn.cursor(dictionary=True) as cursor:
                    await cursor.execute(
                        """
                        SELECT ticket_id, discord_id, type, last_activity
                        FROM tickets
                        WHERE guild_id = %s 
                        AND status = 'open'
                        AND last_activity < %s
                        AND last_activity > %s
                        """,
                        (config.guild_id, cutoff_time, cutoff_time - timedelta(hours=24))
                    )
                    inactive_tickets = await cursor.fetchall()
            
            result = BatchOperationResult(
                success=True,
                processed_count=0,
                error_count=0,
                total_count=len(inactive_tickets),
                errors=[]
            )
            
            # ç™¼é€æé†’ï¼ˆéœ€è¦ bot å¯¦ä¾‹ï¼‰
            for ticket in inactive_tickets:
                try:
                    debug_log(f"[BatchOperation] éœ€è¦ç™¼é€ç„¡æ´»å‹•æé†’ï¼šç¥¨åˆ¸ #{ticket['ticket_id']:04d}")
                    result.processed_count += 1
                    
                except Exception as e:
                    result.add_error(f"ç¥¨åˆ¸ #{ticket['ticket_id']:04d}: {str(e)}")
            
            return result
            
        except Exception as e:
            debug_log(f"[BatchOperation] ç™¼é€ç„¡æ´»å‹•æé†’éŒ¯èª¤ï¼š{e}")
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=1,
                total_count=0,
                errors=[str(e)]
            )
    
    # ===== æ‰¹æ¬¡æ›´æ–°æ“ä½œ =====
    
    async def _bulk_assign_tickets(self, config: BatchOperationConfig) -> BatchOperationResult:
        """æ‰¹æ¬¡æŒ‡æ´¾ç¥¨åˆ¸"""
        try:
            staff_id = config.parameters['staff_id']
            ticket_ids = config.parameters.get('ticket_ids', [])
            status_filter = config.parameters.get('status_filter', 'open')
            
            # å¦‚æœæ²’æœ‰æŒ‡å®šç¥¨åˆ¸ IDï¼Œå–å¾—ç¬¦åˆæ¢ä»¶çš„ç¥¨åˆ¸
            if not ticket_ids:
                async with self.dao.db_pool.acquire() as conn:
                    async with conn.cursor() as cursor:
                        await cursor.execute(
                            """
                            SELECT ticket_id FROM tickets
                            WHERE guild_id = %s AND status = %s AND assigned_to IS NULL
                            ORDER BY created_at ASC
                            LIMIT %s
                            """,
                            (config.guild_id, status_filter, config.parameters.get('limit', 50))
                        )
                        results = await cursor.fetchall()
                        ticket_ids = [r[0] for r in results]
            
            result = BatchOperationResult(
                success=True,
                processed_count=0,
                error_count=0,
                total_count=len(ticket_ids),
                errors=[]
            )
            
            if config.dry_run:
                result.data = {'tickets_to_assign': ticket_ids}
                return result
            
            # æ‰¹æ¬¡æŒ‡æ´¾
            for i in range(0, len(ticket_ids), config.batch_size):
                batch_ids = ticket_ids[i:i + config.batch_size]
                
                for ticket_id in batch_ids:
                    try:
                        success = await self.dao.assign_ticket(ticket_id, staff_id, 'batch_operation')
                        if success:
                            result.processed_count += 1
                        else:
                            result.add_error(f"ç¥¨åˆ¸ #{ticket_id:04d}: æŒ‡æ´¾å¤±æ•—")
                            
                    except Exception as e:
                        result.add_error(f"ç¥¨åˆ¸ #{ticket_id:04d}: {str(e)}")
                
                if i + config.batch_size < len(ticket_ids):
                    await asyncio.sleep(config.delay_between_batches)
            
            return result
            
        except Exception as e:
            debug_log(f"[BatchOperation] æ‰¹æ¬¡æŒ‡æ´¾éŒ¯èª¤ï¼š{e}")
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=1,
                total_count=0,
                errors=[str(e)]
            )
    
    async def _bulk_update_priority(self, config: BatchOperationConfig) -> BatchOperationResult:
        """æ‰¹æ¬¡æ›´æ–°å„ªå…ˆç´š"""
        try:
            priority = config.parameters['priority']
            ticket_ids = config.parameters.get('ticket_ids', [])
            current_priority = config.parameters.get('current_priority')
            
            # å¦‚æœæ²’æœ‰æŒ‡å®šç¥¨åˆ¸ IDï¼Œæ ¹æ“šç•¶å‰å„ªå…ˆç´šç¯©é¸
            if not ticket_ids and current_priority:
                async with self.dao.db_pool.acquire() as conn:
                    async with conn.cursor() as cursor:
                        await cursor.execute(
                            """
                            SELECT ticket_id FROM tickets
                            WHERE guild_id = %s AND status = 'open' AND priority = %s
                            ORDER BY created_at ASC
                            LIMIT %s
                            """,
                            (config.guild_id, current_priority, config.parameters.get('limit', 100))
                        )
                        results = await cursor.fetchall()
                        ticket_ids = [r[0] for r in results]
            
            result = BatchOperationResult(
                success=True,
                processed_count=0,
                error_count=0,
                total_count=len(ticket_ids),
                errors=[]
            )
            
            if config.dry_run:
                result.data = {'tickets_to_update': ticket_ids, 'new_priority': priority}
                return result
            
            # æ‰¹æ¬¡æ›´æ–°
            for i in range(0, len(ticket_ids), config.batch_size):
                batch_ids = ticket_ids[i:i + config.batch_size]
                
                try:
                    async with self.dao.db_pool.acquire() as conn:
                        async with conn.cursor() as cursor:
                            placeholders = ','.join(['%s'] * len(batch_ids))
                            await cursor.execute(
                                f"UPDATE tickets SET priority = %s WHERE ticket_id IN ({placeholders})",
                                [priority] + batch_ids
                            )
                            await conn.commit()
                            
                            result.processed_count += cursor.rowcount
                            
                            # è¨˜éŒ„æ“ä½œæ—¥èªŒ
                            for ticket_id in batch_ids:
                                await cursor.execute(
                                    """
                                    INSERT INTO ticket_logs (ticket_id, action, details, created_by, created_at)
                                    VALUES (%s, 'priority_change', %s, %s, NOW())
                                    """,
                                    (ticket_id, f"æ‰¹æ¬¡æ›´æ–°å„ªå…ˆç´šç‚º {priority}", 'batch_operation')
                                )
                            await conn.commit()
                
                except Exception as e:
                    result.add_error(f"æ‰¹æ¬¡æ›´æ–°å¤±æ•—ï¼š{str(e)}")
                
                if i + config.batch_size < len(ticket_ids):
                    await asyncio.sleep(config.delay_between_batches)
            
            return result
            
        except Exception as e:
            debug_log(f"[BatchOperation] æ‰¹æ¬¡æ›´æ–°å„ªå…ˆç´šéŒ¯èª¤ï¼š{e}")
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=1,
                total_count=0,
                errors=[str(e)]
            )
    
    async def _bulk_update_tags(self, config: BatchOperationConfig) -> BatchOperationResult:
        """æ‰¹æ¬¡æ›´æ–°æ¨™ç±¤"""
        try:
            operation = config.parameters.get('operation', 'add')  # add, remove, replace
            tags = config.parameters['tags']
            ticket_ids = config.parameters.get('ticket_ids', [])
            
            if not ticket_ids:
                # å–å¾—æ‰€æœ‰é–‹å•Ÿçš„ç¥¨åˆ¸
                async with self.dao.db_pool.acquire() as conn:
                    async with conn.cursor() as cursor:
                        await cursor.execute(
                            "SELECT ticket_id FROM tickets WHERE guild_id = %s AND status = 'open'",
                            (config.guild_id,)
                        )
                        results = await cursor.fetchall()
                        ticket_ids = [r[0] for r in results]
            
            result = BatchOperationResult(
                success=True,
                processed_count=0,
                error_count=0,
                total_count=len(ticket_ids),
                errors=[]
            )
            
            if config.dry_run:
                result.data = {
                    'tickets_to_update': ticket_ids,
                    'operation': operation,
                    'tags': tags
                }
                return result
            
            # æ‰¹æ¬¡æ›´æ–°æ¨™ç±¤
            for i in range(0, len(ticket_ids), config.batch_size):
                batch_ids = ticket_ids[i:i + config.batch_size]
                
                for ticket_id in batch_ids:
                    try:
                        if operation == 'add':
                            success = await self.dao.add_tags_to_ticket(ticket_id, tags)
                        elif operation == 'replace':
                            # å…ˆæ¸…ç©ºå†æ·»åŠ 
                            await self._replace_ticket_tags(ticket_id, tags)
                            success = True
                        else:  # remove
                            success = await self._remove_ticket_tags(ticket_id, tags)
                        
                        if success:
                            result.processed_count += 1
                        else:
                            result.add_error(f"ç¥¨åˆ¸ #{ticket_id:04d}: æ¨™ç±¤æ›´æ–°å¤±æ•—")
                            
                    except Exception as e:
                        result.add_error(f"ç¥¨åˆ¸ #{ticket_id:04d}: {str(e)}")
                
                if i + config.batch_size < len(ticket_ids):
                    await asyncio.sleep(config.delay_between_batches)
            
            return result
            
        except Exception as e:
            debug_log(f"[BatchOperation] æ‰¹æ¬¡æ›´æ–°æ¨™ç±¤éŒ¯èª¤ï¼š{e}")
            return BatchOperationResult(
                success=False,
                processed_count=0,
                error_count=1,
                total_count=0,
                errors=[str(e)]
            )
    
    async def _replace_ticket_tags(self, ticket_id: int, new_tags: List[str]) -> bool:
        """æ›¿æ›ç¥¨åˆ¸æ¨™ç±¤"""
        try:
            async with self.dao.db_pool.acquire() as conn:
                async with conn.cursor() as cursor:
                    await cursor.execute(
                        "UPDATE tickets SET tags = %s WHERE ticket_id = %s",
                        (json.dumps(new_tags), ticket_id)
                    )
                    await conn.commit()
                    return cursor.rowcount > 0
                    
        except Exception as e:
            debug_log(f"[BatchOperation] æ›¿æ›æ¨™ç±¤éŒ¯èª¤ï¼š{e}")
            return False
    
    async def _remove_ticket_tags(self, ticket_id: int, tags_to_remove: List[str]) -> bool:
        """ç§»é™¤ç¥¨åˆ¸æ¨™ç±¤"""
        try:
            # å–å¾—ç•¶å‰æ¨™ç±¤
            current_tags = await self.dao.get_ticket_tags(ticket_id)
            
            # ç§»é™¤æŒ‡å®šæ¨™ç±¤
            new_tags = [tag for tag in current_tags if tag not in tags_to_remove]
            
            # æ›´æ–°æ¨™ç±¤
            async with self.dao.db_pool.acquire() as conn:
                async with conn.cursor() as cursor:
                    await cursor.execute(
                        "UPDATE tickets SET tags = %s WHERE ticket_id = %s",
                        (json.dumps(new_tags), ticket_id)
                    )
                    await conn.commit()
                    return cursor.rowcount > 0
                    
        except Exception as e:
            debug_log(f"[BatchOperation] ç§»é™¤æ¨™ç±¤éŒ¯èª¤ï¼š{e}")
            return False
    
    # ===== é€šçŸ¥æ–¹æ³• =====
    
    async def _send_completion_notification(self, config: BatchOperationConfig, 
                                          result: BatchOperationResult):
        """ç™¼é€å®Œæˆé€šçŸ¥"""
        try:
            if config.log_channel_id:
                # å»ºç«‹å®Œæˆå ±å‘ŠåµŒå…¥
                embed = discord.Embed(
                    title="ğŸ”§ æ‰¹æ¬¡æ“ä½œå®Œæˆ",
                    color=discord.Color.green() if result.success else discord.Color.red()
                )
                
                embed.add_field(
                    name="æ“ä½œé¡å‹",
                    value=config.operation_type.value,
                    inline=True
                )
                
                embed.add_field(
                    name="åŸ·è¡Œçµæœ",
                    value=f"âœ… æˆåŠŸï¼š{result.processed_count}\n"
                          f"âŒ éŒ¯èª¤ï¼š{result.error_count}\n"
                          f"ğŸ“Š ç¸½æ•¸ï¼š{result.total_count}",
                    inline=True
                )
                
                embed.add_field(
                    name="åŸ·è¡Œæ™‚é–“",
                    value=f"{result.execution_time:.2f} ç§’",
                    inline=True
                )
                
                if result.errors:
                    error_text = "\n".join(result.errors[:5])
                    if len(result.errors) > 5:
                        error_text += f"\n... é‚„æœ‰ {len(result.errors) - 5} å€‹éŒ¯èª¤"
                    
                    embed.add_field(
                        name="éŒ¯èª¤è©³æƒ…",
                        value=f"```{error_text}```",
                        inline=False
                    )
                
                embed.set_footer(
                    text=f"{'æ¼”ç¿’æ¨¡å¼' if config.dry_run else 'æ­£å¼åŸ·è¡Œ'} | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                )
                
                # é€™è£¡éœ€è¦ bot å¯¦ä¾‹ä¾†ç™¼é€è¨Šæ¯
                debug_log(f"[BatchOperation] éœ€è¦ç™¼é€å®Œæˆé€šçŸ¥åˆ°é »é“ {config.log_channel_id}")
            
        except Exception as e:
            debug_log(f"[BatchOperation] ç™¼é€å®Œæˆé€šçŸ¥éŒ¯èª¤ï¼š{e}")


# ===== å·¥å» å‡½æ•¸ =====

def create_batch_operation_manager() -> BatchOperationManager:
    """å»ºç«‹æ‰¹æ¬¡æ“ä½œç®¡ç†å™¨"""
    return BatchOperationManager()


def create_batch_config(operation_type: BatchOperationType, guild_id: int, 
                       parameters: Dict[str, Any], **kwargs) -> BatchOperationConfig:
    """å»ºç«‹æ‰¹æ¬¡æ“ä½œé…ç½®"""
    return BatchOperationConfig(
        operation_type=operation_type,
        guild_id=guild_id,
        parameters=parameters,
        **kwargs
    )


# ===== é è¨­é…ç½®æ¨¡æ¿ =====

class BatchConfigTemplates:
    """æ‰¹æ¬¡æ“ä½œé…ç½®æ¨¡æ¿"""
    
    @staticmethod
    def close_inactive_tickets(guild_id: int, hours: int, dry_run: bool = False) -> BatchOperationConfig:
        """é—œé–‰ç„¡æ´»å‹•ç¥¨åˆ¸é…ç½®"""
        return BatchOperationConfig(
            operation_type=BatchOperationType.CLOSE_INACTIVE,
            guild_id=guild_id,
            parameters={'hours_threshold': hours},
            dry_run=dry_run,
            batch_size=20,
            delay_between_batches=2.0
        )
    
    @staticmethod
    def archive_old_tickets(guild_id: int, days: int, dry_run: bool = False) -> BatchOperationConfig:
        """æ­¸æª”èˆŠç¥¨åˆ¸é…ç½®"""
        return BatchOperationConfig(
            operation_type=BatchOperationType.ARCHIVE_CLOSED,
            guild_id=guild_id,
            parameters={'days_threshold': days},
            dry_run=dry_run,
            batch_size=50,
            delay_between_batches=1.0
        )
    
    @staticmethod
    def export_tickets_csv(guild_id: int, status: str = 'all', 
                          start_date: datetime = None, end_date: datetime = None) -> BatchOperationConfig:
        """åŒ¯å‡ºç¥¨åˆ¸ CSV é…ç½®"""
        parameters = {'status': status}
        if start_date:
            parameters['start_date'] = start_date
        if end_date:
            parameters['end_date'] = end_date
            
        return BatchOperationConfig(
            operation_type=BatchOperationType.EXPORT_CSV,
            guild_id=guild_id,
            parameters=parameters
        )
    
    @staticmethod
    def bulk_assign_tickets(guild_id: int, staff_id: int, limit: int = 10) -> BatchOperationConfig:
        """æ‰¹æ¬¡æŒ‡æ´¾ç¥¨åˆ¸é…ç½®"""
        return BatchOperationConfig(
            operation_type=BatchOperationType.BULK_ASSIGN,
            guild_id=guild_id,
            parameters={
                'staff_id': staff_id,
                'limit': limit,
                'status_filter': 'open'
            },
            batch_size=10,
            delay_between_batches=1.0
        )
    
    @staticmethod
    def system_maintenance(guild_id: int) -> BatchOperationConfig:
        """ç³»çµ±ç¶­è­·é…ç½®"""
        return BatchOperationConfig(
            operation_type=BatchOperationType.CLEANUP_CACHE,
            guild_id=guild_id,
            parameters={},
            notify_on_completion=True
        )


# ===== åŒ¯å‡º =====

__all__ = [
    'BatchOperationType',
    'BatchOperationResult',
    'BatchOperationConfig',
    'BatchOperationManager',
    'BatchConfigTemplates',
    'create_batch_operation_manager',
    'create_batch_config'
]