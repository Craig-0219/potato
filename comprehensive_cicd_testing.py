#!/usr/bin/env python3
"""
🧪 Comprehensive CI/CD System Testing Suite
全方面 CI/CD 系統測試驗證工具

執行完整的系統測試，驗證所有 Stage 1-4 實現的功能
"""

import asyncio
import json
import os
import sys
import time
import yaml
import subprocess
import importlib
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any
import traceback

class ComprehensiveCICDTester:
    def __init__(self):
        self.results = {
            'test_suite': 'Comprehensive CI/CD System Testing',
            'version': 'v4.0.0',
            'timestamp': datetime.now().isoformat(),
            'environment': 'Testing',
            'total_tests': 0,
            'passed_tests': 0,
            'failed_tests': 0,
            'warning_tests': 0,
            'skipped_tests': 0,
            'test_categories': {},
            'detailed_results': [],
            'performance_metrics': {},
            'recommendations': [],
            'overall_status': 'unknown'
        }
        
        # 設置測試環境
        os.environ['TESTING'] = 'true'
        sys.path.append('.')
    
    def log_test_result(self, category: str, test_name: str, status: str, 
                       details: str = "", duration: float = 0, error: str = ""):
        """記錄測試結果"""
        result = {
            'category': category,
            'test_name': test_name,
            'status': status,
            'details': details,
            'duration': duration,
            'error': error,
            'timestamp': datetime.now().isoformat()
        }
        
        self.results['detailed_results'].append(result)
        self.results['total_tests'] += 1
        
        if status == 'passed':
            self.results['passed_tests'] += 1
        elif status == 'failed':
            self.results['failed_tests'] += 1
        elif status == 'warning':
            self.results['warning_tests'] += 1
        elif status == 'skipped':
            self.results['skipped_tests'] += 1
        
        # 更新分類統計
        if category not in self.results['test_categories']:
            self.results['test_categories'][category] = {
                'total': 0, 'passed': 0, 'failed': 0, 'warning': 0, 'skipped': 0
            }
        
        self.results['test_categories'][category]['total'] += 1
        self.results['test_categories'][category][status] += 1
        
        print(f"{'✅' if status == 'passed' else '⚠️' if status == 'warning' else '❌' if status == 'failed' else '⏭️'} "
              f"[{category}] {test_name}: {status.upper()}")
        if details:
            print(f"    {details}")
        if error:
            print(f"    錯誤: {error}")
    
    async def test_workflow_syntax_validation(self):
        """測試 1: GitHub Actions Workflows 語法驗證"""
        print("\n🔍 測試分類 1: GitHub Actions Workflows 語法驗證")
        print("=" * 60)
        
        workflow_dir = Path('.github/workflows')
        if not workflow_dir.exists():
            self.log_test_result('workflow_syntax', 'workflow_directory_exists', 'failed',
                               error="Workflows 目錄不存在")
            return
        
        workflow_files = list(workflow_dir.glob('*.yml'))
        expected_workflows = [
            'dynamic-matrix-optimization.yml',
            'parallel-execution-optimization.yml', 
            'intelligent-skip-enhancement.yml',
            'performance-monitoring-dashboard.yml',
            'final-integration-validation.yml',
            'phase1-integration-testing.yml'
        ]
        
        # 檢查關鍵工作流程檔案存在
        for expected in expected_workflows:
            file_path = workflow_dir / expected
            if file_path.exists():
                self.log_test_result('workflow_syntax', f'{expected}_exists', 'passed',
                                   f"檔案大小: {file_path.stat().st_size} bytes")
            else:
                self.log_test_result('workflow_syntax', f'{expected}_exists', 'failed',
                                   error=f"缺少關鍵工作流程檔案: {expected}")
        
        # 驗證每個工作流程的 YAML 語法
        for workflow_file in workflow_files:
            try:
                with open(workflow_file, 'r', encoding='utf-8') as f:
                    workflow_content = yaml.safe_load(f)
                
                # 基本結構檢查
                if 'name' not in workflow_content:
                    self.log_test_result('workflow_syntax', f'{workflow_file.name}_has_name', 'warning',
                                       "工作流程缺少 name 欄位")
                else:
                    self.log_test_result('workflow_syntax', f'{workflow_file.name}_yaml_syntax', 'passed',
                                       f"YAML 語法正確，name: {workflow_content['name']}")
                
                # 檢查觸發條件
                if 'on' in workflow_content:
                    triggers = list(workflow_content['on'].keys()) if isinstance(workflow_content['on'], dict) else [workflow_content['on']]
                    self.log_test_result('workflow_syntax', f'{workflow_file.name}_triggers', 'passed',
                                       f"觸發條件: {', '.join(triggers)}")
                
                # 檢查 jobs 結構
                if 'jobs' in workflow_content and workflow_content['jobs']:
                    job_count = len(workflow_content['jobs'])
                    self.log_test_result('workflow_syntax', f'{workflow_file.name}_jobs_structure', 'passed',
                                       f"包含 {job_count} 個 job")
                else:
                    self.log_test_result('workflow_syntax', f'{workflow_file.name}_jobs_structure', 'failed',
                                       error="缺少 jobs 定義")
                
            except yaml.YAMLError as e:
                self.log_test_result('workflow_syntax', f'{workflow_file.name}_yaml_syntax', 'failed',
                                   error=f"YAML 語法錯誤: {str(e)}")
            except Exception as e:
                self.log_test_result('workflow_syntax', f'{workflow_file.name}_validation', 'failed',
                                   error=f"驗證異常: {str(e)}")
    
    async def test_environment_configuration(self):
        """測試 2: 環境配置和依賴檢查"""
        print("\n🔧 測試分類 2: 環境配置和依賴檢查")
        print("=" * 60)
        
        # 檢查 Python 環境
        python_version = sys.version_info
        if python_version >= (3, 10):
            self.log_test_result('environment', 'python_version', 'passed',
                               f"Python {python_version.major}.{python_version.minor}.{python_version.micro}")
        else:
            self.log_test_result('environment', 'python_version', 'warning',
                               f"Python 版本較舊: {python_version.major}.{python_version.minor}")
        
        # 檢查關鍵配置檔案
        config_files = {
            'requirements.txt': '專案依賴',
            'pyproject.toml': '專案配置',
            '.pre-commit-config.yaml': '代碼品質檢查',
            'pytest.ini': '測試配置'
        }
        
        for file_name, description in config_files.items():
            if os.path.exists(file_name):
                file_size = os.path.getsize(file_name)
                self.log_test_result('environment', f'{file_name}_exists', 'passed',
                                   f"{description} - 大小: {file_size} bytes")
            else:
                self.log_test_result('environment', f'{file_name}_exists', 'warning',
                                   f"缺少 {description} 檔案")
        
        # 檢查 Python 模組導入
        critical_modules = [
            ('shared.config', '配置管理'),
            ('bot.db.database_manager', '資料庫管理'),
            ('shared.cache_manager', '快取管理'),
            ('bot.main', 'Bot 主程式')
        ]
        
        for module_name, description in critical_modules:
            try:
                start_time = time.time()
                importlib.import_module(module_name)
                import_time = time.time() - start_time
                self.log_test_result('environment', f'{module_name}_import', 'passed',
                                   f"{description} - 導入時間: {import_time:.3f}s")
            except ImportError as e:
                self.log_test_result('environment', f'{module_name}_import', 'failed',
                                   error=f"{description} 導入失敗: {str(e)}")
            except Exception as e:
                self.log_test_result('environment', f'{module_name}_import', 'warning',
                                   f"{description} 導入警告: {str(e)}")
    
    async def test_core_functionality(self):
        """測試 3: 核心功能驗證"""
        print("\n🚀 測試分類 3: 核心功能驗證")
        print("=" * 60)
        
        # 測試配置載入
        try:
            from shared.config import DISCORD_TOKEN, DB_HOST
            if DISCORD_TOKEN and len(DISCORD_TOKEN) > 50:
                self.log_test_result('core_functionality', 'config_loading', 'passed',
                                   f"配置載入成功，DB_HOST: {DB_HOST}")
            else:
                self.log_test_result('core_functionality', 'config_loading', 'warning',
                                   "Discord Token 長度不足")
        except Exception as e:
            self.log_test_result('core_functionality', 'config_loading', 'failed',
                               error=f"配置載入失敗: {str(e)}")
        
        # 測試快取管理器
        try:
            from shared.cache_manager import MultiLevelCacheManager
            cache_manager = MultiLevelCacheManager()
            # 簡單的快取測試
            test_key = "test_cicd_validation"
            test_value = {"timestamp": datetime.now().isoformat(), "test": True}
            
            # 假設快取管理器有基本的 set/get 方法
            if hasattr(cache_manager, 'set') and hasattr(cache_manager, 'get'):
                self.log_test_result('core_functionality', 'cache_manager_basic', 'passed',
                                   "快取管理器基本功能可用")
            else:
                self.log_test_result('core_functionality', 'cache_manager_basic', 'warning',
                                   "快取管理器方法不完整")
        except Exception as e:
            self.log_test_result('core_functionality', 'cache_manager_basic', 'failed',
                               error=f"快取管理器測試失敗: {str(e)}")
        
        # 測試資料庫管理器
        try:
            from bot.db.database_manager import DatabaseManager
            # 不實際連接資料庫，只檢查類別結構
            db_manager = DatabaseManager()
            required_methods = ['initialize_all_tables', 'get_connection']
            
            missing_methods = []
            for method in required_methods:
                if not hasattr(db_manager, method):
                    missing_methods.append(method)
            
            if not missing_methods:
                self.log_test_result('core_functionality', 'database_manager_structure', 'passed',
                                   "資料庫管理器結構完整")
            else:
                self.log_test_result('core_functionality', 'database_manager_structure', 'warning',
                                   f"缺少方法: {missing_methods}")
        except Exception as e:
            self.log_test_result('core_functionality', 'database_manager_structure', 'failed',
                               error=f"資料庫管理器測試失敗: {str(e)}")
    
    async def test_intelligent_features(self):
        """測試 4: 智能功能驗證"""
        print("\n🧠 測試分類 4: 智能功能驗證")
        print("=" * 60)
        
        # 測試智能跳過策略邏輯
        test_scenarios = [
            {"change_type": "docs", "expected_skip": True, "description": "文檔變更應觸發智能跳過"},
            {"change_type": "core", "expected_skip": False, "description": "核心程式碼變更不應跳過"},
            {"change_type": "tests", "expected_skip": False, "description": "測試變更不應跳過"},
            {"change_type": "config", "expected_skip": False, "description": "配置變更不應跳過"}
        ]
        
        for scenario in test_scenarios:
            # 模擬智能跳過決策邏輯
            skip_decision = self.simulate_intelligent_skip_decision(scenario["change_type"])
            
            if skip_decision == scenario["expected_skip"]:
                self.log_test_result('intelligent_features', f'skip_logic_{scenario["change_type"]}', 'passed',
                                   scenario["description"])
            else:
                self.log_test_result('intelligent_features', f'skip_logic_{scenario["change_type"]}', 'failed',
                                   error=f"跳過決策錯誤: 預期 {scenario['expected_skip']}, 實際 {skip_decision}")
        
        # 測試動態矩陣決策邏輯
        matrix_scenarios = [
            {"impact": "minor", "expected_strategy": "minimal"},
            {"impact": "major", "expected_strategy": "targeted"},
            {"impact": "critical", "expected_strategy": "comprehensive"}
        ]
        
        for scenario in matrix_scenarios:
            strategy = self.simulate_matrix_decision(scenario["impact"])
            
            if strategy == scenario["expected_strategy"]:
                self.log_test_result('intelligent_features', f'matrix_logic_{scenario["impact"]}', 'passed',
                                   f"影響級別 {scenario['impact']} → 策略 {strategy}")
            else:
                self.log_test_result('intelligent_features', f'matrix_logic_{scenario["impact"]}', 'failed',
                                   error=f"矩陣決策錯誤: 預期 {scenario['expected_strategy']}, 實際 {strategy}")
    
    def simulate_intelligent_skip_decision(self, change_type: str) -> bool:
        """模擬智能跳過決策邏輯"""
        skip_rules = {
            "docs": True,
            "README": True,
            "markdown": True,
            "core": False,
            "bot": False,
            "tests": False,
            "config": False,
            "workflows": False
        }
        return skip_rules.get(change_type, False)
    
    def simulate_matrix_decision(self, impact: str) -> str:
        """模擬動態矩陣決策邏輯"""
        decision_map = {
            "minor": "minimal",
            "major": "targeted", 
            "critical": "comprehensive"
        }
        return decision_map.get(impact, "targeted")
    
    async def test_performance_benchmarks(self):
        """測試 5: 效能基準驗證"""
        print("\n⚡ 測試分類 5: 效能基準驗證")
        print("=" * 60)
        
        performance_tests = []
        
        # 配置載入效能測試
        start_time = time.time()
        try:
            from shared.config import DISCORD_TOKEN, DB_HOST, JWT_SECRET
            config_load_time = time.time() - start_time
            
            if config_load_time < 1.0:
                self.log_test_result('performance', 'config_load_time', 'passed',
                                   f"配置載入時間: {config_load_time:.3f}s (< 1.0s)")
            elif config_load_time < 2.0:
                self.log_test_result('performance', 'config_load_time', 'warning',
                                   f"配置載入時間較慢: {config_load_time:.3f}s")
            else:
                self.log_test_result('performance', 'config_load_time', 'failed',
                                   error=f"配置載入時間過慢: {config_load_time:.3f}s (> 2.0s)")
            
            performance_tests.append(('config_load_time', config_load_time))
        except Exception as e:
            self.log_test_result('performance', 'config_load_time', 'failed',
                               error=f"配置載入測試失敗: {str(e)}")
        
        # 模組導入效能測試
        modules_to_test = [
            'bot.db.database_manager',
            'shared.cache_manager',
            'shared.logger'
        ]
        
        total_import_time = 0
        successful_imports = 0
        
        for module_name in modules_to_test:
            start_time = time.time()
            try:
                importlib.import_module(module_name)
                import_time = time.time() - start_time
                total_import_time += import_time
                successful_imports += 1
                
                if import_time < 0.5:
                    self.log_test_result('performance', f'{module_name}_import_time', 'passed',
                                       f"模組導入時間: {import_time:.3f}s")
                else:
                    self.log_test_result('performance', f'{module_name}_import_time', 'warning',
                                       f"模組導入時間較慢: {import_time:.3f}s")
                
                performance_tests.append((f'{module_name}_import', import_time))
            except Exception as e:
                self.log_test_result('performance', f'{module_name}_import_time', 'failed',
                                   error=f"模組導入失敗: {str(e)}")
        
        # 總體導入效能評估
        if successful_imports > 0:
            avg_import_time = total_import_time / successful_imports
            if avg_import_time < 0.3:
                self.log_test_result('performance', 'average_import_time', 'passed',
                                   f"平均導入時間: {avg_import_time:.3f}s")
            else:
                self.log_test_result('performance', 'average_import_time', 'warning',
                                   f"平均導入時間: {avg_import_time:.3f}s")
        
        # 記憶體使用檢查
        try:
            import psutil
            import gc
            gc.collect()
            memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            
            if memory_usage < 200:
                self.log_test_result('performance', 'memory_usage', 'passed',
                                   f"記憶體使用: {memory_usage:.1f}MB")
            elif memory_usage < 500:
                self.log_test_result('performance', 'memory_usage', 'warning',
                                   f"記憶體使用較高: {memory_usage:.1f}MB")
            else:
                self.log_test_result('performance', 'memory_usage', 'failed',
                                   error=f"記憶體使用過高: {memory_usage:.1f}MB")
            
            performance_tests.append(('memory_usage_mb', memory_usage))
        except Exception as e:
            self.log_test_result('performance', 'memory_usage', 'warning',
                               f"記憶體檢查失敗: {str(e)}")
        
        # 儲存效能指標
        self.results['performance_metrics'] = dict(performance_tests)
    
    async def test_integration_scenarios(self):
        """測試 6: 整合情境驗證"""
        print("\n🔗 測試分類 6: 整合情境驗證")
        print("=" * 60)
        
        # 執行現有的單元測試
        try:
            result = subprocess.run([
                'python', '-m', 'pytest', 'tests/unit/', '-v', '--tb=short', '-x'
            ], capture_output=True, text=True, timeout=120)
            
            if result.returncode == 0:
                test_output = result.stdout
                # 解析測試結果
                if 'passed' in test_output:
                    passed_count = test_output.count(' PASSED')
                    self.log_test_result('integration', 'unit_tests_execution', 'passed',
                                       f"單元測試通過，成功 {passed_count} 個測試")
                else:
                    self.log_test_result('integration', 'unit_tests_execution', 'warning',
                                       "單元測試執行但無明確結果")
            else:
                error_output = result.stderr or result.stdout
                self.log_test_result('integration', 'unit_tests_execution', 'failed',
                                   error=f"單元測試失敗: {error_output[:200]}")
        except subprocess.TimeoutExpired:
            self.log_test_result('integration', 'unit_tests_execution', 'failed',
                               error="單元測試執行超時")
        except Exception as e:
            self.log_test_result('integration', 'unit_tests_execution', 'warning',
                               f"單元測試執行異常: {str(e)}")
        
        # 測試基本 Bot 初始化流程
        try:
            from unittest.mock import MagicMock, patch
            
            with patch('discord.ext.commands.Bot') as mock_bot:
                with patch('discord.Intents') as mock_intents:
                    mock_bot.return_value = MagicMock()
                    mock_intents.default.return_value = MagicMock()
                    
                    # 嘗試載入 Bot 主程式
                    from bot.main import PotatoBot
                    
                    self.log_test_result('integration', 'bot_initialization_structure', 'passed',
                                       "Bot 主程式結構載入成功")
        except Exception as e:
            self.log_test_result('integration', 'bot_initialization_structure', 'failed',
                               error=f"Bot 初始化結構測試失敗: {str(e)}")
        
        # 測試關鍵 Cogs 載入
        critical_cogs = [
            'bot.cogs.ticket_core',
            'bot.cogs.vote_core', 
            'bot.cogs.language_core'
        ]
        
        for cog_module in critical_cogs:
            try:
                start_time = time.time()
                with patch('discord.ext.commands.Bot') as mock_bot:
                    mock_bot.return_value = MagicMock()
                    importlib.import_module(cog_module)
                    load_time = time.time() - start_time
                    
                    self.log_test_result('integration', f'{cog_module}_loading', 'passed',
                                       f"Cog 載入成功，時間: {load_time:.3f}s")
            except ImportError as e:
                self.log_test_result('integration', f'{cog_module}_loading', 'warning',
                                   f"Cog 導入警告: {str(e)}")
            except Exception as e:
                self.log_test_result('integration', f'{cog_module}_loading', 'failed',
                                   error=f"Cog 載入失敗: {str(e)}")
    
    async def run_comprehensive_tests(self):
        """執行完整的測試套件"""
        print("🧪 開始執行全方面 CI/CD 系統測試驗證")
        print("=" * 80)
        print(f"測試時間: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"測試版本: v4.0.0")
        print("=" * 80)
        
        # 執行所有測試分類
        test_categories = [
            ('workflow_syntax_validation', '工作流程語法驗證'),
            ('environment_configuration', '環境配置檢查'),
            ('core_functionality', '核心功能驗證'),
            ('intelligent_features', '智能功能驗證'),
            ('performance_benchmarks', '效能基準驗證'),
            ('integration_scenarios', '整合情境驗證')
        ]
        
        for test_method, description in test_categories:
            print(f"\n🔄 開始執行: {description}")
            try:
                await getattr(self, f'test_{test_method}')()
            except Exception as e:
                self.log_test_result('system', test_method, 'failed',
                                   error=f"測試分類執行失敗: {str(e)}")
                print(f"❌ {description} 執行異常: {str(e)}")
        
        # 生成最終分析和建議
        self.generate_final_analysis()
    
    def generate_final_analysis(self):
        """生成最終分析和建議"""
        print("\n📊 生成最終測試分析...")
        
        # 計算成功率
        total_tests = self.results['total_tests']
        if total_tests > 0:
            success_rate = (self.results['passed_tests'] / total_tests) * 100
            warning_rate = (self.results['warning_tests'] / total_tests) * 100
            failure_rate = (self.results['failed_tests'] / total_tests) * 100
        else:
            success_rate = warning_rate = failure_rate = 0
        
        # 決定整體狀態
        if failure_rate > 20:
            self.results['overall_status'] = 'critical'
        elif failure_rate > 10 or warning_rate > 30:
            self.results['overall_status'] = 'needs_improvement'
        elif success_rate >= 80:
            self.results['overall_status'] = 'excellent'
        elif success_rate >= 70:
            self.results['overall_status'] = 'good'
        else:
            self.results['overall_status'] = 'acceptable'
        
        # 生成建議
        if self.results['failed_tests'] > 0:
            self.results['recommendations'].append(f"🚨 優先解決 {self.results['failed_tests']} 個失敗測試")
        
        if self.results['warning_tests'] > 5:
            self.results['recommendations'].append(f"⚠️ 關注 {self.results['warning_tests']} 個警告項目")
        
        if success_rate >= 90:
            self.results['recommendations'].append("🎉 系統測試表現優秀，建議進行生產部署")
        elif success_rate >= 80:
            self.results['recommendations'].append("✅ 系統基本就緒，建議解決警告後部署")
        else:
            self.results['recommendations'].append("🔧 系統需要改善，建議修復問題後重新測試")
        
        # 效能建議
        if 'performance_metrics' in self.results:
            metrics = self.results['performance_metrics']
            if metrics.get('config_load_time', 0) > 1.0:
                self.results['recommendations'].append("⚡ 建議優化配置載入效能")
            
            if metrics.get('memory_usage_mb', 0) > 300:
                self.results['recommendations'].append("💾 建議優化記憶體使用")
        
        # Stage 特定建議
        self.results['recommendations'].extend([
            "📈 持續監控 Stage 1-4 所有功能的運作狀態",
            "🎯 定期執行完整測試套件以確保系統穩定",
            "🔄 根據測試結果調整 CI/CD 優化參數"
        ])

async def main():
    """主執行函數"""
    tester = ComprehensiveCICDTester()
    
    try:
        await tester.run_comprehensive_tests()
        
        # 儲存詳細測試結果
        with open('comprehensive_test_results.json', 'w', encoding='utf-8') as f:
            json.dump(tester.results, f, indent=2, ensure_ascii=False, default=str)
        
        # 輸出測試摘要
        print("\n" + "=" * 80)
        print("🎯 全方面 CI/CD 系統測試驗證 - 執行完成")
        print("=" * 80)
        print(f"📊 測試統計:")
        print(f"   總測試數: {tester.results['total_tests']}")
        print(f"   ✅ 通過: {tester.results['passed_tests']}")
        print(f"   ⚠️ 警告: {tester.results['warning_tests']}")
        print(f"   ❌ 失敗: {tester.results['failed_tests']}")
        print(f"   ⏭️ 跳過: {tester.results['skipped_tests']}")
        
        if tester.results['total_tests'] > 0:
            success_rate = (tester.results['passed_tests'] / tester.results['total_tests']) * 100
            print(f"   🎯 成功率: {success_rate:.1f}%")
        
        print(f"\n🎯 整體狀態: {tester.results['overall_status'].upper()}")
        
        print(f"\n📋 測試分類結果:")
        for category, stats in tester.results['test_categories'].items():
            print(f"   {category}: {stats['passed']}/{stats['total']} 通過")
        
        if tester.results['recommendations']:
            print(f"\n💡 建議事項:")
            for rec in tester.results['recommendations']:
                print(f"   {rec}")
        
        print(f"\n📁 詳細結果已儲存到: comprehensive_test_results.json")
        print("=" * 80)
        
        # 根據結果決定退出代碼
        if tester.results['failed_tests'] > 0:
            print("⚠️ 測試發現問題，建議檢查並修復")
            return 1
        elif tester.results['warning_tests'] > 5:
            print("ℹ️ 測試完成但有較多警告")
            return 0
        else:
            print("🎉 測試全部完成，系統狀態良好！")
            return 0
    
    except Exception as e:
        print(f"❌ 測試執行異常: {str(e)}")
        traceback.print_exc()
        return 2

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)