# ğŸ¥” Potato Bot - ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²æŒ‡å—

<div align="center">

[![Production Ready](https://img.shields.io/badge/production-ready-brightgreen.svg)](https://github.com/Craig-0219/potato)
[![Uptime](https://img.shields.io/badge/uptime-99.9%25-brightgreen.svg)](https://status.potato-bot.com)
[![Security](https://img.shields.io/badge/security-hardened-green.svg)](#å®‰å…¨æ€§é…ç½®)
[![Performance](https://img.shields.io/badge/performance-optimized-blue.svg)](#æ•ˆèƒ½å„ªåŒ–)
[![Monitoring](https://img.shields.io/badge/monitoring-enabled-orange.svg)](#ç›£æ§ç³»çµ±)

**å…¨æ–¹ä½ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²æŒ‡å—**

*é«˜å¯ç”¨æ€§ â€¢ å®‰å…¨æ€§ â€¢ æ•ˆèƒ½å„ªåŒ– â€¢ ç›£æ§å‘Šè­¦*

</div>

## ğŸ“– ç”Ÿç”¢ç’°å¢ƒç›®éŒ„

- [ğŸ¯ éƒ¨ç½²æ¦‚è¦½](#-éƒ¨ç½²æ¦‚è¦½)
- [âš™ï¸ ç³»çµ±è¦æ±‚](#ï¸-ç³»çµ±è¦æ±‚)
- [ğŸ”§ ç”Ÿç”¢ç’°å¢ƒé…ç½®](#-ç”Ÿç”¢ç’°å¢ƒé…ç½®)
- [ğŸ³ Docker éƒ¨ç½²](#-docker-éƒ¨ç½²)
- [â˜ï¸ é›²ç«¯éƒ¨ç½²](#ï¸-é›²ç«¯éƒ¨ç½²)
- [ğŸ›¡ï¸ å®‰å…¨æ€§é…ç½®](#ï¸-å®‰å…¨æ€§é…ç½®)
- [ğŸš€ æ•ˆèƒ½å„ªåŒ–](#-æ•ˆèƒ½å„ªåŒ–)
- [ğŸ“Š ç›£æ§ç³»çµ±](#-ç›£æ§ç³»çµ±)
- [ğŸ’¾ å‚™ä»½èˆ‡æ¢å¾©](#-å‚™ä»½èˆ‡æ¢å¾©)
- [ğŸ”„ ç¶­è­·èˆ‡æ›´æ–°](#-ç¶­è­·èˆ‡æ›´æ–°)

## ğŸ¯ éƒ¨ç½²æ¦‚è¦½

### ç”Ÿç”¢ç’°å¢ƒæ¶æ§‹

```mermaid
graph TB
    subgraph "Load Balancer"
        LB[Nginx Load Balancer]
    end
    
    subgraph "Application Layer"
        APP1[Bot Instance 1]
        APP2[Bot Instance 2]
        API[FastAPI Server]
    end
    
    subgraph "Data Layer"
        DB[(PostgreSQL Primary)]
        DB_SLAVE[(PostgreSQL Replica)]
        REDIS[(Redis Cluster)]
    end
    
    subgraph "Monitoring"
        PROM[Prometheus]
        GRAF[Grafana]
        LOG[Log Aggregation]
    end
    
    subgraph "External Services"
        DISCORD[Discord API]
        AI_APIS[AI Services]
        CDN[Content Delivery Network]
    end
    
    LB --> API
    API --> APP1
    API --> APP2
    APP1 --> DB
    APP2 --> DB
    APP1 --> DB_SLAVE
    APP2 --> DB_SLAVE
    APP1 --> REDIS
    APP2 --> REDIS
    
    PROM --> APP1
    PROM --> APP2
    PROM --> DB
    PROM --> REDIS
    GRAF --> PROM
    
    APP1 --> DISCORD
    APP2 --> DISCORD
    APP1 --> AI_APIS
    APP2 --> AI_APIS
    
    LOG --> APP1
    LOG --> APP2
    LOG --> API
```

### éƒ¨ç½²æª¢æŸ¥æ¸…å–®

#### éƒ¨ç½²å‰æª¢æŸ¥
- [ ] ç’°å¢ƒè®Šæ•¸é…ç½®å®Œæˆ
- [ ] SSL æ†‘è­‰å®‰è£
- [ ] è³‡æ–™åº«é·ç§»åŸ·è¡Œ
- [ ] é˜²ç«ç‰†è¦å‰‡è¨­å®š
- [ ] ç›£æ§ç³»çµ±é…ç½®
- [ ] å‚™ä»½ç­–ç•¥å¯¦æ–½
- [ ] è² è¼‰å‡è¡¡è¨­å®š

#### éƒ¨ç½²å¾Œé©—è­‰
- [ ] æœå‹™å¥åº·æª¢æŸ¥é€šé
- [ ] API ç«¯é»æ­£å¸¸å›æ‡‰
- [ ] Discord æ©Ÿå™¨äººä¸Šç·š
- [ ] è³‡æ–™åº«é€£ç·šæ­£å¸¸
- [ ] Redis å¿«å–é‹ä½œ
- [ ] ç›£æ§è­¦å ±æ¸¬è©¦
- [ ] æ•ˆèƒ½åŸºæº–æ¸¬è©¦

## âš™ï¸ ç³»çµ±è¦æ±‚

### æœ€ä½ç”Ÿç”¢è¦æ±‚

```yaml
# å–®ä¸€å¯¦ä¾‹é…ç½®
CPU: 4 æ ¸å¿ƒ (2.4GHz+)
RAM: 8GB
Storage: 50GB SSD
Network: 1Gbps
OS: Ubuntu 20.04+ / CentOS 8+ / RHEL 8+
```

### æ¨è–¦ç”Ÿç”¢é…ç½®

```yaml
# é«˜å¯ç”¨æ€§é…ç½®
Load Balancer:
  CPU: 2 æ ¸å¿ƒ
  RAM: 4GB
  
Application Servers (2 instances):
  CPU: 8 æ ¸å¿ƒ (3.0GHz+)
  RAM: 16GB
  Storage: 100GB NVMe SSD
  
Database Server:
  CPU: 16 æ ¸å¿ƒ (3.2GHz+)
  RAM: 32GB
  Storage: 500GB NVMe SSD (RAID 1)
  
Redis Cluster:
  CPU: 4 æ ¸å¿ƒ
  RAM: 16GB
  Storage: 100GB SSD
  
Monitoring Server:
  CPU: 4 æ ¸å¿ƒ
  RAM: 8GB
  Storage: 200GB SSD
```

### ç¶²è·¯è¦æ±‚

```yaml
Bandwidth:
  Minimum: 100Mbps
  Recommended: 1Gbps
  
Latency:
  Discord API: < 100ms
  AI Services: < 200ms
  Database: < 5ms (local)
  
Ports:
  HTTP: 80
  HTTPS: 443
  SSH: 22 (custom port recommended)
  PostgreSQL: 5432 (internal only)
  Redis: 6379 (internal only)
  Prometheus: 9090 (internal only)
  Grafana: 3000 (internal only)
```

## ğŸ”§ ç”Ÿç”¢ç’°å¢ƒé…ç½®

### æ ¸å¿ƒç’°å¢ƒè®Šæ•¸

```bash
# .env.production
# ======================
# åŸºæœ¬ç”Ÿç”¢é…ç½®
# ======================

# ç’°å¢ƒè¨­å®š
NODE_ENV=production
ENVIRONMENT=production
DEBUG=false
LOG_LEVEL=INFO

# Discord é…ç½®
DISCORD_TOKEN=your_production_bot_token
DISCORD_GUILD_ID=your_production_server_id
DISCORD_CLIENT_ID=your_discord_client_id
DISCORD_CLIENT_SECRET=your_discord_client_secret

# ======================
# è³‡æ–™åº«é…ç½® (PostgreSQL)
# ======================
DB_HOST=postgres-primary.internal
DB_PORT=5432
DB_USER=potato_bot_prod
DB_PASSWORD=your_super_secure_production_password
DB_NAME=potato_bot_production
DB_SSL_MODE=require

# è®€å–å‰¯æœ¬ (å¯é¸)
DB_READ_HOST=postgres-replica.internal
DB_READ_PORT=5432

# ======================
# Redis é…ç½®
# ======================
REDIS_URL=redis://redis-cluster.internal:6379/0
REDIS_PASSWORD=your_redis_cluster_password
REDIS_SSL=true

# ======================
# API æœå‹™é…ç½®
# ======================
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
JWT_SECRET=your_jwt_secret_key_minimum_64_characters_for_production_security
JWT_EXPIRY=3600

# API å®‰å…¨è¨­å®š
API_RATE_LIMIT_PER_MINUTE=120
API_MAX_REQUEST_SIZE=5242880
API_CORS_ORIGINS=https://your-domain.com,https://api.your-domain.com

# ======================
# SSL/TLS é…ç½®
# ======================
SSL_CERT_PATH=/etc/ssl/certs/your-domain.crt
SSL_KEY_PATH=/etc/ssl/private/your-domain.key
SSL_CA_PATH=/etc/ssl/certs/ca-certificates.crt

# ======================
# AI æœå‹™é…ç½®
# ======================
OPENAI_API_KEY=your_production_openai_key
ANTHROPIC_API_KEY=your_production_anthropic_key
GEMINI_API_KEY=your_production_gemini_key

# AI ä½¿ç”¨é™åˆ¶
AI_MAX_TOKENS=8000
AI_RATE_LIMIT_USER=50
AI_RATE_LIMIT_GUILD=500
AI_DAILY_FREE_QUOTA=100

# ======================
# åŠŸèƒ½é…ç½®
# ======================

# ç¥¨åˆ¸ç³»çµ±
TICKET_AUTO_ASSIGNMENT=true
TICKET_SLA_MONITORING=true
TICKET_ADVANCED_STATS=true
TICKET_DEFAULT_SLA_MINUTES=30
TICKET_MAX_PER_USER=5

# ç¶“æ¿Ÿç³»çµ±
ECONOMY_ENABLED=true
ECONOMY_STARTING_COINS=500
ECONOMY_DAILY_BONUS=50

# ======================
# ç›£æ§èˆ‡æ—¥èªŒ
# ======================
LOG_FILE_PATH=/var/log/potato-bot/app.log
LOG_MAX_SIZE=50MB
LOG_BACKUP_COUNT=10

# Sentry éŒ¯èª¤è¿½è¹¤
SENTRY_DSN=your_sentry_dsn_here
SENTRY_ENVIRONMENT=production

# Prometheus ç›£æ§
PROMETHEUS_ENABLED=true
PROMETHEUS_PORT=9090

# ======================
# å®‰å…¨è¨­å®š
# ======================

# ç¶²è·¯å®‰å…¨
ALLOWED_IPS=10.0.0.0/8,172.16.0.0/12,192.168.0.0/16
PROXY_TRUST_IPS=10.0.0.0/8

# è³‡æ–™åŠ å¯†
ENCRYPTION_KEY=your_32_byte_base64_encoded_encryption_key
HASH_SALT_ROUNDS=12

# ======================
# æ•ˆèƒ½å„ªåŒ–
# ======================
CONNECTION_POOL_SIZE=20
MAX_OVERFLOW=30
POOL_TIMEOUT=30
POOL_RECYCLE=3600

# å¿«å–è¨­å®š
CACHE_TTL=300
CACHE_MAX_SIZE=1000

# ======================
# å¤–éƒ¨æœå‹™
# ======================
CDN_URL=https://cdn.your-domain.com
WEBHOOK_URL=https://your-domain.com/webhooks
BACKUP_STORAGE_URL=s3://your-backup-bucket
```

### ç³»çµ±æœå‹™è¨­å®š

#### Systemd æœå‹™æª”æ¡ˆ

```ini
# /etc/systemd/system/potato-bot.service
[Unit]
Description=Potato Discord Bot
After=network.target postgresql.service redis.service
Wants=postgresql.service redis.service

[Service]
Type=simple
User=potato-bot
Group=potato-bot
WorkingDirectory=/opt/potato-bot
Environment=PATH=/opt/potato-bot/venv/bin
ExecStart=/opt/potato-bot/venv/bin/python start.py
ExecReload=/bin/kill -HUP $MAINPID
Restart=always
RestartSec=10
StandardOutput=journal
StandardError=journal
SyslogIdentifier=potato-bot

# å®‰å…¨è¨­å®š
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths=/opt/potato-bot/logs /opt/potato-bot/data

# è³‡æºé™åˆ¶
LimitNOFILE=65536
LimitNPROC=32768

[Install]
WantedBy=multi-user.target
```

#### Nginx åå‘ä»£ç†

```nginx
# /etc/nginx/sites-available/potato-bot
upstream potato_bot_api {
    server 127.0.0.1:8000;
    server 127.0.0.1:8001 backup;
    keepalive 32;
}

server {
    listen 80;
    server_name api.your-domain.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name api.your-domain.com;

    # SSL é…ç½®
    ssl_certificate /etc/ssl/certs/your-domain.crt;
    ssl_certificate_key /etc/ssl/private/your-domain.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;

    # å®‰å…¨æ¨™é ­
    add_header Strict-Transport-Security "max-age=63072000; includeSubDomains; preload";
    add_header X-Content-Type-Options nosniff;
    add_header X-Frame-Options DENY;
    add_header X-XSS-Protection "1; mode=block";

    # API åå‘ä»£ç†
    location /api/ {
        proxy_pass http://potato_bot_api/;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
        
        # è¶…æ™‚è¨­å®š
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    # å¥åº·æª¢æŸ¥
    location /health {
        proxy_pass http://potato_bot_api/health;
        access_log off;
    }

    # éœæ…‹æª”æ¡ˆ
    location /static/ {
        alias /opt/potato-bot/static/;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```

## ğŸ³ Docker éƒ¨ç½²

### Docker Compose ç”Ÿç”¢é…ç½®

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  # æ‡‰ç”¨ç¨‹å¼
  bot-primary:
    build:
      context: .
      dockerfile: Dockerfile.prod
    container_name: potato-bot-primary
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - INSTANCE_ID=primary
    env_file:
      - .env.production
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    depends_on:
      - postgres-primary
      - redis
    networks:
      - potato-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  bot-secondary:
    build:
      context: .
      dockerfile: Dockerfile.prod
    container_name: potato-bot-secondary
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - INSTANCE_ID=secondary
    env_file:
      - .env.production
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    depends_on:
      - postgres-primary
      - redis
    networks:
      - potato-net

  # è³‡æ–™åº«ä¸»ç¯€é»
  postgres-primary:
    image: postgres:15
    container_name: postgres-primary
    restart: unless-stopped
    environment:
      - POSTGRES_DB=potato_bot_production
      - POSTGRES_USER=potato_bot_prod
      - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
    secrets:
      - postgres_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init:/docker-entrypoint-initdb.d
      - ./postgres/conf:/etc/postgresql/postgresql.conf
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    networks:
      - potato-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U potato_bot_prod"]
      interval: 30s
      timeout: 5s
      retries: 3

  # è³‡æ–™åº«å‰¯æœ¬
  postgres-replica:
    image: postgres:15
    container_name: postgres-replica
    restart: unless-stopped
    environment:
      - POSTGRES_DB=potato_bot_production
      - POSTGRES_USER=potato_bot_prod
      - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
      - PGUSER=postgres
    secrets:
      - postgres_password
    volumes:
      - postgres_replica_data:/var/lib/postgresql/data
    networks:
      - potato-net
    depends_on:
      - postgres-primary

  # Redis å¿«å–
  redis:
    image: redis:7-alpine
    container_name: redis-cache
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD} --maxmemory 1gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    networks:
      - potato-net
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Nginx è² è¼‰å‡è¡¡
  nginx:
    image: nginx:alpine
    container_name: nginx-lb
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/conf.d:/etc/nginx/conf.d
      - ./ssl:/etc/ssl
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - bot-primary
      - bot-secondary
    networks:
      - potato-net

  # ç›£æ§æœå‹™
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.retention.time=15d'
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    networks:
      - potato-net

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana:/etc/grafana/provisioning
    networks:
      - potato-net
    depends_on:
      - prometheus

  # æ—¥èªŒæ”¶é›†
  loki:
    image: grafana/loki:latest
    container_name: loki
    restart: unless-stopped
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./monitoring/loki:/etc/loki
      - loki_data:/loki
    networks:
      - potato-net

volumes:
  postgres_data:
  postgres_replica_data:
  redis_data:
  prometheus_data:
  grafana_data:
  loki_data:

networks:
  potato-net:
    driver: bridge

secrets:
  postgres_password:
    file: ./secrets/postgres_password.txt
```

### ç”Ÿç”¢ç’°å¢ƒ Dockerfile

```dockerfile
# Dockerfile.prod
FROM python:3.11-slim

# è¨­å®šå·¥ä½œç›®éŒ„
WORKDIR /app

# å®‰è£ç³»çµ±ä¾è³´
RUN apt-get update && apt-get install -y \
    curl \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# å»ºç«‹æ‡‰ç”¨ç¨‹å¼ä½¿ç”¨è€…
RUN groupadd -r appuser && useradd -r -g appuser appuser

# è¤‡è£½ä¾è³´æª”æ¡ˆ
COPY requirements.txt requirements-prod.txt ./

# å®‰è£ Python ä¾è³´
RUN pip install --no-cache-dir -r requirements-prod.txt

# è¤‡è£½æ‡‰ç”¨ç¨‹å¼ç¨‹å¼ç¢¼
COPY . .

# è¨­å®šæ¬Šé™
RUN chown -R appuser:appuser /app && \
    mkdir -p /app/logs /app/data && \
    chown -R appuser:appuser /app/logs /app/data

# åˆ‡æ›åˆ°æ‡‰ç”¨ç¨‹å¼ä½¿ç”¨è€…
USER appuser

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼
CMD ["python", "start.py"]
```

## â˜ï¸ é›²ç«¯éƒ¨ç½²

### AWS éƒ¨ç½²æ¶æ§‹

```yaml
# AWS è³‡æºé…ç½®
VPC:
  CIDR: 10.0.0.0/16
  Subnets:
    Public: 10.0.1.0/24, 10.0.2.0/24
    Private: 10.0.3.0/24, 10.0.4.0/24
    Database: 10.0.5.0/24, 10.0.6.0/24

Load Balancer:
  Type: Application Load Balancer
  Scheme: Internet-facing
  Subnets: Public

EC2 Instances:
  Type: t3.large (2 vCPU, 8GB RAM)
  Count: 2 (Auto Scaling)
  Subnets: Private
  AMI: Amazon Linux 2

RDS:
  Engine: PostgreSQL 15
  Instance: db.t3.medium
  Multi-AZ: true
  Backup Retention: 7 days

ElastiCache:
  Engine: Redis 7
  Instance: cache.t3.micro
  Cluster Mode: enabled

S3:
  Buckets:
    - potato-bot-backups
    - potato-bot-logs
    - potato-bot-assets

CloudWatch:
  Logs: /aws/ec2/potato-bot
  Metrics: Custom metrics enabled
  Alarms: CPU, Memory, Disk, Network
```

### Terraform é…ç½®ç¯„ä¾‹

```hcl
# main.tf
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# VPC
resource "aws_vpc" "potato_bot" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = {
    Name = "potato-bot-vpc"
  }
}

# Internet Gateway
resource "aws_internet_gateway" "potato_bot" {
  vpc_id = aws_vpc.potato_bot.id

  tags = {
    Name = "potato-bot-igw"
  }
}

# Public Subnets
resource "aws_subnet" "public" {
  count                   = 2
  vpc_id                  = aws_vpc.potato_bot.id
  cidr_block              = "10.0.${count.index + 1}.0/24"
  availability_zone       = data.aws_availability_zones.available.names[count.index]
  map_public_ip_on_launch = true

  tags = {
    Name = "potato-bot-public-${count.index + 1}"
  }
}

# Private Subnets
resource "aws_subnet" "private" {
  count             = 2
  vpc_id            = aws_vpc.potato_bot.id
  cidr_block        = "10.0.${count.index + 3}.0/24"
  availability_zone = data.aws_availability_zones.available.names[count.index]

  tags = {
    Name = "potato-bot-private-${count.index + 1}"
  }
}

# Load Balancer
resource "aws_lb" "potato_bot" {
  name               = "potato-bot-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets            = aws_subnet.public[*].id

  enable_deletion_protection = true
}

# Auto Scaling Group
resource "aws_autoscaling_group" "potato_bot" {
  name                = "potato-bot-asg"
  vpc_zone_identifier = aws_subnet.private[*].id
  target_group_arns   = [aws_lb_target_group.potato_bot.arn]
  health_check_type   = "ELB"
  
  min_size         = 1
  max_size         = 3
  desired_capacity = 2

  launch_template {
    id      = aws_launch_template.potato_bot.id
    version = "$Latest"
  }
}

# RDS Database
resource "aws_db_instance" "potato_bot" {
  identifier = "potato-bot-db"

  engine         = "postgres"
  engine_version = "15.4"
  instance_class = "db.t3.medium"

  allocated_storage     = 100
  max_allocated_storage = 1000
  storage_encrypted     = true

  db_name  = "potato_bot_production"
  username = var.db_username
  password = var.db_password

  vpc_security_group_ids = [aws_security_group.rds.id]
  db_subnet_group_name   = aws_db_subnet_group.potato_bot.name

  backup_retention_period = 7
  backup_window          = "03:00-04:00"
  maintenance_window     = "Sun:04:00-Sun:05:00"

  skip_final_snapshot = false
  final_snapshot_identifier = "potato-bot-db-final-snapshot"

  tags = {
    Name = "potato-bot-database"
  }
}
```

### Azure éƒ¨ç½²ç¯„ä¾‹

```yaml
# azure-pipelines.yml
trigger:
  branches:
    include:
      - main

pool:
  vmImage: 'ubuntu-latest'

variables:
  azureSubscription: 'potato-bot-subscription'
  resourceGroup: 'potato-bot-rg'
  containerRegistry: 'potatobotacr'
  imageName: 'potato-bot'

stages:
- stage: Build
  displayName: 'Build and Push Image'
  jobs:
  - job: Build
    displayName: 'Build Job'
    steps:
    - task: Docker@2
      displayName: 'Build and Push Image'
      inputs:
        containerRegistry: $(containerRegistry)
        repository: $(imageName)
        command: 'buildAndPush'
        Dockerfile: 'Dockerfile.prod'
        tags: |
          $(Build.BuildId)
          latest

- stage: Deploy
  displayName: 'Deploy to Production'
  dependsOn: Build
  jobs:
  - deployment: Deploy
    displayName: 'Deploy Job'
    environment: 'production'
    strategy:
      runOnce:
        deploy:
          steps:
          - task: AzureRmWebAppDeployment@4
            displayName: 'Deploy to Azure Container Instances'
            inputs:
              azureSubscription: $(azureSubscription)
              appType: 'webAppContainer'
              WebAppName: 'potato-bot-app'
              DockerNamespace: '$(containerRegistry).azurecr.io'
              DockerRepository: $(imageName)
              DockerImageTag: '$(Build.BuildId)'
```

## ğŸ›¡ï¸ å®‰å…¨æ€§é…ç½®

### é˜²ç«ç‰†è¦å‰‡

```bash
# UFW é˜²ç«ç‰†é…ç½®
#!/bin/bash

# é‡ç½®é˜²ç«ç‰†è¦å‰‡
ufw --force reset

# é è¨­æ”¿ç­–
ufw default deny incoming
ufw default allow outgoing

# SSH (è‡ªè¨‚ç«¯å£)
ufw allow 2222/tcp

# HTTP/HTTPS
ufw allow 80/tcp
ufw allow 443/tcp

# å…§éƒ¨æœå‹™ (åƒ…é™å…§ç¶²)
ufw allow from 10.0.0.0/8 to any port 5432    # PostgreSQL
ufw allow from 10.0.0.0/8 to any port 6379    # Redis
ufw allow from 10.0.0.0/8 to any port 9090    # Prometheus
ufw allow from 10.0.0.0/8 to any port 3000    # Grafana

# å•Ÿç”¨é˜²ç«ç‰†
ufw --force enable
```

### SSL/TLS é…ç½®

```bash
#!/bin/bash
# SSL æ†‘è­‰è‡ªå‹•æ›´æ–°è…³æœ¬

# Let's Encrypt æ†‘è­‰ç²å–
certbot --nginx -d api.your-domain.com -d admin.your-domain.com \
  --email admin@your-domain.com \
  --agree-tos --non-interactive

# è¨­å®šè‡ªå‹•æ›´æ–°
echo "0 12 * * * /usr/bin/certbot renew --quiet && systemctl reload nginx" | crontab -

# æ¸¬è©¦æ†‘è­‰
certbot certificates
```

### å®‰å…¨ç›£æ§

```python
# security/monitor.py
import logging
import smtplib
from email.mime.text import MIMEText
from datetime import datetime, timedelta
import psutil
import requests

class SecurityMonitor:
    """å®‰å…¨ç›£æ§ç³»çµ±"""
    
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger(__name__)
    
    async def check_failed_logins(self):
        """æª¢æŸ¥å¤±æ•—ç™»å…¥å˜—è©¦"""
        # æª¢æŸ¥ /var/log/auth.log
        with open('/var/log/auth.log', 'r') as f:
            lines = f.readlines()
        
        failed_attempts = []
        for line in lines:
            if 'Failed password' in line:
                failed_attempts.append(line)
        
        if len(failed_attempts) > 10:  # é–¾å€¼
            await self.send_alert(f"æª¢æ¸¬åˆ° {len(failed_attempts)} æ¬¡å¤±æ•—ç™»å…¥å˜—è©¦")
    
    async def check_system_resources(self):
        """æª¢æŸ¥ç³»çµ±è³‡æºä½¿ç”¨"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory_percent = psutil.virtual_memory().percent
        disk_percent = psutil.disk_usage('/').percent
        
        alerts = []
        if cpu_percent > 80:
            alerts.append(f"CPU ä½¿ç”¨ç‡éé«˜: {cpu_percent}%")
        if memory_percent > 85:
            alerts.append(f"è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜: {memory_percent}%")
        if disk_percent > 90:
            alerts.append(f"ç¡¬ç¢Ÿä½¿ç”¨ç‡éé«˜: {disk_percent}%")
        
        for alert in alerts:
            await self.send_alert(alert)
    
    async def check_service_health(self):
        """æª¢æŸ¥æœå‹™å¥åº·ç‹€æ…‹"""
        services = [
            ('Discord Bot', 'http://localhost:8000/health'),
            ('PostgreSQL', self._check_postgres),
            ('Redis', self._check_redis),
        ]
        
        for service_name, check in services:
            try:
                if isinstance(check, str):
                    response = requests.get(check, timeout=5)
                    if response.status_code != 200:
                        raise Exception(f"HTTP {response.status_code}")
                else:
                    await check()
            except Exception as e:
                await self.send_alert(f"{service_name} æœå‹™ç•°å¸¸: {e}")
    
    async def send_alert(self, message):
        """ç™¼é€è­¦å ±"""
        self.logger.critical(f"å®‰å…¨è­¦å ±: {message}")
        
        # ç™¼é€éƒµä»¶è­¦å ±
        if self.config.get('email_alerts'):
            await self._send_email_alert(message)
        
        # ç™¼é€ Discord è­¦å ±
        if self.config.get('discord_webhook'):
            await self._send_discord_alert(message)
    
    async def _send_email_alert(self, message):
        """ç™¼é€éƒµä»¶è­¦å ±"""
        msg = MIMEText(f"æ™‚é–“: {datetime.now()}\nè¨Šæ¯: {message}")
        msg['Subject'] = '[ALERT] Potato Bot å®‰å…¨è­¦å ±'
        msg['From'] = self.config['smtp_from']
        msg['To'] = self.config['alert_email']
        
        with smtplib.SMTP(self.config['smtp_server']) as server:
            server.starttls()
            server.login(self.config['smtp_user'], self.config['smtp_password'])
            server.send_message(msg)
```

### è³‡æ–™åŠ å¯†

```python
# security/encryption.py
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import base64
import os

class EncryptionManager:
    """è³‡æ–™åŠ å¯†ç®¡ç†å™¨"""
    
    def __init__(self, password: bytes, salt: bytes = None):
        if salt is None:
            salt = os.urandom(16)
        
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000,
        )
        key = base64.urlsafe_b64encode(kdf.derive(password))
        self.cipher = Fernet(key)
        self.salt = salt
    
    def encrypt(self, data: str) -> str:
        """åŠ å¯†è³‡æ–™"""
        return self.cipher.encrypt(data.encode()).decode()
    
    def decrypt(self, encrypted_data: str) -> str:
        """è§£å¯†è³‡æ–™"""
        return self.cipher.decrypt(encrypted_data.encode()).decode()
    
    @classmethod
    def generate_key(cls) -> str:
        """ç”Ÿæˆæ–°çš„åŠ å¯†é‡‘é‘°"""
        return Fernet.generate_key().decode()

# ä½¿ç”¨ç¯„ä¾‹
encryption_manager = EncryptionManager(b"your-master-password")

# åŠ å¯†æ•æ„Ÿé…ç½®
encrypted_db_password = encryption_manager.encrypt("your_database_password")
encrypted_api_key = encryption_manager.encrypt("your_api_key")
```

## ğŸš€ æ•ˆèƒ½å„ªåŒ–

### è³‡æ–™åº«å„ªåŒ–

```sql
-- PostgreSQL æ•ˆèƒ½å„ªåŒ–è¨­å®š

-- é€£ç·šæ± è¨­å®š
ALTER SYSTEM SET max_connections = 100;
ALTER SYSTEM SET shared_buffers = '1GB';
ALTER SYSTEM SET effective_cache_size = '3GB';
ALTER SYSTEM SET work_mem = '16MB';
ALTER SYSTEM SET maintenance_work_mem = '256MB';

-- æŸ¥è©¢å„ªåŒ–
ALTER SYSTEM SET random_page_cost = 1.1;
ALTER SYSTEM SET effective_io_concurrency = 200;

-- WAL è¨­å®š
ALTER SYSTEM SET wal_buffers = '16MB';
ALTER SYSTEM SET checkpoint_completion_target = 0.9;
ALTER SYSTEM SET max_wal_size = '1GB';
ALTER SYSTEM SET min_wal_size = '80MB';

-- å¥—ç”¨è¨­å®š
SELECT pg_reload_conf();

-- å»ºç«‹ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_tickets_user_id_status ON tickets(user_id, status);
CREATE INDEX CONCURRENTLY idx_tickets_created_at ON tickets(created_at);
CREATE INDEX CONCURRENTLY idx_votes_guild_id_active ON votes(guild_id, is_active);

-- çµ±è¨ˆè³‡æ–™æ›´æ–°
ANALYZE;
```

### Redis å¿«å–ç­–ç•¥

```python
# cache/strategy.py
import redis.asyncio as redis
import json
import asyncio
from typing import Any, Optional
from datetime import timedelta

class CacheStrategy:
    """æ™ºèƒ½å¿«å–ç­–ç•¥"""
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
    
    async def get_or_set(self, 
                        key: str, 
                        fetch_func: callable,
                        ttl: int = 300,
                        **kwargs) -> Any:
        """ç²å–å¿«å–æˆ–è¨­å®šæ–°å€¼"""
        try:
            cached_value = await self.redis.get(key)
            if cached_value:
                return json.loads(cached_value)
        except Exception:
            pass
        
        # å¿«å–æœªå‘½ä¸­ï¼Œç²å–æ–°å€¼
        value = await fetch_func(**kwargs)
        
        try:
            await self.redis.setex(
                key, 
                ttl, 
                json.dumps(value, default=str)
            )
        except Exception:
            pass  # å¿«å–è¨­å®šå¤±æ•—ä¸å½±éŸ¿æ¥­å‹™
        
        return value
    
    async def invalidate_pattern(self, pattern: str):
        """æ‰¹é‡æ¸…é™¤å¿«å–"""
        keys = await self.redis.keys(pattern)
        if keys:
            await self.redis.delete(*keys)
    
    async def warm_up_cache(self):
        """é ç†±å¿«å–"""
        # é è¼‰å¸¸ç”¨è³‡æ–™
        warming_tasks = [
            self._warm_user_data(),
            self._warm_guild_settings(),
            self._warm_ticket_stats(),
        ]
        
        await asyncio.gather(*warming_tasks, return_exceptions=True)
    
    async def _warm_user_data(self):
        """é ç†±ç”¨æˆ¶è³‡æ–™"""
        # é è¼‰æ´»èºç”¨æˆ¶çš„è³‡æ–™
        pass
```

### æ‡‰ç”¨ç¨‹å¼æ•ˆèƒ½å„ªåŒ–

```python
# performance/optimizer.py
import asyncio
import time
from functools import wraps
from typing import Dict, List
import psutil

class PerformanceOptimizer:
    """æ•ˆèƒ½å„ªåŒ–å™¨"""
    
    def __init__(self):
        self.metrics = {}
        self.slow_queries = []
    
    def monitor_performance(self, threshold: float = 1.0):
        """æ•ˆèƒ½ç›£æ§è£é£¾å™¨"""
        def decorator(func):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                start_time = time.time()
                
                try:
                    result = await func(*args, **kwargs)
                    execution_time = time.time() - start_time
                    
                    # è¨˜éŒ„æ•ˆèƒ½æŒ‡æ¨™
                    self.metrics[func.__name__] = self.metrics.get(func.__name__, [])
                    self.metrics[func.__name__].append(execution_time)
                    
                    # è¨˜éŒ„æ…¢æŸ¥è©¢
                    if execution_time > threshold:
                        self.slow_queries.append({
                            'function': func.__name__,
                            'execution_time': execution_time,
                            'timestamp': time.time(),
                            'args': str(args)[:100],  # é™åˆ¶é•·åº¦
                        })
                    
                    return result
                    
                except Exception as e:
                    execution_time = time.time() - start_time
                    self.slow_queries.append({
                        'function': func.__name__,
                        'execution_time': execution_time,
                        'error': str(e),
                        'timestamp': time.time(),
                    })
                    raise
            
            return wrapper
        return decorator
    
    async def get_performance_report(self) -> Dict:
        """ç²å–æ•ˆèƒ½å ±å‘Š"""
        return {
            'system': {
                'cpu_percent': psutil.cpu_percent(),
                'memory_percent': psutil.virtual_memory().percent,
                'disk_usage': psutil.disk_usage('/').percent,
            },
            'application': {
                'avg_response_times': {
                    func: sum(times) / len(times)
                    for func, times in self.metrics.items()
                },
                'slow_queries': self.slow_queries[-10:],  # æœ€è¿‘ 10 å€‹æ…¢æŸ¥è©¢
            }
        }
```

## ğŸ“Š ç›£æ§ç³»çµ±

### Prometheus æŒ‡æ¨™

```python
# monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time
import psutil

# å®šç¾©æŒ‡æ¨™
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint', 'status'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')
ACTIVE_USERS = Gauge('discord_active_users', 'Number of active Discord users')
TICKET_QUEUE = Gauge('tickets_in_queue', 'Number of tickets waiting for response')
DB_CONNECTIONS = Gauge('database_connections_active', 'Active database connections')

class MetricsCollector:
    """æŒ‡æ¨™æ”¶é›†å™¨"""
    
    def __init__(self):
        self.start_time = time.time()
    
    def record_request(self, method: str, endpoint: str, status: int, duration: float):
        """è¨˜éŒ„ HTTP è«‹æ±‚æŒ‡æ¨™"""
        REQUEST_COUNT.labels(method=method, endpoint=endpoint, status=status).inc()
        REQUEST_DURATION.observe(duration)
    
    async def update_business_metrics(self):
        """æ›´æ–°æ¥­å‹™æŒ‡æ¨™"""
        # æ›´æ–°æ´»èºç”¨æˆ¶æ•¸
        active_users = await self._get_active_users_count()
        ACTIVE_USERS.set(active_users)
        
        # æ›´æ–°ç¥¨åˆ¸éšŠåˆ—
        pending_tickets = await self._get_pending_tickets_count()
        TICKET_QUEUE.set(pending_tickets)
        
        # æ›´æ–°è³‡æ–™åº«é€£ç·šæ•¸
        db_connections = await self._get_db_connections_count()
        DB_CONNECTIONS.set(db_connections)
    
    def start_metrics_server(self, port: int = 9090):
        """å•Ÿå‹•æŒ‡æ¨™æœå‹™å™¨"""
        start_http_server(port)
```

### Grafana å„€è¡¨æ¿é…ç½®

```json
{
  "dashboard": {
    "id": null,
    "title": "Potato Bot Production Dashboard",
    "tags": ["potato-bot", "production"],
    "timezone": "browser",
    "panels": [
      {
        "title": "System Metrics",
        "type": "stat",
        "targets": [
          {
            "expr": "100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "legendFormat": "CPU Usage %"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 70},
                {"color": "red", "value": 90}
              ]
            }
          }
        }
      },
      {
        "title": "Discord Bot Status",
        "type": "timeseries",
        "targets": [
          {
            "expr": "discord_active_users",
            "legendFormat": "Active Users"
          },
          {
            "expr": "tickets_in_queue",
            "legendFormat": "Pending Tickets"
          }
        ]
      },
      {
        "title": "Response Time Distribution",
        "type": "heatmap",
        "targets": [
          {
            "expr": "rate(http_request_duration_seconds_bucket[5m])",
            "legendFormat": "{{le}}"
          }
        ]
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "30s"
  }
}
```

### è­¦å ±è¦å‰‡

```yaml
# alerting/rules.yml
groups:
- name: potato-bot-alerts
  rules:
  - alert: HighCPUUsage
    expr: 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High CPU usage detected"
      description: "CPU usage is above 80% for more than 5 minutes"

  - alert: HighMemoryUsage
    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage detected"
      description: "Memory usage is above 85% for more than 5 minutes"

  - alert: DiscordBotDown
    expr: up{job="discord-bot"} == 0
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "Discord Bot is down"
      description: "Discord Bot has been down for more than 2 minutes"

  - alert: DatabaseConnectionIssue
    expr: database_connections_active == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Database connection issue"
      description: "No active database connections detected"

  - alert: HighTicketQueue
    expr: tickets_in_queue > 50
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "High ticket queue"
      description: "More than 50 tickets waiting for response"
```

## ğŸ’¾ å‚™ä»½èˆ‡æ¢å¾©

### è‡ªå‹•å‚™ä»½è…³æœ¬

```bash
#!/bin/bash
# backup.sh - è‡ªå‹•å‚™ä»½è…³æœ¬

set -euo pipefail

# é…ç½®
BACKUP_DIR="/var/backups/potato-bot"
DB_NAME="potato_bot_production"
DB_USER="potato_bot_prod"
RETENTION_DAYS=30
S3_BUCKET="potato-bot-backups"
DISCORD_WEBHOOK="https://discord.com/api/webhooks/your-webhook-url"

# å»ºç«‹å‚™ä»½ç›®éŒ„
mkdir -p "${BACKUP_DIR}"

# ç”Ÿæˆå‚™ä»½æª”å
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="${BACKUP_DIR}/backup_${TIMESTAMP}.sql.gz"

# è³‡æ–™åº«å‚™ä»½
echo "é–‹å§‹è³‡æ–™åº«å‚™ä»½..."
pg_dump -h localhost -U "${DB_USER}" -d "${DB_NAME}" | gzip > "${BACKUP_FILE}"

# æª¢æŸ¥å‚™ä»½æª”æ¡ˆ
if [ ! -f "${BACKUP_FILE}" ] || [ ! -s "${BACKUP_FILE}" ]; then
    echo "éŒ¯èª¤: å‚™ä»½æª”æ¡ˆå»ºç«‹å¤±æ•—"
    exit 1
fi

# ä¸Šå‚³åˆ° S3
echo "ä¸Šå‚³å‚™ä»½åˆ° S3..."
aws s3 cp "${BACKUP_FILE}" "s3://${S3_BUCKET}/database/"

# å‚™ä»½æ‡‰ç”¨ç¨‹å¼æª”æ¡ˆ
echo "å‚™ä»½æ‡‰ç”¨ç¨‹å¼æª”æ¡ˆ..."
tar -czf "${BACKUP_DIR}/app_backup_${TIMESTAMP}.tar.gz" \
    /opt/potato-bot/logs \
    /opt/potato-bot/data \
    /opt/potato-bot/.env.production

aws s3 cp "${BACKUP_DIR}/app_backup_${TIMESTAMP}.tar.gz" "s3://${S3_BUCKET}/application/"

# æ¸…ç†èˆŠå‚™ä»½
echo "æ¸…ç†èˆŠå‚™ä»½..."
find "${BACKUP_DIR}" -name "*.sql.gz" -mtime +${RETENTION_DAYS} -delete
find "${BACKUP_DIR}" -name "*.tar.gz" -mtime +${RETENTION_DAYS} -delete

# é©—è­‰å‚™ä»½
echo "é©—è­‰å‚™ä»½..."
BACKUP_SIZE=$(stat -c%s "${BACKUP_FILE}")
if [ "${BACKUP_SIZE}" -gt 1000000 ]; then  # è‡³å°‘ 1MB
    echo "å‚™ä»½å®Œæˆ: ${BACKUP_FILE} (${BACKUP_SIZE} bytes)"
    
    # ç™¼é€æˆåŠŸé€šçŸ¥
    curl -H "Content-Type: application/json" \
         -X POST \
         -d "{\"content\":\"âœ… Potato Bot å‚™ä»½æˆåŠŸå®Œæˆ\\næª”æ¡ˆ: $(basename ${BACKUP_FILE})\\nå¤§å°: ${BACKUP_SIZE} bytes\"}" \
         "${DISCORD_WEBHOOK}"
else
    echo "è­¦å‘Š: å‚™ä»½æª”æ¡ˆéå°ï¼Œå¯èƒ½æœ‰å•é¡Œ"
    
    # ç™¼é€è­¦å‘Šé€šçŸ¥
    curl -H "Content-Type: application/json" \
         -X POST \
         -d "{\"content\":\"âš ï¸ Potato Bot å‚™ä»½ç•°å¸¸\\næª”æ¡ˆå¤§å°éå°: ${BACKUP_SIZE} bytes\"}" \
         "${DISCORD_WEBHOOK}"
    exit 1
fi
```

### ç½é›£æ¢å¾©ç¨‹åº

```bash
#!/bin/bash
# disaster_recovery.sh - ç½é›£æ¢å¾©è…³æœ¬

set -euo pipefail

# é…ç½®
BACKUP_DIR="/var/backups/potato-bot"
DB_NAME="potato_bot_production"
DB_USER="potato_bot_prod"
S3_BUCKET="potato-bot-backups"

# åƒæ•¸æª¢æŸ¥
if [ $# -ne 1 ]; then
    echo "ä½¿ç”¨æ–¹å¼: $0 <backup_timestamp>"
    echo "ç¯„ä¾‹: $0 20240101_120000"
    exit 1
fi

TIMESTAMP=$1
BACKUP_FILE="${BACKUP_DIR}/backup_${TIMESTAMP}.sql.gz"

echo "é–‹å§‹ç½é›£æ¢å¾©ç¨‹åº..."
echo "ç›®æ¨™æ™‚é–“é»: ${TIMESTAMP}"

# åœæ­¢æœå‹™
echo "åœæ­¢ç›¸é—œæœå‹™..."
systemctl stop potato-bot
systemctl stop nginx

# å¾ S3 ä¸‹è¼‰å‚™ä»½
if [ ! -f "${BACKUP_FILE}" ]; then
    echo "å¾ S3 ä¸‹è¼‰å‚™ä»½æª”æ¡ˆ..."
    aws s3 cp "s3://${S3_BUCKET}/database/backup_${TIMESTAMP}.sql.gz" "${BACKUP_FILE}"
fi

# å‚™ä»½ç•¶å‰è³‡æ–™åº« (ä»¥é˜²è¬ä¸€)
echo "å‚™ä»½ç•¶å‰è³‡æ–™åº«..."
pg_dump -h localhost -U "${DB_USER}" -d "${DB_NAME}" | \
    gzip > "${BACKUP_DIR}/pre_recovery_backup_$(date +%Y%m%d_%H%M%S).sql.gz"

# æ¢å¾©è³‡æ–™åº«
echo "æ¢å¾©è³‡æ–™åº«..."
dropdb -h localhost -U "${DB_USER}" "${DB_NAME}" || true
createdb -h localhost -U "${DB_USER}" "${DB_NAME}"
zcat "${BACKUP_FILE}" | psql -h localhost -U "${DB_USER}" -d "${DB_NAME}"

# æ¢å¾©æ‡‰ç”¨ç¨‹å¼æª”æ¡ˆ
echo "æ¢å¾©æ‡‰ç”¨ç¨‹å¼æª”æ¡ˆ..."
APP_BACKUP="app_backup_${TIMESTAMP}.tar.gz"
if [ ! -f "${BACKUP_DIR}/${APP_BACKUP}" ]; then
    aws s3 cp "s3://${S3_BUCKET}/application/${APP_BACKUP}" "${BACKUP_DIR}/"
fi

tar -xzf "${BACKUP_DIR}/${APP_BACKUP}" -C /

# é‡å•Ÿæœå‹™
echo "é‡å•Ÿæœå‹™..."
systemctl start potato-bot
systemctl start nginx

# æª¢æŸ¥æœå‹™ç‹€æ…‹
echo "æª¢æŸ¥æœå‹™ç‹€æ…‹..."
sleep 10

if systemctl is-active --quiet potato-bot; then
    echo "âœ… Potato Bot æœå‹™æ¢å¾©æ­£å¸¸"
else
    echo "âŒ Potato Bot æœå‹™å•Ÿå‹•å¤±æ•—"
    systemctl status potato-bot
    exit 1
fi

if systemctl is-active --quiet nginx; then
    echo "âœ… Nginx æœå‹™æ¢å¾©æ­£å¸¸"
else
    echo "âŒ Nginx æœå‹™å•Ÿå‹•å¤±æ•—"
    systemctl status nginx
    exit 1
fi

# å¥åº·æª¢æŸ¥
echo "åŸ·è¡Œå¥åº·æª¢æŸ¥..."
if curl -f http://localhost:8000/health; then
    echo "âœ… æ‡‰ç”¨ç¨‹å¼å¥åº·æª¢æŸ¥é€šé"
    echo "ğŸ‰ ç½é›£æ¢å¾©å®Œæˆï¼"
else
    echo "âŒ æ‡‰ç”¨ç¨‹å¼å¥åº·æª¢æŸ¥å¤±æ•—"
    exit 1
fi
```

## ğŸ”„ ç¶­è­·èˆ‡æ›´æ–°

### æ»¾å‹•æ›´æ–°è…³æœ¬

```bash
#!/bin/bash
# rolling_update.sh - é›¶åœæ©Ÿæ»¾å‹•æ›´æ–°

set -euo pipefail

# é…ç½®
APP_DIR="/opt/potato-bot"
BACKUP_DIR="/var/backups/potato-bot"
HEALTH_CHECK_URL="http://localhost:8000/health"
DISCORD_WEBHOOK="your-webhook-url"

echo "é–‹å§‹æ»¾å‹•æ›´æ–°ç¨‹åº..."

# é æ›´æ–°æª¢æŸ¥
echo "åŸ·è¡Œé æ›´æ–°æª¢æŸ¥..."
if ! curl -f "${HEALTH_CHECK_URL}" > /dev/null; then
    echo "éŒ¯èª¤: ç•¶å‰æ‡‰ç”¨ç¨‹å¼ä¸å¥åº·ï¼Œå–æ¶ˆæ›´æ–°"
    exit 1
fi

# å»ºç«‹å‚™ä»½
echo "å»ºç«‹ç•¶å‰ç‰ˆæœ¬å‚™ä»½..."
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
cp -r "${APP_DIR}" "${BACKUP_DIR}/app_backup_${TIMESTAMP}"

# ä¸‹è¼‰æ–°ç‰ˆæœ¬
echo "ä¸‹è¼‰æ–°ç‰ˆæœ¬..."
cd "${APP_DIR}"
git fetch origin
NEW_VERSION=$(git rev-parse origin/main)
CURRENT_VERSION=$(git rev-parse HEAD)

if [ "${NEW_VERSION}" = "${CURRENT_VERSION}" ]; then
    echo "å·²ç¶“æ˜¯æœ€æ–°ç‰ˆæœ¬ï¼Œç„¡éœ€æ›´æ–°"
    exit 0
fi

echo "ç•¶å‰ç‰ˆæœ¬: ${CURRENT_VERSION}"
echo "ç›®æ¨™ç‰ˆæœ¬: ${NEW_VERSION}"

# æ›´æ–°ç¨‹å¼ç¢¼
echo "æ›´æ–°ç¨‹å¼ç¢¼..."
git checkout "${NEW_VERSION}"

# æ›´æ–°ä¾è³´
echo "æ›´æ–° Python ä¾è³´..."
pip install -r requirements.txt

# åŸ·è¡Œè³‡æ–™åº«é·ç§»
echo "åŸ·è¡Œè³‡æ–™åº«é·ç§»..."
python -m alembic upgrade head

# é‡æ–°è¼‰å…¥æœå‹™é…ç½®
echo "é‡æ–°è¼‰å…¥æœå‹™..."
systemctl daemon-reload
systemctl reload potato-bot

# å¥åº·æª¢æŸ¥
echo "ç­‰å¾…æœå‹™ç©©å®š..."
sleep 30

HEALTH_CHECK_ATTEMPTS=0
MAX_ATTEMPTS=12

while [ $HEALTH_CHECK_ATTEMPTS -lt $MAX_ATTEMPTS ]; do
    if curl -f "${HEALTH_CHECK_URL}" > /dev/null; then
        echo "âœ… å¥åº·æª¢æŸ¥é€šé"
        break
    fi
    
    echo "å¥åº·æª¢æŸ¥å¤±æ•—ï¼Œç­‰å¾…é‡è©¦..."
    sleep 10
    HEALTH_CHECK_ATTEMPTS=$((HEALTH_CHECK_ATTEMPTS + 1))
done

if [ $HEALTH_CHECK_ATTEMPTS -eq $MAX_ATTEMPTS ]; then
    echo "âŒ å¥åº·æª¢æŸ¥å¤±æ•—ï¼Œé–‹å§‹å›æ»¾..."
    
    # å›æ»¾åˆ°å‰ä¸€å€‹ç‰ˆæœ¬
    git checkout "${CURRENT_VERSION}"
    systemctl reload potato-bot
    
    echo "å›æ»¾å®Œæˆï¼Œç™¼é€è­¦å ±..."
    curl -H "Content-Type: application/json" \
         -X POST \
         -d "{\"content\":\"ğŸš¨ Potato Bot æ›´æ–°å¤±æ•—ï¼Œå·²è‡ªå‹•å›æ»¾\"}" \
         "${DISCORD_WEBHOOK}"
    
    exit 1
fi

# æ›´æ–°æˆåŠŸ
echo "ğŸ‰ æ›´æ–°æˆåŠŸå®Œæˆï¼"
curl -H "Content-Type: application/json" \
     -X POST \
     -d "{\"content\":\"âœ… Potato Bot æˆåŠŸæ›´æ–°è‡³ç‰ˆæœ¬ ${NEW_VERSION:0:8}\"}" \
     "${DISCORD_WEBHOOK}"
```

### ç¶­è­·æ¨¡å¼

```python
# maintenance/mode.py
import asyncio
import aioredis
from datetime import datetime, timedelta

class MaintenanceMode:
    """ç¶­è­·æ¨¡å¼ç®¡ç†"""
    
    def __init__(self, redis_client):
        self.redis = redis_client
        self.maintenance_key = "potato_bot:maintenance"
    
    async def enable_maintenance(self, duration_minutes: int = 30, reason: str = ""):
        """å•Ÿç”¨ç¶­è­·æ¨¡å¼"""
        end_time = datetime.utcnow() + timedelta(minutes=duration_minutes)
        
        maintenance_info = {
            'enabled': True,
            'start_time': datetime.utcnow().isoformat(),
            'end_time': end_time.isoformat(),
            'reason': reason,
        }
        
        await self.redis.hset(self.maintenance_key, mapping=maintenance_info)
        await self.redis.expire(self.maintenance_key, duration_minutes * 60)
        
        print(f"âœ… ç¶­è­·æ¨¡å¼å·²å•Ÿç”¨ï¼Œé è¨ˆçµæŸæ™‚é–“: {end_time}")
    
    async def disable_maintenance(self):
        """åœç”¨ç¶­è­·æ¨¡å¼"""
        await self.redis.delete(self.maintenance_key)
        print("âœ… ç¶­è­·æ¨¡å¼å·²åœç”¨")
    
    async def is_maintenance_active(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦åœ¨ç¶­è­·æ¨¡å¼"""
        return await self.redis.exists(self.maintenance_key)
    
    async def get_maintenance_info(self) -> dict:
        """ç²å–ç¶­è­·è³‡è¨Š"""
        info = await self.redis.hgetall(self.maintenance_key)
        if not info:
            return {'enabled': False}
        
        return {
            'enabled': True,
            'start_time': info.get('start_time'),
            'end_time': info.get('end_time'),
            'reason': info.get('reason'),
        }

# åœ¨ Discord Bot ä¸­ä½¿ç”¨
class MaintenanceMiddleware:
    """ç¶­è­·æ¨¡å¼ä¸­ä»‹è»Ÿé«”"""
    
    def __init__(self, maintenance_manager: MaintenanceMode):
        self.maintenance = maintenance_manager
    
    async def check_maintenance(self, ctx):
        """æª¢æŸ¥ç¶­è­·æ¨¡å¼"""
        if await self.maintenance.is_maintenance_active():
            info = await self.maintenance.get_maintenance_info()
            
            embed = discord.Embed(
                title="ğŸ”§ ç³»çµ±ç¶­è­·ä¸­",
                description=f"åŸå› : {info.get('reason', 'ä¾‹è¡Œç¶­è­·')}",
                color=0xff9900
            )
            embed.add_field(
                name="é è¨ˆçµæŸæ™‚é–“",
                value=info.get('end_time', 'æœªçŸ¥'),
                inline=False
            )
            
            await ctx.send(embed=embed)
            return True
        
        return False
```

---

<div align="center">

**ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²å®Œæˆï¼** ğŸš€

[è¿”å›ä¸»æ–‡æª”](README.md) â€¢ [é–‹ç™¼æŒ‡å—](README.dev.md) â€¢ [æŠ€è¡“æ”¯æ´](https://github.com/Craig-0219/potato/issues)

*æœ¬æŒ‡å—æ¶µè“‹å°ˆæ¥­ç´šç”Ÿç”¢ç’°å¢ƒçš„æ‰€æœ‰é—œéµé…ç½®å’Œæœ€ä½³å¯¦è¸*

</div>