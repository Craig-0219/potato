#!/usr/bin/env python3
"""
CI/CD æ•ˆèƒ½åˆ†æå·¥å…·
åˆ†æ GitHub Actions workflow åŸ·è¡Œæ™‚é–“å’Œç“¶é ¸
"""

import os
import sys
import json
import requests
from datetime import datetime, timedelta
import argparse
import statistics
from typing import List, Dict, Any

class CICDPerformanceAnalyzer:
    def __init__(self, repo: str = "Craig-0219/potato", token: str = None):
        self.repo = repo
        self.token = token or os.environ.get('GITHUB_TOKEN')
        self.headers = {
            'Authorization': f'token {self.token}' if self.token else '',
            'Accept': 'application/vnd.github.v3+json'
        }
        self.workflows_of_interest = [
            "ğŸ§ª Test Coverage & Quality",
            "ğŸ” Code Quality Checks", 
            "ğŸ”’ Security Scans",
            "âš¡ Optimized CI Pipeline",
            "ğŸš€ Lightweight CI"
        ]
    
    def fetch_workflow_runs(self, days: int = 7, limit: int = 50) -> List[Dict[str, Any]]:
        """ç²å– workflow åŸ·è¡Œæ•¸æ“š"""
        if not self.token:
            print("âŒ éœ€è¦ GITHUB_TOKEN ç’°å¢ƒè®Šæ•¸")
            return []
        
        url = f'https://api.github.com/repos/{self.repo}/actions/runs'
        params = {
            'per_page': limit,
            'branch': 'dev',
            'status': 'completed'
        }
        
        try:
            response = requests.get(url, headers=self.headers, params=params)
            response.raise_for_status()
            
            runs_data = response.json()
            metrics = []
            cutoff_date = datetime.now() - timedelta(days=days)
            
            for run in runs_data.get('workflow_runs', []):
                created_at = datetime.fromisoformat(run['created_at'].replace('Z', '+00:00'))
                
                # åªåˆ†ææœ€è¿‘æŒ‡å®šå¤©æ•¸çš„æ•¸æ“š
                if created_at < cutoff_date:
                    continue
                
                updated_at = datetime.fromisoformat(run['updated_at'].replace('Z', '+00:00'))
                duration_seconds = (updated_at - created_at).total_seconds()
                
                metrics.append({
                    'workflow_name': run['name'],
                    'run_id': run['id'],
                    'status': run['conclusion'],
                    'branch': run['head_branch'],
                    'duration_seconds': duration_seconds,
                    'duration_minutes': round(duration_seconds / 60, 2),
                    'created_at': run['created_at'],
                    'trigger_event': run['event'],
                    'attempt': run['run_attempt']
                })
            
            return metrics
            
        except Exception as e:
            print(f"âŒ API è«‹æ±‚å¤±æ•—: {e}")
            return []
    
    def analyze_by_workflow(self, metrics: List[Dict[str, Any]]) -> Dict[str, Dict[str, float]]:
        """æŒ‰ workflow åˆ†ææ•ˆèƒ½"""
        workflow_data = {}
        
        for metric in metrics:
            name = metric['workflow_name']
            duration = metric['duration_minutes']
            
            if name not in workflow_data:
                workflow_data[name] = []
            workflow_data[name].append(duration)
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        analysis = {}
        for name, durations in workflow_data.items():
            if durations:
                analysis[name] = {
                    'count': len(durations),
                    'mean': statistics.mean(durations),
                    'median': statistics.median(durations),
                    'max': max(durations),
                    'min': min(durations),
                    'stdev': statistics.stdev(durations) if len(durations) > 1 else 0
                }
        
        return analysis
    
    def calculate_success_rates(self, metrics: List[Dict[str, Any]]) -> Dict[str, float]:
        """è¨ˆç®—æˆåŠŸç‡"""
        workflow_results = {}
        
        for metric in metrics:
            name = metric['workflow_name']
            status = metric['status']
            
            if name not in workflow_results:
                workflow_results[name] = {'total': 0, 'success': 0}
            
            workflow_results[name]['total'] += 1
            if status == 'success':
                workflow_results[name]['success'] += 1
        
        success_rates = {}
        for name, results in workflow_results.items():
            success_rates[name] = (results['success'] / results['total']) * 100 if results['total'] > 0 else 0
        
        return success_rates
    
    def identify_bottlenecks(self, analysis: Dict[str, Dict[str, float]]) -> List[Dict[str, Any]]:
        """è­˜åˆ¥æ•ˆèƒ½ç“¶é ¸"""
        bottlenecks = []
        
        # æŒ‰å¹³å‡åŸ·è¡Œæ™‚é–“æ’åº
        sorted_workflows = sorted(analysis.items(), key=lambda x: x[1]['mean'], reverse=True)
        
        for i, (name, stats) in enumerate(sorted_workflows[:3], 1):
            improvement_potential = max(0, stats['mean'] - 5.0)  # ç›®æ¨™ 5 åˆ†é˜
            
            bottlenecks.append({
                'rank': i,
                'workflow': name,
                'avg_duration': stats['mean'],
                'max_duration': stats['max'],
                'execution_count': stats['count'],
                'improvement_potential': improvement_potential,
                'variability': stats['stdev']
            })
        
        return bottlenecks
    
    def generate_optimization_suggestions(self, bottlenecks: List[Dict[str, Any]], 
                                        success_rates: Dict[str, float]) -> List[str]:
        """ç”Ÿæˆå„ªåŒ–å»ºè­°"""
        suggestions = []
        
        # åŸºæ–¼ç“¶é ¸çš„å»ºè­°
        total_potential = sum(b['improvement_potential'] for b in bottlenecks)
        if total_potential > 0:
            suggestions.append(f"ğŸ¯ å„ªåŒ–å‰ 3 å¤§ç“¶é ¸å¯ç¯€çœ {total_potential:.1f} åˆ†é˜åŸ·è¡Œæ™‚é–“")
        
        # åŸºæ–¼åŸ·è¡Œæ™‚é–“çš„å»ºè­°
        for b in bottlenecks:
            if b['avg_duration'] > 10:
                suggestions.append(f"âš¡ {b['workflow']} å¹³å‡åŸ·è¡Œæ™‚é–“éé•· ({b['avg_duration']:.1f}åˆ†é˜)ï¼Œå»ºè­°:")
                suggestions.append(f"  - å¯¦ä½œæ™ºèƒ½è·³éæ©Ÿåˆ¶")
                suggestions.append(f"  - å„ªåŒ–ä¾è³´å®‰è£å¿«å–")
                suggestions.append(f"  - ä¸¦è¡ŒåŒ–æ¸¬è©¦åŸ·è¡Œ")
            
            if b['variability'] > 2:
                suggestions.append(f"ğŸ“Š {b['workflow']} åŸ·è¡Œæ™‚é–“è®Šç•°å¤§ (Â±{b['variability']:.1f}åˆ†é˜)ï¼Œéœ€è¦ç©©å®šæ€§å„ªåŒ–")
        
        # åŸºæ–¼æˆåŠŸç‡çš„å»ºè­°
        failing_workflows = [name for name, rate in success_rates.items() if rate < 95]
        if failing_workflows:
            suggestions.append(f"ğŸ”§ æ”¹å–„å¤±æ•—ç‡è¼ƒé«˜çš„ workflows: {', '.join(failing_workflows)}")
        
        # é€šç”¨å»ºè­°
        suggestions.extend([
            "ğŸ’¡ é€šç”¨å„ªåŒ–ç­–ç•¥:",
            "  - å¯¦ä½œå¤šå±¤å¿«å–ç­–ç•¥ (ä¾è³´ã€æ¸¬è©¦çµæœã€å·¥å…·é…ç½®)",
            "  - åŸºæ–¼è®Šæ›´é¡å‹çš„æ™ºèƒ½åŸ·è¡Œç­–ç•¥", 
            "  - å‹•æ…‹æ¸¬è©¦çŸ©é™£ï¼Œé¿å…ä¸å¿…è¦çš„åŸ·è¡Œ",
            "  - å¤±æ•—å¿«é€Ÿæ¢å¾©å’Œé‡è©¦æ©Ÿåˆ¶"
        ])
        
        return suggestions
    
    def print_analysis_report(self, metrics: List[Dict[str, Any]]) -> None:
        """è¼¸å‡ºåˆ†æå ±å‘Š"""
        if not metrics:
            print("âŒ æ²’æœ‰å¯åˆ†æçš„æ•¸æ“š")
            return
        
        print("ğŸš€ CI/CD æ•ˆèƒ½åˆ†æå ±å‘Š")
        print("=" * 60)
        print(f"ğŸ“Š æ•¸æ“šç¯„åœ: æœ€è¿‘ {len(metrics)} æ¬¡åŸ·è¡Œ")
        print(f"ğŸ“… åˆ†ææ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        # æ•´é«”çµ±è¨ˆ
        durations = [m['duration_minutes'] for m in metrics]
        overall_avg = statistics.mean(durations)
        overall_median = statistics.median(durations)
        overall_max = max(durations)
        
        print("ğŸ“ˆ æ•´é«”æ•ˆèƒ½æŒ‡æ¨™:")
        print(f"  â€¢ å¹³å‡åŸ·è¡Œæ™‚é–“: {overall_avg:.2f} åˆ†é˜")
        print(f"  â€¢ ä¸­ä½æ•¸åŸ·è¡Œæ™‚é–“: {overall_median:.2f} åˆ†é˜") 
        print(f"  â€¢ æœ€é•·åŸ·è¡Œæ™‚é–“: {overall_max:.2f} åˆ†é˜")
        print()
        
        # æŒ‰ workflow åˆ†æ
        analysis = self.analyze_by_workflow(metrics)
        print("ğŸ“Š å„ Workflow æ•ˆèƒ½åˆ†æ:")
        
        for name, stats in sorted(analysis.items(), key=lambda x: x[1]['mean'], reverse=True):
            print(f"â€¢ {name}:")
            print(f"  - åŸ·è¡Œæ¬¡æ•¸: {stats['count']}")
            print(f"  - å¹³å‡æ™‚é–“: {stats['mean']:.2f} åˆ†é˜")
            print(f"  - ä¸­ä½æ•¸: {stats['median']:.2f} åˆ†é˜")
            print(f"  - æœ€é•·æ™‚é–“: {stats['max']:.2f} åˆ†é˜")
            if stats['stdev'] > 0:
                print(f"  - æ¨™æº–å·®: {stats['stdev']:.2f} åˆ†é˜")
        print()
        
        # æˆåŠŸç‡åˆ†æ
        success_rates = self.calculate_success_rates(metrics)
        print("âœ… æˆåŠŸç‡åˆ†æ:")
        for name, rate in sorted(success_rates.items(), key=lambda x: x[1], reverse=True):
            status = "âœ…" if rate >= 95 else "âš ï¸" if rate >= 90 else "âŒ"
            print(f"  {status} {name}: {rate:.1f}%")
        print()
        
        # ç“¶é ¸åˆ†æ
        bottlenecks = self.identify_bottlenecks(analysis)
        print("ğŸš¨ æ•ˆèƒ½ç“¶é ¸ TOP 3:")
        for b in bottlenecks:
            print(f"  {b['rank']}. {b['workflow']}")
            print(f"     å¹³å‡: {b['avg_duration']:.2f} åˆ†é˜ | æœ€é•·: {b['max_duration']:.2f} åˆ†é˜")
            print(f"     åŸ·è¡Œæ¬¡æ•¸: {b['execution_count']} | æ”¹å–„æ½›åŠ›: {b['improvement_potential']:.1f} åˆ†é˜")
        print()
        
        # å„ªåŒ–å»ºè­°
        suggestions = self.generate_optimization_suggestions(bottlenecks, success_rates)
        print("ğŸ’¡ å„ªåŒ–å»ºè­°:")
        for suggestion in suggestions:
            print(f"  {suggestion}")
        print()
        
        # ç›®æ¨™å°æ¯”
        target_time = 8.0  # ç›®æ¨™åŸ·è¡Œæ™‚é–“
        current_avg = overall_avg
        if current_avg > target_time:
            improvement_needed = current_avg - target_time
            improvement_percent = (improvement_needed / current_avg) * 100
            print(f"ğŸ¯ å„ªåŒ–ç›®æ¨™:")
            print(f"  â€¢ ç•¶å‰å¹³å‡: {current_avg:.2f} åˆ†é˜")
            print(f"  â€¢ ç›®æ¨™æ™‚é–“: {target_time} åˆ†é˜")
            print(f"  â€¢ éœ€è¦æ”¹å–„: {improvement_needed:.2f} åˆ†é˜ ({improvement_percent:.1f}%)")
        else:
            print(f"ğŸ‰ å·²é”æˆç›®æ¨™! ç•¶å‰å¹³å‡åŸ·è¡Œæ™‚é–“ {current_avg:.2f} åˆ†é˜ < ç›®æ¨™ {target_time} åˆ†é˜")

def main():
    parser = argparse.ArgumentParser(description='CI/CD æ•ˆèƒ½åˆ†æå·¥å…·')
    parser.add_argument('--days', type=int, default=7, help='åˆ†ææœ€è¿‘Nå¤©çš„æ•¸æ“š (é»˜èª: 7)')
    parser.add_argument('--limit', type=int, default=50, help='æœ€å¤§åˆ†æè¨˜éŒ„æ•¸ (é»˜èª: 50)')
    parser.add_argument('--repo', default='Craig-0219/potato', help='GitHub å€‰åº« (é»˜èª: Craig-0219/potato)')
    parser.add_argument('--output', help='è¼¸å‡ºå ±å‘Šåˆ°æ–‡ä»¶')
    
    args = parser.parse_args()
    
    analyzer = CICDPerformanceAnalyzer(repo=args.repo)
    
    print(f"ğŸ“¡ æ­£åœ¨ç²å–æœ€è¿‘ {args.days} å¤©çš„ CI/CD æ•¸æ“š...")
    metrics = analyzer.fetch_workflow_runs(days=args.days, limit=args.limit)
    
    if not metrics:
        print("âŒ æœªç²å–åˆ°æ•¸æ“šï¼Œè«‹æª¢æŸ¥:")
        print("  â€¢ GITHUB_TOKEN ç’°å¢ƒè®Šæ•¸æ˜¯å¦è¨­ç½®") 
        print("  â€¢ å€‰åº«åç¨±æ˜¯å¦æ­£ç¢º")
        print("  â€¢ ç¶²è·¯é€£æ¥æ˜¯å¦æ­£å¸¸")
        return
    
    # ç”Ÿæˆåˆ†æå ±å‘Š
    if args.output:
        # é‡å®šå‘è¼¸å‡ºåˆ°æ–‡ä»¶
        import io
        from contextlib import redirect_stdout
        
        with open(args.output, 'w', encoding='utf-8') as f:
            with redirect_stdout(f):
                analyzer.print_analysis_report(metrics)
        print(f"ğŸ“ å ±å‘Šå·²ä¿å­˜åˆ°: {args.output}")
    else:
        analyzer.print_analysis_report(metrics)

if __name__ == '__main__':
    main()